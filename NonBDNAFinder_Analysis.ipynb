{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NonBDNA Finder â€” Analysis Notebook\n\n## Overview\nDetects and analyses **Non-B DNA structural motifs** in one or more FASTA files.  \nThe notebook is structured as **3 cells (tabs)**:\n\n| Cell | Purpose |\n|------|---------|\n| **Cell 1 Â· Setup** | Imports, user config, helpers, engine initialisation |\n| **Cell 2 Â· Analysis** | Detection, all statistics (class/subclass densities & coverages), plots, downloads |\n\nRun **Cell 1 first**, then **Cell 2**.\n\n---\n\n## Detectors â€” 11 classes, 23+ subclasses\n\nNine specialised structural detectors are run in parallel; **Hybrid** and **Non-B DNA Cluster** annotations\nare derived automatically from their combined output.\n\n| Class | Detection Method | Key Subclasses |\n|---|---|---|\n| Curved DNA | A/T-tract phasing (Koo 1986; Olson 1998) | Global Curvature, Local Curvature |\n| Slipped DNA | K-mer indexing, repeat scoring (SchlÃ¶tterer 2000; Weber 1989) | STR, Direct Repeat |\n| Cruciform | Thermodynamic seed-and-extend IR analysis (Lilley 2000; SantaLucia 1998) | Cruciform forming IRs |\n| R-Loop | QmRLFS algorithm (Jenjaroenpun 2016; Aguilera 2012) | R-loop formation sites |\n| Triplex | Mirror-repeat purity + Sticky DNA GAA/TTC (Frank-Kamenetskii 1995; Sakamoto 1999) | H-DNA, Sticky DNA |\n| G-Quadruplex | Seeded G4Hunter scoring (Bedrat 2016) | Canonical G4, Telomeric G4, Bulged G4, Extended-loop G4, Stacked G4, G-wire, G-triplex, Weak PQS |\n| i-Motif | C-rich four-tract patterns + HUR AC-motif (Gehring 1993; Zeraati 2018; Hur 2021) | Canonical i-Motif, AC-motif (HUR) |\n| Z-DNA | 10-mer propensity table (Ho 1986); eGZ trinucleotide repeats (Herbert 1997) | Z-DNA, eGZ |\n| A-philic DNA | 10-mer propensity scoring (Gorin 1995; Vinogradov 2003) | A-philic DNA |\n| **Hybrid** | Multi-class overlap detection (this work) | Mixed |\n| **Non-B DNA Clusters** | Density-based structural hotspot detection (this work) | Mixed |\n\n---\n\n## Statistics produced\n\n| Table | Columns |\n|---|---|\n| **Per-file summary** | Sequences, bp, GC%, Motifs, Classes, Subclasses, Density/kb, Coverage% |\n| **Class statistics** | Count, Mean Length, Mean Score, **Density/kb**, **Coverage%** |\n| **Subclass statistics** | Count, Mean Length, Mean Score, **Density/kb**, **Coverage%** |\n| **File Ã— Class pivot** | Motif counts per file per class |\n| **Class density pivot** | Density (motifs/kb) per file per class |\n| **Class coverage pivot** | Coverage (%) per file per class |\n| **Comprehensive genome stats** | 25 structural metrics per file and globally |\n\n### Comprehensive Genome Statistics (25 metrics)\n\n| Section | Metrics |\n|---|---|\n| **I. Genome Overview** | Genome Length, Motifs (excl./incl. Hybrid/Cluster), Classes, Density/kb |\n| **II. Structural Coverage** | Total Covered Bases, Coverage Fraction, Coverage % |\n| **III. Occupancy Metrics** | Raw Occupancy, Normalized Occupancy (SLI), Mean Overlap Depth |\n| **IV. Class-Specific Coverage** | Covered bp, Coverage %, Contribution % per class |\n| **V. Structural Load Metrics** | SLI, Structural Intensity, Weighted Structural Coverage |\n| **VI. Spatial Distribution** | Mean Inter-Motif Distance, CV (Clustering Coefficient) |\n| **VII. Hotspot / Cluster Metrics** | Max Local Density, Max Class Diversity, Max Cluster Score |\n| **VIII. Hybrid & Cluster Regions** | Counts, Coverage %, Mean Overlap Fraction |\n| **IX. Structural Diversity** | Simpson Diversity Index (D), Effective Class Number (Neff) |\n| **X. Genome-Scale Comparative** | SCI (Structural Complexity Index), Structural Dominance Ratio |\n\n## Plots produced\n\n### Per-file plots\n- Class distribution & Subclass distribution\n- Class density & coverage (motifs/kb, %)\n- Subclass density & coverage (top 20)\n- Hybrid & Cluster breakdown\n- **Linear motif track** (genome-scale positional view)\n- **Linear subclass track**\n- **Nested pie chart** (Class â†’ Subclass hierarchy)\n- **Length distribution KDE** (by class)\n- **Score violin** (by class)\n- **Density comparison** (genomic vs positional)\n- **Structural potential heatmap**\n- **Motif co-occurrence network**\n- **Co-occurrence matrix**\n- **Chromosome density** (motif density by class)\n- **Inter-motif clustering distance**\n- **Structural features** (spacer/loop variation)\n- **Structural competition** (UpSet plot)\n- **Cluster size distribution** (when Hybrid/Cluster motifs present)\n- Sequence-level density & coverage (multi-sequence files)\n- Positional distribution (equal-length multiFASTA)\n\n### Global plots\n- All per-file plots summarised across all input files\n- Density / coverage comparison across files\n- Class/Subclass density & coverage heatmaps (files Ã— classes)\n- Hybrid & Cluster comparison across files\n- GFF feature-type Ã— class heatmap (when GFF provided)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1 Â· SETUP â€” imports, configuration, helpers\n",
    "# Edit FASTA_INPUT and OUTPUT_DIR, then run this cell before Cell 2.\n",
    "# =============================================================================\n",
    "\n",
    "import sys, os, importlib, glob, gc, time, datetime, re, warnings\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "_REPO_ROOT = os.path.abspath(os.getcwd())\n",
    "if _REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, _REPO_ROOT)\n",
    "\n",
    "# â”€â”€ Auto-install missing packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "_REQUIRED = [('psutil','psutil>=5.8'),('pandas','pandas>=1.3'),('numpy','numpy>=1.21'),\n",
    "             ('matplotlib','matplotlib>=3.5'),('seaborn','seaborn>=0.11'),\n",
    "             ('openpyxl','openpyxl>=3.0'),('tqdm','tqdm>=4.64'),\n",
    "             ('pyarrow','pyarrow>=10.0')]\n",
    "_miss = [p for m,p in _REQUIRED if importlib.util.find_spec(m) is None]\n",
    "if _miss:\n",
    "    import subprocess; subprocess.check_call([sys.executable,'-m','pip','install',*_miss,'-q'])\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, HTML, Image\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# â”€â”€ Optional fast FASTA parser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    import pyfastx as _pyfastx\n",
    "    _HAS_PYFASTX = True\n",
    "except ImportError:\n",
    "    _HAS_PYFASTX = False\n",
    "    try:\n",
    "        from Bio import SeqIO as _SeqIO\n",
    "        _HAS_SEQIO = True\n",
    "    except ImportError:\n",
    "        _HAS_SEQIO = False\n",
    "\n",
    "# â”€â”€ USER CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FASTA_INPUT        = ['*.fna', '*.fasta']   # path, wildcard, or list\n",
    "OUTPUT_DIR         = 'notebook_reports'\n",
    "ENABLED_CLASSES    = None                   # None = all; e.g. ['G-Quadruplex','Z-DNA']\n",
    "RAM_OVERRIDE_BYTES = None                   # None = auto\n",
    "\n",
    "# â”€â”€ Execution mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MODE = 'GENOME'  -> ProcessPoolExecutor, Parquet streaming, no plots/previews\n",
    "# MODE = 'LOCAL'   -> original notebook behaviour with all visualisations\n",
    "MODE = 'LOCAL'\n",
    "\n",
    "# â”€â”€ Large-chromosome chunking (active in both modes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Chromosomes larger than LARGE_CHR_THRESHOLD_MB are split into overlapping\n",
    "# sub-chunks processed sequentially inside the chromosome worker, then merged.\n",
    "LARGE_CHR_THRESHOLD_MB  = 50   # Mb - split chromosomes larger than this\n",
    "GENOME_CHUNK_SIZE_MB    = 2    # Mb - sub-chunk size (1-5 Mb recommended)\n",
    "GENOME_CHUNK_OVERLAP_KB = 5    # kb - overlap between sub-chunks\n",
    "\n",
    "# â”€â”€ GPU detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _detect_gpu():\n",
    "    for lib, attr in [('torch','cuda'),('cupy',None)]:\n",
    "        try:\n",
    "            m = importlib.import_module(lib)\n",
    "            if lib == 'torch' and m.cuda.is_available():\n",
    "                return 'cuda', m.cuda.get_device_name(0)\n",
    "            elif lib == 'cupy':\n",
    "                m.array([1]); return 'cupy', 'CUDA GPU'\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None, None\n",
    "\n",
    "GPU_BACKEND, GPU_NAME = _detect_gpu()\n",
    "print(f'\\u2705 Deps OK | Python {sys.version.split()[0]} | '\n",
    "      f'GPU: {GPU_BACKEND+(\"(\"+GPU_NAME+\")\") if GPU_BACKEND else \"none (CPU)\"}')\n",
    "\n",
    "# â”€â”€ Resolve FASTA files & classify types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _resolve(inp):\n",
    "    out = []\n",
    "    for p in ([inp] if isinstance(inp, str) else list(inp)):\n",
    "        hits = glob.glob(p); out.extend(hits)\n",
    "        if not hits and os.path.isfile(p): out.append(p)\n",
    "    return sorted({str(Path(f).resolve()) for f in out})\n",
    "\n",
    "def _seq_lengths(p):\n",
    "    L, c = [], 0\n",
    "    with open(p) as fh:\n",
    "        for ln in fh:\n",
    "            s = ln.strip()\n",
    "            if s.startswith('>'):\n",
    "                if c: L.append(c); c = 0\n",
    "            else: c += len(s)\n",
    "    if c: L.append(c)\n",
    "    return L\n",
    "\n",
    "def _stream_fasta(fasta_path):\n",
    "    \"\"\"Stream one sequence at a time without loading the full genome into memory.\n",
    "\n",
    "    Uses pyfastx if available, Bio.SeqIO iterator otherwise, or a plain FASTA\n",
    "    line reader as fallback.  Yields (name, sequence_str) tuples.\n",
    "    \"\"\"\n",
    "    if _HAS_PYFASTX:\n",
    "        for seq in _pyfastx.Fasta(str(fasta_path), build_index=False):\n",
    "            yield seq.name, seq.seq\n",
    "    elif _HAS_SEQIO:\n",
    "        with open(fasta_path) as fh:\n",
    "            for rec in _SeqIO.parse(fh, 'fasta'):\n",
    "                yield rec.id, str(rec.seq)\n",
    "    else:\n",
    "        name, parts = None, []\n",
    "        with open(fasta_path) as fh:\n",
    "            for ln in fh:\n",
    "                s = ln.rstrip('\\n')\n",
    "                if s.startswith('>'):\n",
    "                    if name is not None:\n",
    "                        yield name, ''.join(parts)\n",
    "                    name = s[1:].split()[0]; parts = []\n",
    "                else:\n",
    "                    parts.append(s)\n",
    "        if name is not None:\n",
    "            yield name, ''.join(parts)\n",
    "\n",
    "FASTA_FILES = _resolve(FASTA_INPUT)\n",
    "if not FASTA_FILES:\n",
    "    raise FileNotFoundError(f'No FASTA files found for: {FASTA_INPUT}')\n",
    "\n",
    "FILE_TYPES = {}\n",
    "for fp in FASTA_FILES:\n",
    "    ls = _seq_lengths(fp)\n",
    "    FILE_TYPES[fp] = ('single' if len(ls)==1 else\n",
    "                      'multi_equal' if len(set(ls))==1 else 'multi')\n",
    "\n",
    "GFF_MAP = {}\n",
    "for fp in FASTA_FILES:\n",
    "    stem, parent = Path(fp).stem, Path(fp).parent\n",
    "    for ext in ('.gff3','.gff'):\n",
    "        cand = parent/(stem+ext)\n",
    "        if cand.exists(): GFF_MAP[fp] = str(cand); break\n",
    "\n",
    "print(f'\\n\\U0001f4c2 Input files: {len(FASTA_FILES)}')\n",
    "for fp in FASTA_FILES:\n",
    "    gff_tag = f'  +GFF: {Path(GFF_MAP[fp]).name}' if fp in GFF_MAP else ''\n",
    "    print(f'   [{FILE_TYPES[fp]:12s}]  {Path(fp).name}{gff_tag}')\n",
    "\n",
    "# â”€â”€ Adaptive resource planning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from Utilities.system_resource_inspector import SystemResourceInspector\n",
    "from Utilities.adaptive_chunk_planner    import AdaptiveChunkPlanner\n",
    "from Utilities.nonbscanner               import analyze_sequence as _nbf_analyze\n",
    "from Utilities.utilities                 import (\n",
    "    read_fasta_file, compute_comprehensive_genome_stats,\n",
    "    calculate_genomic_density, calculate_positional_density,\n",
    "    plot_linear_motif_track, plot_linear_subclass_track,\n",
    "    plot_density_comparison, plot_motif_length_kde,\n",
    "    plot_score_violin, plot_nested_pie_chart,\n",
    "    plot_structural_heatmap, plot_motif_network,\n",
    "    plot_motif_cooccurrence_matrix, plot_chromosome_density,\n",
    "    plot_spacer_loop_variation, plot_motif_clustering_distance,\n",
    "    plot_structural_competition_upset, plot_cluster_size_distribution,\n",
    ")\n",
    "\n",
    "_insp   = SystemResourceInspector()\n",
    "_budget = RAM_OVERRIDE_BYTES or _insp.get_memory_budget()\n",
    "_cpus   = _insp.get_cpu_count()\n",
    "_total  = max(sum(os.path.getsize(f) for f in FASTA_FILES if os.path.exists(f)), 1_000)\n",
    "_plan   = AdaptiveChunkPlanner().plan(_total, _budget, _cpus)\n",
    "CHUNK_SIZE, CHUNK_OVERLAP = _plan['chunk_size'], _plan['overlap']\n",
    "\n",
    "# Worker count: GENOME mode uses all available cores minus 2 for OS/IO headroom.\n",
    "# LOCAL mode keeps the adaptive planner's suggestion (original behaviour).\n",
    "if MODE == 'GENOME':\n",
    "    N_WORKERS = max(1, (os.cpu_count() or 4) - 2)\n",
    "    EXEC_MODE = _plan['mode']\n",
    "else:\n",
    "    N_WORKERS, EXEC_MODE = _plan['workers'], _plan['mode']\n",
    "    if GPU_BACKEND:\n",
    "        N_WORKERS = min(N_WORKERS * 2, os.cpu_count() or 4)\n",
    "\n",
    "# Derived chromosome-chunking parameters (Mb / kb -> bp)\n",
    "_LARGE_CHR_THRESHOLD  = LARGE_CHR_THRESHOLD_MB  * 1_000_000\n",
    "_GENOME_CHUNK_SIZE    = GENOME_CHUNK_SIZE_MB     * 1_000_000\n",
    "_GENOME_CHUNK_OVERLAP = GENOME_CHUNK_OVERLAP_KB  * 1_000\n",
    "\n",
    "_RUN_TS = datetime.datetime.now(datetime.timezone.utc).strftime('%Y%m%d_%H%M%S')\n",
    "_BASE   = Path(OUTPUT_DIR) / _RUN_TS\n",
    "_BASE.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\u2699\\ufe0f  MODE={MODE} | RAM {_budget/1e9:.2f}GB | '\n",
    "      f'chunk={CHUNK_SIZE:,} overlap={CHUNK_OVERLAP:,} '\n",
    "      f'workers={N_WORKERS} mode={EXEC_MODE}')\n",
    "_fasta_backend = 'pyfastx' if _HAS_PYFASTX else ('SeqIO' if _HAS_SEQIO else 'built-in')\n",
    "print(f'   FASTA stream: {_fasta_backend} | '\n",
    "      f'large-chr chunk: {GENOME_CHUNK_SIZE_MB} Mb + {GENOME_CHUNK_OVERLAP_KB} kb overlap')\n",
    "print(f'\\U0001f4c2 Run output: {_BASE}')\n",
    "\n",
    "# â”€â”€ Core helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _scan(name, seq):\n",
    "    if len(seq) < 10:\n",
    "        tqdm.write(f'  \\u26a0\\ufe0f  {name[:55]}  \\u2192 skipped (sequence too short: {len(seq)}bp < 10bp)')\n",
    "        return []\n",
    "    return _nbf_analyze(sequence=seq, sequence_name=name, use_chunking=True,\n",
    "                        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP,\n",
    "                        use_parallel_chunks=(EXEC_MODE=='hybrid'),\n",
    "                        enabled_classes=ENABLED_CLASSES)\n",
    "\n",
    "def _savefig(fig, path, show=True):\n",
    "    fig.savefig(str(path), dpi=150, bbox_inches='tight'); plt.close(fig)\n",
    "    if show and MODE != 'GENOME': display(Image(str(path)))\n",
    "\n",
    "def _safe_fname(s): return re.sub(r'[^\\w\\-]', '_', str(s))\n",
    "\n",
    "def _parse_species_region(stem):\n",
    "    idx = stem.find('_')\n",
    "    return (stem, 'unknown') if idx == -1 else (stem[:idx], stem[idx+1:])\n",
    "\n",
    "def _gc_and_length(fasta_path):\n",
    "    gc = total = 0\n",
    "    with open(fasta_path) as fh:\n",
    "        for ln in fh:\n",
    "            s = ln.strip()\n",
    "            if not s or s.startswith('>'): continue\n",
    "            su = s.upper(); gc += su.count('G') + su.count('C'); total += len(su)\n",
    "    return (round(gc/total*100, 2) if total else 0.0), total\n",
    "\n",
    "def _merge_coverage(intervals, cap=None):\n",
    "    \"\"\"Sum of merged interval lengths; optionally capped at cap.\"\"\"\n",
    "    if len(intervals) == 0: return 0\n",
    "    intervals = np.array(intervals, dtype=int)\n",
    "    if cap is not None:\n",
    "        intervals[:,1] = np.minimum(intervals[:,1], cap)\n",
    "    intervals = intervals[intervals[:,1] > intervals[:,0]]\n",
    "    if len(intervals) == 0: return 0\n",
    "    intervals = intervals[np.argsort(intervals[:,0])]\n",
    "    s, e = intervals[0]; covered = 0\n",
    "    for cs, ce in intervals[1:]:\n",
    "        if cs <= e: e = max(e, ce)\n",
    "        else: covered += e-s; s,e = cs,ce\n",
    "    return covered + e - s\n",
    "\n",
    "def _coverage(df, seq_lengths_dict):\n",
    "    \"\"\"Overall coverage % across all sequences.\"\"\"\n",
    "    if df.empty or not seq_lengths_dict: return 0.0\n",
    "    total_len = sum(seq_lengths_dict.values())\n",
    "    if total_len == 0: return 0.0\n",
    "    covered = sum(\n",
    "        _merge_coverage(grp[['Start','End']].values, cap=seq_lengths_dict.get(sn, 0))\n",
    "        for sn, grp in df.groupby('Sequence_Name')\n",
    "    )\n",
    "    return round(covered / total_len * 100, 2)\n",
    "\n",
    "def _class_density_coverage(df, all_results):\n",
    "    \"\"\"Return dict: class -> {Density_per_kb, Coverage_pct} across all files.\"\"\"\n",
    "    total_bp = sum(sum(r['seq_lengths'].values()) for r in all_results.values())\n",
    "    if total_bp == 0 or df.empty: return {}\n",
    "    out = {}\n",
    "    for cls, grp in df.groupby('Class'):\n",
    "        cov_bp = 0\n",
    "        for stem, res in all_results.items():\n",
    "            sub = grp[grp['Source_File'] == Path(res['path']).name]\n",
    "            if sub.empty: continue\n",
    "            for sn, sg in sub.groupby('Sequence_Name'):\n",
    "                sq_len = res['seq_lengths'].get(sn, 0)\n",
    "                cov_bp += _merge_coverage(sg[['Start','End']].values, cap=sq_len)\n",
    "        out[cls] = {'Density_per_kb': round(len(grp)/total_bp*1000, 4),\n",
    "                    'Coverage_pct':   round(cov_bp/total_bp*100, 3)}\n",
    "    return out\n",
    "\n",
    "def _subclass_density_coverage(df, all_results):\n",
    "    \"\"\"Return dict: subclass -> {Density_per_kb, Coverage_pct} across all files.\"\"\"\n",
    "    total_bp = sum(sum(r['seq_lengths'].values()) for r in all_results.values())\n",
    "    if total_bp == 0 or df.empty: return {}\n",
    "    out = {}\n",
    "    for sc, grp in df.groupby('Subclass'):\n",
    "        cov_bp = 0\n",
    "        for stem, res in all_results.items():\n",
    "            sub = grp[grp['Source_File'] == Path(res['path']).name]\n",
    "            if sub.empty: continue\n",
    "            for sn, sg in sub.groupby('Sequence_Name'):\n",
    "                sq_len = res['seq_lengths'].get(sn, 0)\n",
    "                cov_bp += _merge_coverage(sg[['Start','End']].values, cap=sq_len)\n",
    "        out[sc] = {'Density_per_kb': round(len(grp)/total_bp*1000, 4),\n",
    "                   'Coverage_pct':   round(cov_bp/total_bp*100, 3)}\n",
    "    return out\n",
    "\n",
    "def _parse_gff(gff_path):\n",
    "    feats = []\n",
    "    with open(gff_path) as fh:\n",
    "        for ln in fh:\n",
    "            if ln.startswith('#') or not ln.strip(): continue\n",
    "            p = ln.rstrip('\\n').split('\\t')\n",
    "            if len(p) < 8: continue\n",
    "            try:\n",
    "                feats.append({'seqid':p[0],'type':p[2],'start':max(int(p[3])-1,0),\n",
    "                              'end':int(p[4]),'strand':p[6],\n",
    "                              'attrs':p[8] if len(p)>8 else ''})\n",
    "            except ValueError: pass\n",
    "    return feats\n",
    "\n",
    "print('\\u2705 Engine Ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2 Â· ANALYSIS â€” detection, all statistics, plots, downloads\n",
    "# Run Cell 1 first.\n",
    "# =============================================================================\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# PROFILING HOOKS (optional; active in both modes)\n",
    "# ---------------------------------------------------------------------------\n",
    "_PROFILE_ENABLED = False   # set True to wrap execution with cProfile\n",
    "_WALL_START = time.perf_counter()\n",
    "\n",
    "try:\n",
    "    import psutil as _psutil\n",
    "    _proc = _psutil.Process()\n",
    "    def _mem_mb(): return _proc.memory_info().rss / 1e6\n",
    "except ImportError:\n",
    "    def _mem_mb(): return float('nan')\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# GENOME MODE: chromosome-level ProcessPoolExecutor + Parquet disk streaming\n",
    "# ---------------------------------------------------------------------------\n",
    "if MODE == 'GENOME':\n",
    "    import cProfile, pstats, io\n",
    "    from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "    from Utilities.genome_worker import process_chromosome\n",
    "\n",
    "    if __name__ == '__main__' or True:   # True keeps this runnable from Jupyter\n",
    "        RESULTS_BY_FILE = {}\n",
    "        GFF_RESULTS     = {}\n",
    "\n",
    "        for fasta_path in tqdm(FASTA_FILES, desc='Files (GENOME)', unit='file'):\n",
    "            stem  = Path(fasta_path).stem\n",
    "            ftype = FILE_TYPES[fasta_path]\n",
    "            fdir  = _BASE / stem\n",
    "            fdir.mkdir(parents=True, exist_ok=True)\n",
    "            _parquet_dir = str(fdir / '_parquet')\n",
    "            Path(_parquet_dir).mkdir(exist_ok=True)\n",
    "            tqdm.write(f'\\n\\u2500\\u2500 {stem}  [{ftype}] \\u2500\\u2500  (GENOME mode)')\n",
    "\n",
    "            # Stream sequences without loading entire genome into memory\n",
    "            _seq_items = list(_stream_fasta(fasta_path))   # (name, seq) pairs\n",
    "            sl_map = {sn: len(sq) for sn, sq in _seq_items}\n",
    "\n",
    "            # Build worker args; sequences are passed by value (copy-on-write\n",
    "            # on Linux fork, explicit copy on Windows spawn)\n",
    "            _worker_args = [\n",
    "                (\n",
    "                    sn, sq,\n",
    "                    Path(fasta_path).name, ftype,\n",
    "                    _LARGE_CHR_THRESHOLD,\n",
    "                    _GENOME_CHUNK_SIZE,\n",
    "                    _GENOME_CHUNK_OVERLAP,\n",
    "                    ENABLED_CLASSES,\n",
    "                    _parquet_dir,\n",
    "                    CHUNK_SIZE, CHUNK_OVERLAP,\n",
    "                )\n",
    "                for sn, sq in _seq_items\n",
    "            ]\n",
    "            # Release in-memory sequences before spawning workers\n",
    "            del _seq_items; gc.collect()\n",
    "\n",
    "            _t0 = time.perf_counter()\n",
    "            _parquet_paths = []\n",
    "            _total_motifs  = 0\n",
    "            _chr_times     = {}\n",
    "\n",
    "            # Each chromosome processed by a separate process\n",
    "            with ProcessPoolExecutor(max_workers=N_WORKERS) as _pool:\n",
    "                _futs = {_pool.submit(process_chromosome, a): a[0]\n",
    "                         for a in _worker_args}\n",
    "                for _fut in tqdm(as_completed(_futs),\n",
    "                                 total=len(_futs),\n",
    "                                 desc=f'  seqs({stem})', leave=False):\n",
    "                    _sn = _futs[_fut]\n",
    "                    try:\n",
    "                        _sn_r, _ppath, _n, _t = _fut.result()\n",
    "                        _chr_times[_sn_r] = _t\n",
    "                        if _ppath:\n",
    "                            _parquet_paths.append(_ppath)\n",
    "                        _total_motifs += _n\n",
    "                        tqdm.write(f'  \\u25b8 {_sn_r[:55]}  \\u2192 {_n:,} motifs '\n",
    "                                   f'({_t:.1f}s | RAM {_mem_mb():.0f} MB)')\n",
    "                    except Exception as _e:\n",
    "                        tqdm.write(f'  \\u26a0\\ufe0f  {_sn[:55]}  \\u2192 skipped ({_e})')\n",
    "\n",
    "            _elapsed_file = time.perf_counter() - _t0\n",
    "            tqdm.write(f'  \\u2705 {_total_motifs:,} motifs in {_elapsed_file:.1f}s | '\n",
    "                       f'RAM {_mem_mb():.0f} MB')\n",
    "\n",
    "            # Merge per-chromosome Parquet files into a single per-file DataFrame\n",
    "            if _parquet_paths:\n",
    "                import pyarrow.parquet as _pq_local\n",
    "                df = pd.concat(\n",
    "                    [pd.read_parquet(p) for p in _parquet_paths],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                df = pd.DataFrame()\n",
    "\n",
    "            # Ensure required columns exist with correct defaults\n",
    "            for _col, _dflt in [('Class','Unknown'),('Subclass','Other'),\n",
    "                                 ('Start',0),('End',0),('Length',0),\n",
    "                                 ('Score',0.0),('Strand','+'),\n",
    "                                 ('Sequence_Name','')]:\n",
    "                if _col not in df.columns: df[_col] = _dflt\n",
    "            if not df.empty:\n",
    "                df['Length'] = np.where(df['Length']==0,\n",
    "                                        (df['End']-df['Start']).clip(lower=0),\n",
    "                                        df['Length'])\n",
    "            df['Source_File'] = Path(fasta_path).name\n",
    "            df['File_Type']   = ftype\n",
    "\n",
    "            # Persist merged results as Parquet (fast, compressed)\n",
    "            if not df.empty:\n",
    "                df.to_parquet(str(fdir/'motifs.parquet'), index=False)\n",
    "                df.to_csv(str(fdir/'motifs.csv'), encoding='utf-8-sig', index=False)\n",
    "\n",
    "            RESULTS_BY_FILE[stem] = {\n",
    "                'df':df, 'folder':fdir, 'file_type':ftype,\n",
    "                'path':fasta_path, 'seq_lengths':sl_map\n",
    "            }\n",
    "            gc.collect()\n",
    "\n",
    "        print(f'\\n\\u2705 GENOME detection complete â€” {len(RESULTS_BY_FILE)} file(s)')\n",
    "        _wall_total = time.perf_counter() - _WALL_START\n",
    "        print(f'   Total wall time: {_wall_total:.1f}s | '\n",
    "               f'Peak RAM: {_mem_mb():.0f} MB')\n",
    "\n",
    "        # â”€â”€â”€ Build master tables (identical schema to LOCAL mode) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        _dfs       = [r['df'] for r in RESULTS_BY_FILE.values() if not r['df'].empty]\n",
    "        _master_df = pd.concat(_dfs, ignore_index=True) if _dfs else pd.DataFrame()\n",
    "        _master_dir = _BASE / '_master'; _master_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        if not _master_df.empty:\n",
    "            _master_df.to_parquet(str(_master_dir/'master_motifs.parquet'), index=False)\n",
    "            _master_df.to_csv(str(_master_dir/'master_motifs.csv'),\n",
    "                              encoding='utf-8-sig', index=False)\n",
    "            print(f'\\U0001f4be Parquet output: {_master_dir}/master_motifs.parquet')\n",
    "            print(f'   Shape: {_master_df.shape}')\n",
    "\n",
    "else:  # LOCAL mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # fall-through: the original LOCAL detection code runs below\n",
    "    pass\n",
    "\n",
    "if MODE != 'GENOME':\n",
    "    RESULTS_BY_FILE = {}   # stem -> {df, folder, file_type, path, seq_lengths}\n",
    "    GFF_RESULTS     = {}   # stem -> {region_df, gff_path, folder}\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # A. PER-FILE DETECTION\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for fasta_path in tqdm(FASTA_FILES, desc='Files', unit='file'):\n",
    "        stem    = Path(fasta_path).stem\n",
    "        ftype   = FILE_TYPES[fasta_path]\n",
    "        fdir    = _BASE / stem\n",
    "        fdir.mkdir(parents=True, exist_ok=True)\n",
    "        tqdm.write(f'\\n\\u2500\\u2500 {stem}  [{ftype}] \\u2500\\u2500')\n",
    "\n",
    "        seqs = read_fasta_file(fasta_path)\n",
    "        if not seqs:\n",
    "            tqdm.write('  \\u26a0\\ufe0f  No sequences â€” skipping.')\n",
    "            continue\n",
    "\n",
    "        sl_map = {sn: len(sq) for sn, sq in seqs.items()}  # seq_name -> length\n",
    "\n",
    "        # Parallel motif scanning\n",
    "        motifs_file, t0 = [], time.perf_counter()\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=N_WORKERS) as pool:\n",
    "            futs = {pool.submit(_scan, sn, sq): sn for sn, sq in seqs.items()}\n",
    "            for fut in tqdm(concurrent.futures.as_completed(futs),\n",
    "                            total=len(futs), desc=f'  seqs({stem})', leave=False):\n",
    "                sn = futs[fut]\n",
    "                try:\n",
    "                    res = fut.result()\n",
    "                    tqdm.write(f'  \\u25b8 {sn[:55]}  \\u2192 {len(res):,} motifs')\n",
    "                    motifs_file.extend(res)\n",
    "                except Exception as _e:\n",
    "                    tqdm.write(f'  \\u26a0\\ufe0f  {sn[:55]}  \\u2192 skipped ({_e})')\n",
    "        tqdm.write(f'  \\u2705 {len(motifs_file):,} motifs in {time.perf_counter()-t0:.1f}s')\n",
    "        gc.collect()\n",
    "\n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame(motifs_file) if motifs_file else pd.DataFrame()\n",
    "        for col, dflt in [('Class','Unknown'),('Subclass','Other'),('Start',0),\n",
    "                          ('End',0),('Length',0),('Score',0.0),('Strand','+'),('Sequence_Name','')]:\n",
    "            if col not in df.columns: df[col] = dflt\n",
    "        if not df.empty:\n",
    "            df['Length'] = np.where(df['Length']==0,\n",
    "                                    (df['End']-df['Start']).clip(lower=0), df['Length'])\n",
    "        df['Source_File'] = Path(fasta_path).name\n",
    "        df['File_Type']   = ftype\n",
    "\n",
    "        # Save CSV + Excel\n",
    "        if not df.empty:\n",
    "            df.to_csv(str(fdir/'motifs.csv'), encoding='utf-8-sig', index=False)\n",
    "            df.to_excel(str(fdir/'motifs.xlsx'), index=False)\n",
    "\n",
    "        # â”€â”€ Per-file inline plots â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if not df.empty:\n",
    "            total_bp = max(sum(sl_map.values()), 1)\n",
    "\n",
    "            # 1. Class distribution\n",
    "            cc = df['Class'].value_counts()\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, len(cc)*0.45)))\n",
    "            ax.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n",
    "            ax.set_xlabel('Motif Count')\n",
    "            ax.set_title(f'{stem} [{ftype}] â€” Class Distribution')\n",
    "            for i,v in enumerate(cc.values[::-1]): ax.text(v+0.3, i, str(v), va='center', fontsize=8)\n",
    "            plt.tight_layout(); _savefig(fig, fdir/'class_distribution.png')\n",
    "\n",
    "            # 2. Subclass distribution (top 30)\n",
    "            sc = df['Subclass'].value_counts().head(30)\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, len(sc)*0.4)))\n",
    "            ax.barh(sc.index[::-1], sc.values[::-1], color='darkorange')\n",
    "            ax.set_xlabel('Motif Count')\n",
    "            ax.set_title(f'{stem} â€” Subclass Distribution (top 30)')\n",
    "            plt.tight_layout(); _savefig(fig, fdir/'subclass_distribution.png')\n",
    "\n",
    "            # 3. Class density (motifs/kb)\n",
    "            cls_dens = df.groupby('Class').apply(\n",
    "                lambda g: round(len(g)/total_bp*1000, 4)).sort_values(ascending=False)\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, len(cls_dens)*0.45)))\n",
    "            ax.barh(cls_dens.index[::-1], cls_dens.values[::-1], color='teal')\n",
    "            ax.set_xlabel('Motifs per kb'); ax.set_title(f'{stem} â€” Class Density (motifs/kb)')\n",
    "            for i,v in enumerate(cls_dens.values[::-1]): ax.text(v, i, f'{v:.4f}', va='center', fontsize=8)\n",
    "            plt.tight_layout(); _savefig(fig, fdir/'class_density.png')\n",
    "\n",
    "            # 4. Class coverage (%)\n",
    "            cls_cov = {}\n",
    "            for cls, grp in df.groupby('Class'):\n",
    "                cov = sum(_merge_coverage(sg[['Start','End']].values, cap=sl_map.get(sn,0))\n",
    "                          for sn, sg in grp.groupby('Sequence_Name'))\n",
    "                cls_cov[cls] = round(cov/total_bp*100, 3)\n",
    "            _cov_s = pd.Series(cls_cov).sort_values(ascending=False)\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, len(_cov_s)*0.45)))\n",
    "            ax.barh(_cov_s.index[::-1], _cov_s.values[::-1], color='mediumseagreen')\n",
    "            ax.set_xlabel('Coverage (%)'); ax.set_title(f'{stem} â€” Class Coverage (%)')\n",
    "            ax.set_xlim(0, min(100, _cov_s.max()*1.15+0.5))\n",
    "            for i,v in enumerate(_cov_s.values[::-1]): ax.text(v, i, f'{v:.3f}%', va='center', fontsize=8)\n",
    "            plt.tight_layout(); _savefig(fig, fdir/'class_coverage.png')\n",
    "\n",
    "            # 5. Subclass density (top 20)\n",
    "            sc_dens = df.groupby('Subclass').apply(\n",
    "                lambda g: round(len(g)/total_bp*1000, 4)).nlargest(20)\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, len(sc_dens)*0.4)))\n",
    "            ax.barh(sc_dens.index[::-1], sc_dens.values[::-1], color='coral')\n",
    "            ax.set_xlabel('Motifs per kb'); ax.set_title(f'{stem} â€” Subclass Density (top 20, motifs/kb)')\n",
    "            plt.tight_layout(); _savefig(fig, fdir/'subclass_density.png')\n",
    "\n",
    "            # 6. Subclass coverage (top 20 by coverage)\n",
    "            sc_cov = {}\n",
    "            for sc_name, grp in df.groupby('Subclass'):\n",
    "                cov = sum(_merge_coverage(sg[['Start','End']].values, cap=sl_map.get(sn,0))\n",
    "                          for sn, sg in grp.groupby('Sequence_Name'))\n",
    "                sc_cov[sc_name] = round(cov/total_bp*100, 3)\n",
    "            _scov_s = pd.Series(sc_cov).nlargest(20)\n",
    "            fig, ax = plt.subplots(figsize=(8, max(3, len(_scov_s)*0.4)))\n",
    "            ax.barh(_scov_s.index[::-1], _scov_s.values[::-1], color='orchid')\n",
    "            ax.set_xlabel('Coverage (%)'); ax.set_title(f'{stem} â€” Subclass Coverage (top 20, %)')\n",
    "            plt.tight_layout(); _savefig(fig, fdir/'subclass_coverage.png')\n",
    "\n",
    "            # 7. Hybrid & Cluster breakdown\n",
    "            _special = df[df['Class'].isin(['Hybrid','Non-B_DNA_Clusters'])]\n",
    "            if not _special.empty:\n",
    "                sp_cnt = _special['Class'].value_counts()\n",
    "                fig, ax = plt.subplots(figsize=(6,3))\n",
    "                ax.bar(sp_cnt.index, sp_cnt.values, color=['tomato','mediumpurple'])\n",
    "                ax.set_ylabel('Count'); ax.set_title(f'{stem} â€” Hybrid & Cluster Motifs')\n",
    "                for i,v in enumerate(sp_cnt.values): ax.text(i, v+0.2, str(v), ha='center', fontsize=9)\n",
    "                plt.tight_layout(); _savefig(fig, fdir/'hybrid_cluster_breakdown.png')\n",
    "\n",
    "            # 8. Sequence-level density & coverage (multi-seq)\n",
    "            if ftype in ('multi','multi_equal'):\n",
    "                _rows_d, _rows_c = [], []\n",
    "                for sn, sq_len in sl_map.items():\n",
    "                    sub = df[df['Sequence_Name']==sn]\n",
    "                    n   = len(sub)\n",
    "                    cov = (_merge_coverage(sub[['Start','End']].values, cap=sq_len)\n",
    "                           if not sub.empty else 0)\n",
    "                    _rows_d.append({'Sequence':sn[:40],'Density_per_kb':round(n/sq_len*1000,4) if sq_len else 0})\n",
    "                    _rows_c.append({'Sequence':sn[:40],'Coverage_pct':round(cov/sq_len*100,2) if sq_len else 0})\n",
    "\n",
    "                _dd = pd.DataFrame(_rows_d).sort_values('Density_per_kb',ascending=False).head(40)\n",
    "                fig, ax = plt.subplots(figsize=(9, max(4, len(_dd)*0.35)))\n",
    "                ax.barh(_dd['Sequence'][::-1], _dd['Density_per_kb'][::-1], color='teal')\n",
    "                ax.set_xlabel('Motifs per kb'); ax.set_title(f'{stem} â€” Motif Density by Sequence (top 40)')\n",
    "                plt.tight_layout(); _savefig(fig, fdir/'motif_density_by_sequence.png')\n",
    "\n",
    "                _cd = pd.DataFrame(_rows_c).sort_values('Coverage_pct',ascending=False).head(40)\n",
    "                fig, ax = plt.subplots(figsize=(9, max(4, len(_cd)*0.35)))\n",
    "                ax.barh(_cd['Sequence'][::-1], _cd['Coverage_pct'][::-1], color='mediumseagreen')\n",
    "                ax.set_xlabel('Coverage (%)'); ax.set_title(f'{stem} â€” Non-B DNA Coverage by Sequence (top 40)')\n",
    "                ax.set_xlim(0,100); plt.tight_layout(); _savefig(fig, fdir/'sequence_coverage.png')\n",
    "\n",
    "            # 9. Positional distribution (equal-length multiFASTA)\n",
    "            if ftype == 'multi_equal':\n",
    "                seq_len_val = list(sl_map.values())[0]\n",
    "                for cls in df['Class'].unique():\n",
    "                    starts = df[df['Class']==cls]['Start'].dropna().astype(int)\n",
    "                    starts = starts[starts < seq_len_val]\n",
    "                    if starts.empty: continue\n",
    "                    fig, ax = plt.subplots(figsize=(10,3))\n",
    "                    ax.hist(starts, bins=min(100,seq_len_val), color='steelblue', alpha=0.8, edgecolor='none')\n",
    "                    ax.set_xlabel('Position (bp)'); ax.set_ylabel('Frequency')\n",
    "                    ax.set_title(f'{stem} â€” {cls} Positional Distribution (n={len(starts):,})')\n",
    "                    ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x,_: f'{int(x):,}'))\n",
    "                    plt.tight_layout(); _savefig(fig, fdir/f'positional_dist_{_safe_fname(cls)}.png', show=False)\n",
    "\n",
    "                    # 10. Comprehensive genome statistics\n",
    "            _motifs_list = df.to_dict('records')\n",
    "            try:\n",
    "                gstats = compute_comprehensive_genome_stats(_motifs_list, total_bp)\n",
    "                print(f'\\n  ðŸ“Š Comprehensive Genome Statistics â€” {stem}')\n",
    "                _gs_rows = [\n",
    "                    ('Genome Length',                        f\"{gstats['genome_length']:,} bp\"),\n",
    "                    ('Motifs (excl. Hybrid/Cluster)',        f\"{gstats['n_motifs']:,}\"),\n",
    "                    ('Motifs (incl. Hybrid/Cluster)',        f\"{gstats['n_motifs_all']:,}\"),\n",
    "                    ('Motif Classes',                        str(gstats['n_classes'])),\n",
    "                    ('Motif Density',                        f\"{gstats['density_per_kb']:.4f} / kb\"),\n",
    "                    ('Total Covered Bases',                  f\"{gstats['total_covered_bases']:,} bp\"),\n",
    "                    ('Coverage Fraction',                    f\"{gstats['coverage_fraction']:.6f}\"),\n",
    "                    ('Coverage (%)',                         f\"{gstats['coverage_pct']:.4f}%\"),\n",
    "                    ('Raw Occupancy',                        f\"{gstats['raw_occupancy_bp']:,} bp\"),\n",
    "                    ('Normalized Occupancy (SLI)',           f\"{gstats['normalized_occupancy']:.6f}\"),\n",
    "                    ('Mean Overlap Depth',                   f\"{gstats['mean_overlap_depth']:.4f}\"),\n",
    "                    ('SLI',                                  f\"{gstats['sli']:.6f}\"),\n",
    "                    ('Structural Intensity',                 f\"{gstats['structural_intensity']:.6f}\"),\n",
    "                    ('Weighted Structural Coverage',         f\"{gstats['weighted_structural_coverage']:.6f}\"),\n",
    "                    ('Mean Inter-Motif Distance',            f\"{gstats['mean_inter_motif_distance']:.2f} bp\"),\n",
    "                    ('CV (Clustering Coefficient)',          f\"{gstats['cv_spatial_clustering']:.4f}\"),\n",
    "                    (f\"Max Local Density (W={gstats['window_size']:,} bp)\", f\"{gstats['max_local_density']:.6f}\"),\n",
    "                    ('Max Class Diversity',                  str(gstats['max_class_diversity_window'])),\n",
    "                    ('Max Cluster Score',                    f\"{gstats['max_cluster_score']:.6f}\"),\n",
    "                    ('Hybrid Regions',                       f\"{gstats['hybrid_count']:,}\"),\n",
    "                    ('Hybrid Coverage',                      f\"{gstats['hybrid_coverage_pct']:.4f}%\"),\n",
    "                    ('Cluster Regions',                      f\"{gstats['cluster_count']:,}\"),\n",
    "                    ('Cluster Coverage',                     f\"{gstats['cluster_coverage_pct']:.4f}%\"),\n",
    "                    ('Mean Overlap Fraction',                f\"{gstats['mean_overlap_fraction']:.4f}\"),\n",
    "                    ('Simpson Diversity Index (D)',          f\"{gstats['simpson_diversity_index']:.4f}\"),\n",
    "                    ('Effective Class Number (Neff)',        f\"{gstats['effective_class_number']:.4f}\"),\n",
    "                    ('SCI (Structural Complexity Index)',    f\"{gstats['sci']:.4f}\"),\n",
    "                    ('Structural Dominance Ratio',           f\"{gstats['dominance_ratio']:.4f}\"),\n",
    "                ]\n",
    "                _gs_df = pd.DataFrame(_gs_rows, columns=['Metric', 'Value'])\n",
    "                display(_gs_df)\n",
    "                _gs_df.to_csv(str(fdir/'comprehensive_genome_stats.csv'), encoding='utf-8-sig', index=False)\n",
    "            except Exception as _gse:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Comprehensive stats failed: {_gse}')\n",
    "\n",
    "            # 11. Linear motif track (class-level, genome-scale positional view)\n",
    "            try:\n",
    "                fig = plot_linear_motif_track(_motifs_list, total_bp, title=f'{stem} â€” Class Track')\n",
    "                _savefig(fig, fdir/'linear_motif_track.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Linear motif track: {_e}')\n",
    "\n",
    "            # 12. Linear subclass track\n",
    "            try:\n",
    "                _sm = [m for m in _motifs_list if m.get('Class') not in ('Hybrid', 'Non-B_DNA_Clusters')]\n",
    "                if _sm:\n",
    "                    fig = plot_linear_subclass_track(_sm, total_bp, title=f'{stem} â€” Subclass Track')\n",
    "                    _savefig(fig, fdir/'linear_subclass_track.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Subclass track: {_e}')\n",
    "\n",
    "            # 13. Nested pie chart (Class â†’ Subclass hierarchy)\n",
    "            try:\n",
    "                fig = plot_nested_pie_chart(_motifs_list, title=f'{stem} â€” Class \\u2192 Subclass')\n",
    "                _savefig(fig, fdir/'nested_pie_chart.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Nested pie chart: {_e}')\n",
    "\n",
    "            # 14. Length distribution KDE (by class)\n",
    "            try:\n",
    "                fig = plot_motif_length_kde(_motifs_list, by_class=True, title=f'{stem} â€” Length Distribution')\n",
    "                _savefig(fig, fdir/'length_kde.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Length KDE: {_e}')\n",
    "\n",
    "            # 15. Score violin (by class)\n",
    "            try:\n",
    "                fig = plot_score_violin(_motifs_list, by_class=True, title=f'{stem} â€” Score Distribution')\n",
    "                _savefig(fig, fdir/'score_violin.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Score violin: {_e}')\n",
    "\n",
    "            # 16. Density comparison (genomic vs positional)\n",
    "            try:\n",
    "                _gd     = calculate_genomic_density(_motifs_list, total_bp, by_class=True)\n",
    "                _pd_kbp = calculate_positional_density(_motifs_list, total_bp, unit='kbp', by_class=True)\n",
    "                if _gd and _pd_kbp:\n",
    "                    fig = plot_density_comparison(_gd, _pd_kbp, title=f'{stem} â€” Density Analysis')\n",
    "                    _savefig(fig, fdir/'density_comparison_advanced.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Density comparison: {_e}')\n",
    "\n",
    "            # 17. Structural potential heatmap\n",
    "            try:\n",
    "                fig = plot_structural_heatmap(_motifs_list, total_bp, title=f'{stem} â€” Structural Potential Heatmap')\n",
    "                _savefig(fig, fdir/'structural_heatmap.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Structural heatmap: {_e}')\n",
    "\n",
    "            # 18. Motif co-occurrence network\n",
    "            try:\n",
    "                fig = plot_motif_network(_motifs_list, title=f'{stem} â€” Motif Co-occurrence Network')\n",
    "                _savefig(fig, fdir/'motif_network.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Motif network: {_e}')\n",
    "\n",
    "            # 19. Co-occurrence matrix\n",
    "            try:\n",
    "                fig = plot_motif_cooccurrence_matrix(_motifs_list, title=f'{stem} â€” Co-occurrence Matrix')\n",
    "                _savefig(fig, fdir/'cooccurrence_matrix.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Co-occurrence matrix: {_e}')\n",
    "\n",
    "            # 20. Chromosome density (motif density by class)\n",
    "            try:\n",
    "                fig = plot_chromosome_density(_motifs_list, title=f'{stem} â€” Motif Density by Class')\n",
    "                _savefig(fig, fdir/'chromosome_density.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Chromosome density: {_e}')\n",
    "\n",
    "            # 21. Inter-motif clustering distance\n",
    "            try:\n",
    "                fig = plot_motif_clustering_distance(_motifs_list, title=f'{stem} â€” Inter-Motif Distance')\n",
    "                _savefig(fig, fdir/'clustering_distance.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Clustering distance: {_e}')\n",
    "\n",
    "            # 22. Structural features (spacer / loop variation)\n",
    "            try:\n",
    "                fig = plot_spacer_loop_variation(_motifs_list, title=f'{stem} â€” Structural Features Distribution')\n",
    "                _savefig(fig, fdir/'spacer_loop_variation.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Spacer/loop variation: {_e}')\n",
    "\n",
    "            # 23. Structural competition (UpSet plot)\n",
    "            try:\n",
    "                fig = plot_structural_competition_upset(_motifs_list, title=f'{stem} â€” Structural Competition')\n",
    "                _savefig(fig, fdir/'structural_competition_upset.png')\n",
    "            except Exception as _e:\n",
    "                tqdm.write(f'  \\u26a0\\ufe0f  Structural competition upset: {_e}')\n",
    "\n",
    "            # 24. Cluster size distribution (when Hybrid/Cluster motifs are present)\n",
    "            if not df[df['Class'].isin(['Hybrid', 'Non-B_DNA_Clusters'])].empty:\n",
    "                try:\n",
    "                    fig = plot_cluster_size_distribution(_motifs_list, title=f'{stem} â€” Cluster Statistics')\n",
    "                    _savefig(fig, fdir/'cluster_size_distribution.png')\n",
    "                except Exception as _e:\n",
    "                    tqdm.write(f'  \\u26a0\\ufe0f  Cluster size distribution: {_e}')\n",
    "\n",
    "            tqdm.write(f'  \\U0001f4ca Plots saved: {fdir}')\n",
    "\n",
    "        RESULTS_BY_FILE[stem] = {\n",
    "            'df':df, 'folder':fdir, 'file_type':ftype,\n",
    "            'path':fasta_path, 'seq_lengths':sl_map\n",
    "        }\n",
    "\n",
    "        # GFF region analysis\n",
    "        if fasta_path in GFF_MAP:\n",
    "            gff_path = GFF_MAP[fasta_path]\n",
    "            tqdm.write(f'  \\U0001f4cb GFF: {Path(gff_path).name}')\n",
    "            features = _parse_gff(gff_path)\n",
    "            gff_dir  = fdir/'gff_regions'; gff_dir.mkdir(exist_ok=True)\n",
    "            region_rows = []\n",
    "            for ftype_gff in tqdm(sorted({f['type'] for f in features}),\n",
    "                                  desc=f'  GFF({stem})', leave=False):\n",
    "                type_feats  = [f for f in features if f['type']==ftype_gff]\n",
    "                type_motifs = []\n",
    "                for feat in type_feats:\n",
    "                    sid = feat['seqid']\n",
    "                    if sid not in seqs: continue\n",
    "                    rseq = seqs[sid][feat['start']:feat['end']]\n",
    "                    if len(rseq) < 12: continue\n",
    "                    rname = f\"{sid}:{ftype_gff}:{feat['start']}-{feat['end']}({feat['strand']})\"\n",
    "                    for m in _scan(rname, rseq):\n",
    "                        m.update({'GFF_Type':ftype_gff,'GFF_SeqID':sid,\n",
    "                                   'GFF_Start':feat['start'],'GFF_End':feat['end'],\n",
    "                                   'GFF_Strand':feat['strand'],\n",
    "                                   'GFF_Attrs':feat['attrs'][:80]})\n",
    "                        type_motifs.append(m)\n",
    "                region_rows.extend(type_motifs)\n",
    "                gc.collect()\n",
    "            gff_df = pd.DataFrame(region_rows) if region_rows else pd.DataFrame()\n",
    "            for col, dflt in [('Class','Unknown'),('Subclass','Other'),('Start',0),\n",
    "                              ('End',0),('Length',0),('Score',0.0),\n",
    "                              ('GFF_Type',''),('GFF_SeqID',''),('GFF_Start',0),\n",
    "                              ('GFF_End',0),('GFF_Strand','+'),('GFF_Attrs','')]:\n",
    "                if col not in gff_df.columns: gff_df[col] = dflt\n",
    "            if not gff_df.empty:\n",
    "                gff_df.to_csv(str(gff_dir/'gff_region_motifs.csv'), encoding='utf-8-sig', index=False)\n",
    "                pivot = gff_df.groupby(['GFF_Type','Class']).size().unstack(fill_value=0)\n",
    "                fig, ax = plt.subplots(figsize=(max(8,len(pivot)*1.4), 5))\n",
    "                pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n",
    "                ax.set_xlabel('GFF Feature Type'); ax.set_ylabel('Motif Count')\n",
    "                ax.set_title(f'{stem} â€” Motifs per GFF Feature Type')\n",
    "                ax.legend(title='Class', bbox_to_anchor=(1,1)); plt.tight_layout()\n",
    "                _savefig(fig, gff_dir/'gff_motifs_by_type.png', show=False)\n",
    "            GFF_RESULTS[stem] = {'region_df':gff_df,'gff_path':gff_path,'folder':gff_dir}\n",
    "            tqdm.write(f'  \\u2705 GFF: {len(gff_df):,} region motifs')\n",
    "\n",
    "    print(f'\\n\\u2705 Detection complete â€” {len(RESULTS_BY_FILE)} file(s) '\n",
    "          f'({len(GFF_RESULTS)} with GFF)')\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # B. MASTER TABLES & GLOBAL STATISTICS\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    _dfs       = [r['df'] for r in RESULTS_BY_FILE.values() if not r['df'].empty]\n",
    "    _master_df = pd.concat(_dfs, ignore_index=True) if _dfs else pd.DataFrame()\n",
    "    _master_dir = _BASE / '_master'; _master_dir.mkdir(exist_ok=True)\n",
    "    _gdfs   = [v['region_df'] for v in GFF_RESULTS.values() if not v['region_df'].empty]\n",
    "    _gff_df = pd.concat(_gdfs, ignore_index=True) if _gdfs else pd.DataFrame()\n",
    "    _tables = {}\n",
    "\n",
    "    if not _master_df.empty:\n",
    "        total_bp_all = max(sum(sum(r['seq_lengths'].values())\n",
    "                               for r in RESULTS_BY_FILE.values()), 1)\n",
    "\n",
    "        # Table 1: Global class distribution (file Ã— class counts)\n",
    "        _tables['1_global_class_distribution'] = (\n",
    "            _master_df.groupby(['Source_File','File_Type','Class'])\n",
    "            .size().reset_index(name='Count'))\n",
    "\n",
    "        # Table 2: Per-file summary\n",
    "        _pf_rows = []\n",
    "        for stem, res in RESULTS_BY_FILE.items():\n",
    "            df, fp, ftype_v, sl = res['df'], res['path'], res['file_type'], res['seq_lengths']\n",
    "            gc_pct, seq_len = _gc_and_length(fp)\n",
    "            n = len(df)\n",
    "            _pf_rows.append({\n",
    "                'File':           Path(fp).name,\n",
    "                'File_Type':      ftype_v,\n",
    "                'Sequences':      len(sl),\n",
    "                'Total_bp':       seq_len,\n",
    "                'GC_Percent':     gc_pct,\n",
    "                'Total_Motifs':   n,\n",
    "                'Classes':        df['Class'].nunique()    if not df.empty else 0,\n",
    "                'Subclasses':     df['Subclass'].nunique() if not df.empty else 0,\n",
    "                'Hybrids':        int((df['Class']=='Hybrid').sum())             if not df.empty else 0,\n",
    "                'Clusters':       int((df['Class']=='Non-B_DNA_Clusters').sum()) if not df.empty else 0,\n",
    "                'Density_per_kb': round(n/seq_len*1000,4) if seq_len else 0.0,\n",
    "                'Coverage_pct':   _coverage(df, sl),\n",
    "            })\n",
    "        _tables['2_per_file_summary'] = pd.DataFrame(_pf_rows)\n",
    "\n",
    "        # Table 3: Class statistics WITH density and coverage\n",
    "        _cls_dc = _class_density_coverage(_master_df, RESULTS_BY_FILE)\n",
    "        _tables['3_class_statistics'] = (\n",
    "            _master_df.groupby('Class')\n",
    "            .agg(Total_Count=('Class','count'),\n",
    "                 Mean_Length=('Length','mean'),\n",
    "                 Mean_Score=('Score','mean'))\n",
    "            .round(3).reset_index()\n",
    "            .assign(Density_per_kb=lambda d: d['Class'].map(\n",
    "                        lambda c: _cls_dc.get(c,{}).get('Density_per_kb',0)),\n",
    "                    Coverage_pct=lambda d: d['Class'].map(\n",
    "                        lambda c: _cls_dc.get(c,{}).get('Coverage_pct',0)))\n",
    "            .sort_values('Total_Count', ascending=False)\n",
    "            [['Class','Total_Count','Mean_Length','Mean_Score','Density_per_kb','Coverage_pct']]\n",
    "        )\n",
    "\n",
    "        # Table 4: File Ã— Class pivot (counts)\n",
    "        _tables['4_file_class_pivot'] = (\n",
    "            _master_df.groupby(['Source_File','Class'])\n",
    "            .size().unstack(fill_value=0).reset_index())\n",
    "\n",
    "        # Table 5: Subclass statistics WITH density and coverage\n",
    "        _sc_dc = _subclass_density_coverage(_master_df, RESULTS_BY_FILE)\n",
    "        _tables['5_subclass_statistics'] = (\n",
    "            _master_df.groupby('Subclass')\n",
    "            .agg(Total_Count=('Subclass','count'),\n",
    "                 Mean_Length=('Length','mean'),\n",
    "                 Mean_Score=('Score','mean'))\n",
    "            .round(3).reset_index()\n",
    "            .assign(Density_per_kb=lambda d: d['Subclass'].map(\n",
    "                        lambda s: _sc_dc.get(s,{}).get('Density_per_kb',0)),\n",
    "                    Coverage_pct=lambda d: d['Subclass'].map(\n",
    "                        lambda s: _sc_dc.get(s,{}).get('Coverage_pct',0)))\n",
    "            .sort_values('Total_Count', ascending=False)\n",
    "            [['Subclass','Total_Count','Mean_Length','Mean_Score','Density_per_kb','Coverage_pct']]\n",
    "        )\n",
    "\n",
    "        # Table 6: Class density pivot (density per file per class)\n",
    "        _dens_rows_t = []\n",
    "        for (fname, cls), grp in _master_df.groupby(['Source_File','Class']):\n",
    "            stem = Path(fname).stem\n",
    "            res  = RESULTS_BY_FILE.get(stem, {})\n",
    "            slen = max(sum(res.get('seq_lengths',{1:1}).values()),1)\n",
    "            _dens_rows_t.append({'Source_File':fname,'Class':cls,\n",
    "                                  'Density_per_kb':round(len(grp)/slen*1000,4)})\n",
    "        _tables['6_class_density_pivot'] = (\n",
    "            pd.DataFrame(_dens_rows_t)\n",
    "            .pivot_table(index='Source_File',columns='Class',\n",
    "                         values='Density_per_kb',fill_value=0).reset_index())\n",
    "\n",
    "        # Table 7: Class coverage pivot (coverage % per file per class)\n",
    "        _cov_rows_t = []\n",
    "        for fname in _master_df['Source_File'].unique():\n",
    "            stem = Path(fname).stem\n",
    "            res  = RESULTS_BY_FILE.get(stem)\n",
    "            if not res: continue\n",
    "            sub_file = _master_df[_master_df['Source_File']==fname]\n",
    "            slen = max(sum(res['seq_lengths'].values()),1)\n",
    "            for cls, grp in sub_file.groupby('Class'):\n",
    "                cov = sum(_merge_coverage(sg[['Start','End']].values, cap=res['seq_lengths'].get(sn,0))\n",
    "                          for sn, sg in grp.groupby('Sequence_Name'))\n",
    "                _cov_rows_t.append({'Source_File':fname,'Class':cls,\n",
    "                                     'Coverage_pct':round(cov/slen*100,3)})\n",
    "        _tables['7_class_coverage_pivot'] = (\n",
    "            pd.DataFrame(_cov_rows_t)\n",
    "            .pivot_table(index='Source_File',columns='Class',\n",
    "                         values='Coverage_pct',fill_value=0).reset_index())\n",
    "\n",
    "        # Equal-length positional table\n",
    "        _eq_dfs = [r['df'] for r in RESULTS_BY_FILE.values()\n",
    "                   if r['file_type']=='multi_equal' and not r['df'].empty]\n",
    "        if _eq_dfs:\n",
    "            _eq = pd.concat(_eq_dfs, ignore_index=True)\n",
    "            _tables['8_equal_length_positional'] = (\n",
    "                _eq.groupby(['Source_File','Class','Start'])\n",
    "                .size().reset_index(name='Frequency')\n",
    "                .sort_values(['Source_File','Class','Frequency'], ascending=[True,True,False]))\n",
    "\n",
    "    if not _gff_df.empty:\n",
    "        _tables['9_gff_motifs_per_feature'] = (\n",
    "            _gff_df.groupby(['GFF_Type','Class']).size().reset_index(name='Count')\n",
    "            .sort_values('Count',ascending=False))\n",
    "        _tables['10_gff_density_per_feature'] = (\n",
    "            _gff_df.assign(Region_Len=(_gff_df['GFF_End']-_gff_df['GFF_Start']).clip(lower=1))\n",
    "            .groupby('GFF_Type')\n",
    "            .agg(Total_Motifs=('Class','count'),Unique_Classes=('Class','nunique'),\n",
    "                 Mean_Region_Len=('Region_Len','mean'))\n",
    "            .round(2).reset_index().sort_values('Total_Motifs',ascending=False))\n",
    "\n",
    "    # Export all tables + master CSVs\n",
    "    if not _master_df.empty:\n",
    "        _master_df.to_csv(str(_master_dir/'master_motifs.csv'), encoding='utf-8-sig', index=False)\n",
    "        _master_df.to_excel(str(_master_dir/'master_motifs.xlsx'), index=False)\n",
    "    if not _gff_df.empty:\n",
    "        _gff_df.to_csv(str(_master_dir/'gff_region_motifs_all.csv'), encoding='utf-8-sig', index=False)\n",
    "    for tname, tdf in _tables.items():\n",
    "        tdf.to_csv(str(_master_dir/f'{tname}.csv'), encoding='utf-8-sig', index=False)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # C. GLOBAL SUMMARY PLOTS (all inline)\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if not _master_df.empty:\n",
    "        _pf_summary = _tables.get('2_per_file_summary', pd.DataFrame())\n",
    "        _n_files    = len(RESULTS_BY_FILE)\n",
    "\n",
    "        # (a) Global class distribution\n",
    "        cc = _master_df['Class'].value_counts()\n",
    "        fig, ax = plt.subplots(figsize=(8, max(3, len(cc)*0.45)))\n",
    "        ax.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n",
    "        ax.set_xlabel('Count'); ax.set_title('Global Class Distribution')\n",
    "        for i,v in enumerate(cc.values[::-1]): ax.text(v+0.3, i, str(v), va='center', fontsize=8)\n",
    "        plt.tight_layout(); _savefig(fig, _master_dir/'global_class_distribution.png')\n",
    "\n",
    "        # (b) Global class density (motifs/kb)\n",
    "        cls_stat = _tables['3_class_statistics'].set_index('Class')['Density_per_kb']\n",
    "        fig, ax = plt.subplots(figsize=(8, max(3, len(cls_stat)*0.45)))\n",
    "        ax.barh(cls_stat.index[::-1], cls_stat.values[::-1], color='teal')\n",
    "        ax.set_xlabel('Motifs per kb'); ax.set_title('Global Class Density (motifs/kb)')\n",
    "        for i,v in enumerate(cls_stat.values[::-1]): ax.text(v, i, f'{v:.4f}', va='center', fontsize=8)\n",
    "        plt.tight_layout(); _savefig(fig, _master_dir/'global_class_density.png')\n",
    "\n",
    "        # (c) Global class coverage (%)\n",
    "        cls_cov_s = _tables['3_class_statistics'].set_index('Class')['Coverage_pct']\n",
    "        fig, ax = plt.subplots(figsize=(8, max(3, len(cls_cov_s)*0.45)))\n",
    "        ax.barh(cls_cov_s.index[::-1], cls_cov_s.values[::-1], color='mediumseagreen')\n",
    "        ax.set_xlabel('Coverage (%)'); ax.set_title('Global Class Coverage (%)')\n",
    "        for i,v in enumerate(cls_cov_s.values[::-1]): ax.text(v, i, f'{v:.3f}%', va='center', fontsize=8)\n",
    "        plt.tight_layout(); _savefig(fig, _master_dir/'global_class_coverage.png')\n",
    "\n",
    "        # (d) Global subclass distribution (top 30)\n",
    "        sc_all = _master_df['Subclass'].value_counts().head(30)\n",
    "        fig, ax = plt.subplots(figsize=(8, max(4, len(sc_all)*0.4)))\n",
    "        ax.barh(sc_all.index[::-1], sc_all.values[::-1], color='darkorange')\n",
    "        ax.set_xlabel('Count'); ax.set_title('Global Subclass Distribution (top 30)')\n",
    "        plt.tight_layout(); _savefig(fig, _master_dir/'global_subclass_distribution.png')\n",
    "\n",
    "        # (e) Global subclass density (top 20)\n",
    "        sc_dens_all = _tables['5_subclass_statistics'].set_index('Subclass')['Density_per_kb'].nlargest(20)\n",
    "        fig, ax = plt.subplots(figsize=(8, max(3, len(sc_dens_all)*0.4)))\n",
    "        ax.barh(sc_dens_all.index[::-1], sc_dens_all.values[::-1], color='coral')\n",
    "        ax.set_xlabel('Motifs per kb'); ax.set_title('Global Subclass Density (top 20, motifs/kb)')\n",
    "        plt.tight_layout(); _savefig(fig, _master_dir/'global_subclass_density.png')\n",
    "\n",
    "        # (f) Global subclass coverage (top 20)\n",
    "        sc_cov_all = _tables['5_subclass_statistics'].set_index('Subclass')['Coverage_pct'].nlargest(20)\n",
    "        fig, ax = plt.subplots(figsize=(8, max(3, len(sc_cov_all)*0.4)))\n",
    "        ax.barh(sc_cov_all.index[::-1], sc_cov_all.values[::-1], color='orchid')\n",
    "        ax.set_xlabel('Coverage (%)'); ax.set_title('Global Subclass Coverage (top 20, %)')\n",
    "        plt.tight_layout(); _savefig(fig, _master_dir/'global_subclass_coverage.png')\n",
    "\n",
    "        # (g) File-level density & coverage comparison\n",
    "        if not _pf_summary.empty:\n",
    "            for col, label, color, title in [\n",
    "                ('Density_per_kb','Motifs per kb','steelblue','Motif Density Comparison Across Files'),\n",
    "                ('Coverage_pct',  'Coverage (%)','mediumseagreen','Non-B DNA Coverage Comparison Across Files'),\n",
    "            ]:\n",
    "                _pfs = _pf_summary.sort_values(col, ascending=False)\n",
    "                fig, ax = plt.subplots(figsize=(max(6, len(_pfs)*1.4), 4))\n",
    "                bars = ax.bar(_pfs['File'].apply(lambda x: Path(x).stem[:25]),\n",
    "                              _pfs[col], color=color)\n",
    "                ax.bar_label(bars, fmt='%.3f' if col=='Density_per_kb' else '%.1f%%',\n",
    "                             padding=2, fontsize=8)\n",
    "                ax.set_ylabel(label); ax.set_title(title)\n",
    "                if col=='Coverage_pct': ax.set_ylim(0,100)\n",
    "                plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n",
    "                _savefig(fig, _master_dir/f'{\"density\" if col==\"Density_per_kb\" else \"coverage\"}_comparison.png')\n",
    "\n",
    "        # (h) Class density heatmap (files Ã— classes)\n",
    "        if '6_class_density_pivot' in _tables and not _tables['6_class_density_pivot'].empty:\n",
    "            _dens_piv = _tables['6_class_density_pivot'].set_index('Source_File')\n",
    "            if not _dens_piv.empty:\n",
    "                fig, ax = plt.subplots(figsize=(max(10, len(_dens_piv.columns)*1.2),\n",
    "                                                max(4,  len(_dens_piv)*0.7)))\n",
    "                sns.heatmap(_dens_piv, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,\n",
    "                            linewidths=0.4, cbar_kws={'label':'Motifs per kb'})\n",
    "                ax.set_title('Class Density Heatmap (motifs/kb) â€” Files Ã— Classes')\n",
    "                ax.set_xlabel('Non-B Class'); ax.set_ylabel('File')\n",
    "                plt.tight_layout(); _savefig(fig, _master_dir/'class_density_heatmap.png')\n",
    "\n",
    "        # (i) Class coverage heatmap (files Ã— classes)\n",
    "        if '7_class_coverage_pivot' in _tables and not _tables['7_class_coverage_pivot'].empty:\n",
    "            _cov_piv = _tables['7_class_coverage_pivot'].set_index('Source_File')\n",
    "            if not _cov_piv.empty:\n",
    "                fig, ax = plt.subplots(figsize=(max(10, len(_cov_piv.columns)*1.2),\n",
    "                                                max(4,  len(_cov_piv)*0.7)))\n",
    "                sns.heatmap(_cov_piv, annot=True, fmt='.3f', cmap='Blues', ax=ax,\n",
    "                            linewidths=0.4, cbar_kws={'label':'Coverage %'})\n",
    "                ax.set_title('Class Coverage Heatmap (%) â€” Files Ã— Classes')\n",
    "                ax.set_xlabel('Non-B Class'); ax.set_ylabel('File')\n",
    "                plt.tight_layout(); _savefig(fig, _master_dir/'class_coverage_heatmap.png')\n",
    "\n",
    "        # (j) Hybrid & Cluster comparison\n",
    "        if not _pf_summary.empty and (_pf_summary['Hybrids'].sum()>0 or _pf_summary['Clusters'].sum()>0):\n",
    "            x = np.arange(len(_pf_summary)); w = 0.35\n",
    "            labels = _pf_summary['File'].apply(lambda x: Path(x).stem[:20])\n",
    "            fig, ax = plt.subplots(figsize=(max(7, len(_pf_summary)*1.5), 4))\n",
    "            ax.bar(x-w/2, _pf_summary['Hybrids'],  w, label='Hybrids',  color='tomato')\n",
    "            ax.bar(x+w/2, _pf_summary['Clusters'], w, label='Clusters', color='mediumpurple')\n",
    "            ax.set_xticks(x); ax.set_xticklabels(labels, rotation=30, ha='right')\n",
    "            ax.set_ylabel('Count'); ax.set_title('Hybrid & Cluster Motifs Across Files')\n",
    "            ax.legend(); plt.tight_layout()\n",
    "            _savefig(fig, _master_dir/'hybrid_cluster_comparison.png')\n",
    "\n",
    "        # (k) GFF heatmap\n",
    "        if not _gff_df.empty and '9_gff_motifs_per_feature' in _tables:\n",
    "            _piv = _gff_df.groupby(['GFF_Type','Class']).size().unstack(fill_value=0)\n",
    "            fig2, ax2 = plt.subplots(figsize=(max(10,len(_piv.columns)*1.2), max(4,len(_piv)*0.6)))\n",
    "            sns.heatmap(_piv, annot=True, fmt='d', cmap='YlOrRd', ax=ax2,\n",
    "                        linewidths=0.4, cbar_kws={'label':'Motif count'})\n",
    "            ax2.set_title('GFF Feature Type Ã— Non-B Class Heatmap')\n",
    "            ax2.set_xlabel('Non-B Class'); ax2.set_ylabel('GFF Feature Type')\n",
    "            plt.tight_layout(); _savefig(fig2, _master_dir/'gff_class_heatmap.png')\n",
    "\n",
    "        # (l) Global comprehensive genome statistics\n",
    "        _all_motifs_global = _master_df.to_dict('records')\n",
    "        _total_bp_global   = max(sum(sum(r['seq_lengths'].values()) for r in RESULTS_BY_FILE.values()), 1)\n",
    "        try:\n",
    "            gstats_global = compute_comprehensive_genome_stats(_all_motifs_global, _total_bp_global)\n",
    "            print('\\n' + '='*70)\n",
    "            print('GLOBAL COMPREHENSIVE GENOME STATISTICS')\n",
    "            print('='*70)\n",
    "            _gsg_rows = [\n",
    "                ('Genome Length',                        f\"{gstats_global['genome_length']:,} bp\"),\n",
    "                ('Motifs (excl. Hybrid/Cluster)',        f\"{gstats_global['n_motifs']:,}\"),\n",
    "                ('Motifs (incl. Hybrid/Cluster)',        f\"{gstats_global['n_motifs_all']:,}\"),\n",
    "                ('Motif Classes',                        str(gstats_global['n_classes'])),\n",
    "                ('Motif Density',                        f\"{gstats_global['density_per_kb']:.4f} / kb\"),\n",
    "                ('Total Covered Bases',                  f\"{gstats_global['total_covered_bases']:,} bp\"),\n",
    "                ('Coverage Fraction',                    f\"{gstats_global['coverage_fraction']:.6f}\"),\n",
    "                ('Coverage (%)',                         f\"{gstats_global['coverage_pct']:.4f}%\"),\n",
    "                ('Raw Occupancy',                        f\"{gstats_global['raw_occupancy_bp']:,} bp\"),\n",
    "                ('Normalized Occupancy (SLI)',           f\"{gstats_global['normalized_occupancy']:.6f}\"),\n",
    "                ('Mean Overlap Depth',                   f\"{gstats_global['mean_overlap_depth']:.4f}\"),\n",
    "                ('SLI',                                  f\"{gstats_global['sli']:.6f}\"),\n",
    "                ('Structural Intensity',                 f\"{gstats_global['structural_intensity']:.6f}\"),\n",
    "                ('Weighted Structural Coverage',         f\"{gstats_global['weighted_structural_coverage']:.6f}\"),\n",
    "                ('Mean Inter-Motif Distance',            f\"{gstats_global['mean_inter_motif_distance']:.2f} bp\"),\n",
    "                ('CV (Clustering Coefficient)',          f\"{gstats_global['cv_spatial_clustering']:.4f}\"),\n",
    "                (f\"Max Local Density (W={gstats_global['window_size']:,} bp)\", f\"{gstats_global['max_local_density']:.6f}\"),\n",
    "                ('Max Class Diversity',                  str(gstats_global['max_class_diversity_window'])),\n",
    "                ('Max Cluster Score',                    f\"{gstats_global['max_cluster_score']:.6f}\"),\n",
    "                ('Hybrid Regions',                       f\"{gstats_global['hybrid_count']:,}\"),\n",
    "                ('Hybrid Coverage',                      f\"{gstats_global['hybrid_coverage_pct']:.4f}%\"),\n",
    "                ('Cluster Regions',                      f\"{gstats_global['cluster_count']:,}\"),\n",
    "                ('Cluster Coverage',                     f\"{gstats_global['cluster_coverage_pct']:.4f}%\"),\n",
    "                ('Mean Overlap Fraction',                f\"{gstats_global['mean_overlap_fraction']:.4f}\"),\n",
    "                ('Simpson Diversity Index (D)',          f\"{gstats_global['simpson_diversity_index']:.4f}\"),\n",
    "                ('Effective Class Number (Neff)',        f\"{gstats_global['effective_class_number']:.4f}\"),\n",
    "                ('SCI (Structural Complexity Index)',    f\"{gstats_global['sci']:.4f}\"),\n",
    "                ('Structural Dominance Ratio',           f\"{gstats_global['dominance_ratio']:.4f}\"),\n",
    "            ]\n",
    "            _gsg_df = pd.DataFrame(_gsg_rows, columns=['Metric', 'Value'])\n",
    "            display(_gsg_df)\n",
    "            _gsg_df.to_csv(str(_master_dir/'global_comprehensive_genome_stats.csv'), encoding='utf-8-sig', index=False)\n",
    "        except Exception as _gse:\n",
    "            print(f'  \\u26a0\\ufe0f  Global comprehensive stats failed: {_gse}')\n",
    "\n",
    "        # (m) Global linear motif track\n",
    "        try:\n",
    "            fig = plot_linear_motif_track(_all_motifs_global, _total_bp_global, title='Global â€” Class Track')\n",
    "            _savefig(fig, _master_dir/'global_linear_motif_track.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global linear motif track: {_e}')\n",
    "\n",
    "        # (n) Global linear subclass track\n",
    "        try:\n",
    "            _gsm = [m for m in _all_motifs_global if m.get('Class') not in ('Hybrid', 'Non-B_DNA_Clusters')]\n",
    "            if _gsm:\n",
    "                fig = plot_linear_subclass_track(_gsm, _total_bp_global, title='Global â€” Subclass Track')\n",
    "                _savefig(fig, _master_dir/'global_linear_subclass_track.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global subclass track: {_e}')\n",
    "\n",
    "        # (o) Global nested pie chart (Class â†’ Subclass)\n",
    "        try:\n",
    "            fig = plot_nested_pie_chart(_all_motifs_global, title='Global â€” Class \\u2192 Subclass')\n",
    "            _savefig(fig, _master_dir/'global_nested_pie_chart.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global nested pie chart: {_e}')\n",
    "\n",
    "        # (p) Global length distribution KDE\n",
    "        try:\n",
    "            fig = plot_motif_length_kde(_all_motifs_global, by_class=True, title='Global â€” Length Distribution')\n",
    "            _savefig(fig, _master_dir/'global_length_kde.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global length KDE: {_e}')\n",
    "\n",
    "        # (q) Global score violin\n",
    "        try:\n",
    "            fig = plot_score_violin(_all_motifs_global, by_class=True, title='Global â€” Score Distribution')\n",
    "            _savefig(fig, _master_dir/'global_score_violin.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global score violin: {_e}')\n",
    "\n",
    "        # (r) Global density comparison (genomic vs positional)\n",
    "        try:\n",
    "            _gd_g     = calculate_genomic_density(_all_motifs_global, _total_bp_global, by_class=True)\n",
    "            _pd_g_kbp = calculate_positional_density(_all_motifs_global, _total_bp_global, unit='kbp', by_class=True)\n",
    "            if _gd_g and _pd_g_kbp:\n",
    "                fig = plot_density_comparison(_gd_g, _pd_g_kbp, title='Global â€” Density Analysis')\n",
    "                _savefig(fig, _master_dir/'global_density_comparison_advanced.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global density comparison: {_e}')\n",
    "\n",
    "        # (s) Global structural potential heatmap\n",
    "        try:\n",
    "            fig = plot_structural_heatmap(_all_motifs_global, _total_bp_global, title='Global â€” Structural Potential Heatmap')\n",
    "            _savefig(fig, _master_dir/'global_structural_heatmap.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global structural heatmap: {_e}')\n",
    "\n",
    "        # (t) Global motif co-occurrence network\n",
    "        try:\n",
    "            fig = plot_motif_network(_all_motifs_global, title='Global â€” Motif Co-occurrence Network')\n",
    "            _savefig(fig, _master_dir/'global_motif_network.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global motif network: {_e}')\n",
    "\n",
    "        # (u) Global co-occurrence matrix\n",
    "        try:\n",
    "            fig = plot_motif_cooccurrence_matrix(_all_motifs_global, title='Global â€” Co-occurrence Matrix')\n",
    "            _savefig(fig, _master_dir/'global_cooccurrence_matrix.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global co-occurrence matrix: {_e}')\n",
    "\n",
    "        # (v) Global chromosome density\n",
    "        try:\n",
    "            fig = plot_chromosome_density(_all_motifs_global, title='Global â€” Motif Density by Class')\n",
    "            _savefig(fig, _master_dir/'global_chromosome_density.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global chromosome density: {_e}')\n",
    "\n",
    "        # (w) Global inter-motif clustering distance\n",
    "        try:\n",
    "            fig = plot_motif_clustering_distance(_all_motifs_global, title='Global â€” Inter-Motif Distance')\n",
    "            _savefig(fig, _master_dir/'global_clustering_distance.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global clustering distance: {_e}')\n",
    "\n",
    "        # (x) Global structural features (spacer / loop variation)\n",
    "        try:\n",
    "            fig = plot_spacer_loop_variation(_all_motifs_global, title='Global â€” Structural Features Distribution')\n",
    "            _savefig(fig, _master_dir/'global_spacer_loop_variation.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global spacer/loop variation: {_e}')\n",
    "\n",
    "        # (y) Global structural competition (UpSet plot)\n",
    "        try:\n",
    "            fig = plot_structural_competition_upset(_all_motifs_global, title='Global â€” Structural Competition')\n",
    "            _savefig(fig, _master_dir/'global_structural_competition_upset.png')\n",
    "        except Exception as _e:\n",
    "            print(f'  \\u26a0\\ufe0f  Global structural competition upset: {_e}')\n",
    "\n",
    "        # (z) Global cluster size distribution\n",
    "        _has_global_clusters = any(m.get('Class') in ('Hybrid', 'Non-B_DNA_Clusters') for m in _all_motifs_global)\n",
    "        if _has_global_clusters:\n",
    "            try:\n",
    "                fig = plot_cluster_size_distribution(_all_motifs_global, title='Global â€” Cluster Statistics')\n",
    "                _savefig(fig, _master_dir/'global_cluster_size_distribution.png')\n",
    "            except Exception as _e:\n",
    "                print(f'  \\u26a0\\ufe0f  Global cluster size distribution: {_e}')\n",
    "\n",
    "    # Display all statistics tables\n",
    "    print('\\n' + '='*70)\n",
    "    print('ALL STATISTICS TABLES')\n",
    "    print('='*70)\n",
    "    for tname, tdf in _tables.items():\n",
    "        print(f\"\\n{'â”€'*60}\")\n",
    "        print(f\"  {tname.replace('_',' ').upper()}\")\n",
    "        print(f\"{'â”€'*60}\")\n",
    "        display(tdf)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # D. COMPARATIVE ANALYSIS\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    _comp_rows = []\n",
    "    for stem, res in RESULTS_BY_FILE.items():\n",
    "        species, region = _parse_species_region(stem)\n",
    "        df, fp, sl = res['df'], res['path'], res['seq_lengths']\n",
    "        gc_pct, seq_len = _gc_and_length(fp)\n",
    "        n = len(df)\n",
    "        _comp_rows.append({\n",
    "            'Stem':stem,'Species':species,'Region':region,\n",
    "            'Total_Motifs':n,'Seq_Length_bp':seq_len,\n",
    "            'Density_per_kb':round(n/seq_len*1000,4) if seq_len else 0.0,\n",
    "            'Coverage_pct':_coverage(df,sl),'GC_Percent':gc_pct,\n",
    "            'Mean_Motif_Length':  round(df['Length'].mean(),2)   if not df.empty else 0.0,\n",
    "            'Median_Motif_Length':round(df['Length'].median(),2) if not df.empty else 0.0,\n",
    "            'Unique_Classes':   df['Class'].nunique()    if not df.empty else 0,\n",
    "            'Unique_Subclasses':df['Subclass'].nunique() if not df.empty else 0,\n",
    "            'Hybrids':  int((df['Class']=='Hybrid').sum())             if not df.empty else 0,\n",
    "            'Clusters': int((df['Class']=='Non-B_DNA_Clusters').sum()) if not df.empty else 0,\n",
    "        })\n",
    "    _comp_df      = pd.DataFrame(_comp_rows)\n",
    "    _species_list = sorted(_comp_df['Species'].unique())\n",
    "    _region_list  = sorted(_comp_df['Region'].unique())\n",
    "    _cmp_dir = _BASE / '_comparisons'; _cmp_dir.mkdir(exist_ok=True)\n",
    "    _comp_df.to_csv(str(_cmp_dir/'all_comparisons_summary.csv'), encoding='utf-8-sig', index=False)\n",
    "    _comp_df.to_excel(str(_cmp_dir/'all_comparisons_summary.xlsx'), index=False)\n",
    "    print(f'\\nSpecies: {_species_list}  |  Regions: {_region_list}')\n",
    "\n",
    "    # Multi-file comparative plots\n",
    "    if len(RESULTS_BY_FILE) >= 2 and not _master_df.empty:\n",
    "        # Class comparison\n",
    "        _cls_pivot = _master_df.groupby(['Source_File','Class']).size().unstack(fill_value=0)\n",
    "        fig, ax = plt.subplots(figsize=(max(10,len(_cls_pivot)*1.4), max(4,len(_cls_pivot.columns)*0.5)))\n",
    "        _cls_pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n",
    "        ax.set_xlabel('File'); ax.set_ylabel('Motif Count')\n",
    "        ax.set_title('Class Distribution â€” All Files Comparison')\n",
    "        ax.legend(title='Class', bbox_to_anchor=(1,1), fontsize=8)\n",
    "        plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n",
    "        _savefig(fig, _cmp_dir/'all_files_class_comparison.png')\n",
    "\n",
    "        # Subclass comparison (top 20)\n",
    "        _top_subs = _master_df['Subclass'].value_counts().head(20).index\n",
    "        _sub_pivot = _master_df.groupby(['Source_File','Subclass']).size().unstack(fill_value=0)\n",
    "        _sub_pivot = _sub_pivot[[c for c in _top_subs if c in _sub_pivot.columns]]\n",
    "        if not _sub_pivot.empty:\n",
    "            fig, ax = plt.subplots(figsize=(max(10,len(_sub_pivot)*1.4), max(4,len(_sub_pivot.columns)*0.4)))\n",
    "            _sub_pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n",
    "            ax.set_xlabel('File'); ax.set_ylabel('Motif Count')\n",
    "            ax.set_title('Subclass Distribution â€” All Files (top 20)')\n",
    "            ax.legend(title='Subclass', bbox_to_anchor=(1,1), fontsize=7)\n",
    "            plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n",
    "            _savefig(fig, _cmp_dir/'all_files_subclass_comparison.png')\n",
    "\n",
    "    # Within-species comparisons\n",
    "    _sep = '\\u2550'*60\n",
    "    for species in _species_list:\n",
    "        sp_rows  = _comp_df[_comp_df['Species']==species].copy()\n",
    "        sp_stems = sp_rows['Stem'].tolist()\n",
    "        sp_dir   = _cmp_dir/_safe_fname(species); sp_dir.mkdir(exist_ok=True)\n",
    "        if len(sp_stems) < 2:\n",
    "            print(f\"\\n\\u26a0  '{species}' â€” single region, skipping within-species plots.\")\n",
    "            continue\n",
    "        print(f'\\n{_sep}\\nWithin-species: {species}\\n{_sep}')\n",
    "\n",
    "        # Class + subclass by region\n",
    "        for attr, label, fname, colors in [\n",
    "            ('Class',   'Class',   'class_by_region.png',   'tab20'),\n",
    "            ('Subclass','Subclass','subclass_by_region.png','tab20'),\n",
    "        ]:\n",
    "            _by_reg = {sp_rows.loc[sp_rows['Stem']==st,'Region'].values[0]:\n",
    "                       RESULTS_BY_FILE[st]['df'][attr].value_counts()\n",
    "                       if not RESULTS_BY_FILE[st]['df'].empty else pd.Series(dtype=int)\n",
    "                       for st in sp_stems}\n",
    "            _all_v = sorted({c for s in _by_reg.values() for c in s.index})\n",
    "            if not _all_v: continue\n",
    "            _mat = pd.DataFrame({r:s.reindex(_all_v,fill_value=0) for r,s in _by_reg.items()}).T\n",
    "            fig, ax = plt.subplots(figsize=(max(8,len(_all_v)*1.2),4))\n",
    "            _mat.plot(kind='bar', ax=ax, colormap=colors, width=0.8)\n",
    "            ax.set_title(f'{species} â€” {label} Distribution by Region')\n",
    "            ax.set_xlabel('Region'); ax.set_ylabel('Motif Count')\n",
    "            ax.legend(title=label, bbox_to_anchor=(1,1), fontsize=7)\n",
    "            plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n",
    "            _savefig(fig, sp_dir/fname, show=False)\n",
    "\n",
    "        # Density, coverage, GC, length by region\n",
    "        for col, label, color, fmt, ylim, fn in [\n",
    "            ('Density_per_kb','Motifs per kb',    'steelblue',     '%.3f', None, 'density_by_region.png'),\n",
    "            ('Coverage_pct',  'Coverage (%)',     'mediumseagreen','%.1f%%',(0,100),'coverage_by_region.png'),\n",
    "            ('GC_Percent',    'GC (%)',           'goldenrod',     '%.1f%%',(0,100),'gc_by_region.png'),\n",
    "        ]:\n",
    "            fig, ax = plt.subplots(figsize=(max(6,len(sp_rows)*1.2),4))\n",
    "            bars = ax.bar(sp_rows['Region'], sp_rows[col], color=color)\n",
    "            ax.bar_label(bars, fmt=fmt, padding=2)\n",
    "            ax.set_title(f'{species} â€” {label} by Region')\n",
    "            ax.set_xlabel('Region'); ax.set_ylabel(label)\n",
    "            if ylim: ax.set_ylim(*ylim)\n",
    "            plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n",
    "            _savefig(fig, sp_dir/fn, show=False)\n",
    "\n",
    "        # Motif length boxplot\n",
    "        _len_parts = []\n",
    "        for st in sp_stems:\n",
    "            df = RESULTS_BY_FILE[st]['df']\n",
    "            reg = sp_rows.loc[sp_rows['Stem']==st,'Region'].values[0]\n",
    "            if not df.empty and 'Length' in df.columns:\n",
    "                tmp = df[['Length']].copy(); tmp['Region'] = reg; _len_parts.append(tmp)\n",
    "        if _len_parts:\n",
    "            _len_df = pd.concat(_len_parts)[lambda d: d['Length']>0]\n",
    "            if not _len_df.empty:\n",
    "                fig, ax = plt.subplots(figsize=(max(8,len(sp_stems)*2),4))\n",
    "                sns.boxplot(data=_len_df, x='Region', y='Length', ax=ax, palette='Set2')\n",
    "                ax.set_title(f'{species} â€” Motif Length Distribution by Region')\n",
    "                plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n",
    "                _savefig(fig, sp_dir/'length_by_region.png', show=False)\n",
    "\n",
    "        _sp_summary = sp_rows.set_index('Region')[[\n",
    "            'Total_Motifs','Seq_Length_bp','Density_per_kb','Coverage_pct',\n",
    "            'GC_Percent','Mean_Motif_Length','Median_Motif_Length',\n",
    "            'Unique_Classes','Unique_Subclasses','Hybrids','Clusters',\n",
    "        ]]\n",
    "        _sp_summary.to_csv(str(sp_dir/'within_species_summary.csv'), encoding='utf-8-sig')\n",
    "        print(f'{species} Summary:'); display(_sp_summary)\n",
    "\n",
    "    # Cross-species\n",
    "    if len(_species_list) >= 2:\n",
    "        _xs_dir = _cmp_dir/'_cross_species'; _xs_dir.mkdir(exist_ok=True)\n",
    "        print(f'\\n{_sep}\\nCross-species: {_species_list}\\n{_sep}')\n",
    "        _all_regs = sorted(set.union(*[set(_comp_df[_comp_df['Species']==sp]['Region'])\n",
    "                                       for sp in _species_list]))\n",
    "        for col, label, cmap, fmt, fn in [\n",
    "            ('Density_per_kb','Motifs/kb','YlOrRd','.3f','cross_species_density_heatmap.png'),\n",
    "            ('Coverage_pct',  'Coverage %','Blues', '.1f','cross_species_coverage_heatmap.png'),\n",
    "            ('GC_Percent',    'GC %',     'YlGn',  '.1f','cross_species_gc_heatmap.png'),\n",
    "        ]:\n",
    "            _piv = _comp_df.pivot_table(index='Species',columns='Region',values=col,aggfunc='mean')\n",
    "            if not _piv.empty:\n",
    "                fig, ax = plt.subplots(figsize=(max(8,len(_all_regs)*1.4), max(4,len(_species_list)*0.8)))\n",
    "                sns.heatmap(_piv, annot=True, fmt=fmt, cmap=cmap, ax=ax,\n",
    "                            linewidths=0.4, cbar_kws={'label':label})\n",
    "                ax.set_title(f'Cross-Species â€” {label} Heatmap')\n",
    "                ax.set_xlabel('Region'); ax.set_ylabel('Species')\n",
    "                plt.tight_layout(); _savefig(fig, _xs_dir/fn, show=False)\n",
    "        _xs_summary = _comp_df.sort_values(['Species','Region'])\n",
    "        _xs_summary.to_csv(str(_xs_dir/'cross_species_summary.csv'), encoding='utf-8-sig', index=False)\n",
    "        print('Cross-Species Summary:'); display(_xs_summary)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # E. DOWNLOAD LINKS\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    import base64\n",
    "\n",
    "    _MIME = {'csv':'text/csv',\n",
    "             'xlsx':'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
    "             'png':'image/png'}\n",
    "\n",
    "    def _dl(path, label):\n",
    "        with open(path,'rb') as fh: b64 = base64.b64encode(fh.read()).decode()\n",
    "        ext  = Path(path).suffix.lstrip('.')\n",
    "        mime = _MIME.get(ext,'application/octet-stream')\n",
    "        return (f'<a href=\"data:{mime};base64,{b64}\" download=\"{Path(path).name}\" '\n",
    "                f'style=\"margin:2px 6px;padding:3px 8px;border:1px solid #aaa;'\n",
    "                f'border-radius:4px;text-decoration:none;\">{label}</a>')\n",
    "\n",
    "    _html = ['<h2>\\U0001f4e5 Downloads</h2><h3>Master Outputs</h3><div>']\n",
    "    for fmt, fn in [('CSV','master_motifs.csv'),('Excel','master_motifs.xlsx')]:\n",
    "        p = _master_dir/fn\n",
    "        if p.exists(): _html.append(_dl(str(p), f'Master {fmt}'))\n",
    "    if (_master_dir/'gff_region_motifs_all.csv').exists():\n",
    "        _html.append(_dl(str(_master_dir/'gff_region_motifs_all.csv'),'GFF Regions CSV'))\n",
    "    if (_master_dir/'global_comprehensive_genome_stats.csv').exists():\n",
    "        _html.append(_dl(str(_master_dir/'global_comprehensive_genome_stats.csv'),'Global Comprehensive Stats CSV'))\n",
    "    _html.append('</div><h3>Statistics Tables</h3><div>')\n",
    "    for tn in _tables:\n",
    "        p = _master_dir/f'{tn}.csv'\n",
    "        if p.exists(): _html.append(_dl(str(p), tn.replace('_',' ').title()))\n",
    "    _html.append('</div><h3>Comparative Analysis</h3><div>')\n",
    "    for fn in ['all_comparisons_summary.csv','all_comparisons_summary.xlsx']:\n",
    "        p = _cmp_dir/fn\n",
    "        if p.exists(): _html.append(_dl(str(p), fn))\n",
    "    _html.append('</div><h3>Per-File Outputs</h3>')\n",
    "    for stem, res in RESULTS_BY_FILE.items():\n",
    "        _html.append(f'<details style=\"margin:4px 0\"><summary><b>{stem}</b> '\n",
    "                     f'<em>[{res[\"file_type\"]}]</em></summary><div style=\"margin:4px 12px\">')\n",
    "        for fmt, fn in [('CSV','motifs.csv'),('Excel','motifs.xlsx')]:\n",
    "            p = res['folder']/fn\n",
    "            if p.exists(): _html.append(_dl(str(p), fmt))\n",
    "        for fn in sorted(res['folder'].glob('*.png')):\n",
    "            _html.append(_dl(str(fn), fn.stem.replace('_',' ').title()))\n",
    "        _html.append('</div></details>')\n",
    "\n",
    "    display(HTML('\\n'.join(_html)))\n",
    "    print(f'\\n\\u2705 All outputs saved to: {_BASE}')\n",
    "\n",
    ""
   ]
  }
 ]
}