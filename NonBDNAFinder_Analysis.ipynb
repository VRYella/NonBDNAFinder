{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nbdna-overview",
   "metadata": {},
   "source": "# NonBDNA Finder — Analysis Notebook\n\n## Overview\n\nThis notebook detects and analyses **Non-B DNA structural motifs** in one or more FASTA files using the **NonBDNAFinder** suite.  \nRun the single code cell below to perform the complete analysis.\n\n---\n\n## Detectors — 9 classes, 23+ subclasses\n\n| Class | Method | Key Subclasses |\n|---|---|---|\n| Curved DNA | A-tract phasing | Curved, Bent |\n| Slipped DNA | K-mer indexing | Direct-repeat, Mirror |\n| Cruciform | Inverted repeat detection | Cruciform |\n| R-Loop | QmRLFS algorithm | R-loop, G-rich, C-rich |\n| Triplex | Mirror repeat + purine runs | H-DNA, R·R·Y, Y·R·Y |\n| G-Quadruplex | G4Hunter + 7 pattern models | G4, Parallel, Anti-parallel… |\n| i-Motif | C-run patterns | iM-Canonical, iM-Partial, iM-C-rich |\n| Z-DNA | CG/CA repeat scoring | ZH-score, CG-repeat |\n| A-philic DNA | 10-mer A-tract patterns | A-philic |\n| **Hybrid** | Overlapping-motif detection | Class₁\\_Class₂\\_Overlap |\n| **Non-B Clusters** | Dense multi-motif windows | Mixed\\_Cluster\\_N\\_classes |\n\n---\n\n## What this notebook produces\n\n### Per-file outputs (saved under `OUTPUT_DIR/<timestamp>/<stem>/`)\n| File | Contents |\n|---|---|\n| `motifs.csv` | Every detected motif with Class, Subclass, position, score |\n| `motifs.xlsx` | Same data in Excel format |\n| `class_distribution.png` | Horizontal bar chart — motif counts per class |\n| `subclass_distribution.png` | Horizontal bar chart — motif counts per subclass |\n| `hybrid_cluster_breakdown.png` | Bar chart — Hybrid and Cluster motif counts |\n| `motif_density_by_sequence.png` | Motifs-per-kb for each sequence (multi-sequence files) |\n| `sequence_coverage.png` | Fraction of each sequence covered by Non-B DNA |\n| `positional_distribution_<class>.png` | Positional frequency along fixed-length sequences (**equal-length multiFASTA only**) |\n\n### Master outputs (saved under `OUTPUT_DIR/<timestamp>/_master/`)\n| File | Contents |\n|---|---|\n| `master_motifs.csv / .xlsx` | Combined motif table across **all** input files |\n| `1_global_class_distribution.csv` | Motif counts by file × class |\n| `2_per_file_summary.csv` | Per-file totals (sequences, motifs, classes, hybrids, clusters, coverage, density) |\n| `3_class_statistics.csv` | Mean length & score per class |\n| `4_file_class_pivot.csv` | Pivot: files × classes |\n| `5_subclass_statistics.csv` | Mean length & score per subclass |\n| `6_equal_length_positional.csv` | Positional frequency table (equal-length multiFASTA) |\n| `master_summary.png` | Global class distribution + file-type breakdown + motifs-per-file |\n| `density_comparison.png` | Motif density (motifs per kb) across all input files |\n| `coverage_comparison.png` | Sequence coverage (%) across all input files |\n| `hybrid_cluster_comparison.png` | Hybrid and Cluster counts across all input files |\n\n### Comparative analysis (saved under `OUTPUT_DIR/<timestamp>/_comparisons/`)\nActivated automatically when **≥ 2 files** are present.  \nUses `Species_region.fasta` filename convention when available.\n\n| Plot | Contents |\n|---|---|\n| `all_comparisons_summary.csv / .xlsx` | Per-file density, GC%, motif lengths |\n| Within-species plots | Class dist, subclass dist, density, coverage, length dist, GC% |\n| Cross-species heatmaps | Density × region, GC% × region, class comparison per region |\n\n---\n\n## How to use\n\n1. **Edit `FASTA_INPUT`** — a file path, a glob pattern (`*.fasta`), or a Python list of paths/patterns.  \n2. **Edit `OUTPUT_DIR`** — destination folder (default: `notebook_reports`).  \n3. Optionally restrict detectors with **`ENABLED_CLASSES`** (e.g. `['G-Quadruplex','Z-DNA']`).  \n4. **Run the code cell** below — the full analysis runs automatically.\n\n> Results are written to `OUTPUT_DIR/<timestamp>/`.  No internet access is required.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nbdna-analysis",
   "metadata": {},
   "outputs": [],
   "source": "# ═══════════════════════════════════════════════════════════════════════════════\n# NonBDNAFinder — Complete Analysis\n# Edit FASTA_INPUT and OUTPUT_DIR, then run this cell.\n# ═══════════════════════════════════════════════════════════════════════════════\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 0.  IMPORTS, PACKAGES, CONFIGURATION\n# ─────────────────────────────────────────────────────────────────────────────\nimport sys, os, importlib, glob, gc, time, datetime, re, warnings\nimport concurrent.futures\nfrom pathlib import Path\nfrom collections import defaultdict\nwarnings.filterwarnings('ignore')\n\n# Add repo root to Python path\n_REPO_ROOT = os.path.abspath(os.getcwd())\nif _REPO_ROOT not in sys.path:\n    sys.path.insert(0, _REPO_ROOT)\n\n# Auto-install missing packages\n_REQUIRED = [\n    ('psutil',     'psutil>=5.8.0'),\n    ('pandas',     'pandas>=1.3.0'),\n    ('numpy',      'numpy>=1.21.0'),\n    ('matplotlib', 'matplotlib>=3.5.0'),\n    ('seaborn',    'seaborn>=0.11.0'),\n    ('openpyxl',   'openpyxl>=3.0.0'),\n    ('tqdm',       'tqdm>=4.64.0'),\n]\n_miss = [p for m, p in _REQUIRED if importlib.util.find_spec(m) is None]\nif _miss:\n    import subprocess\n    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *_miss, '-q'])\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom IPython.display import display, HTML, Image\n\nsns.set_theme(style='whitegrid')\n\n# ── USER CONFIGURATION ────────────────────────────────────────────────────────\nFASTA_INPUT        = ['*.fna', '*.fasta']   # path, wildcard glob, or list of paths/globs\nOUTPUT_DIR         = 'notebook_reports'\nENABLED_CLASSES    = None                   # None = all 9 detectors; e.g. ['G-Quadruplex','Z-DNA']\nRAM_OVERRIDE_BYTES = None                   # None = auto-detect\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 1.  GPU DETECTION\n# ─────────────────────────────────────────────────────────────────────────────\ndef _detect_gpu():\n    try:\n        import torch\n        if torch.cuda.is_available():\n            return 'cuda', torch.cuda.get_device_name(0)\n    except ImportError:\n        pass\n    try:\n        import cupy as cp; cp.array([1])\n        return 'cupy', 'CUDA GPU'\n    except Exception:\n        pass\n    return None, None\n\nGPU_BACKEND, GPU_NAME = _detect_gpu()\n_gpu_msg = f'GPU  {GPU_BACKEND} ({GPU_NAME})' if GPU_BACKEND else 'GPU  none (CPU only)'\nprint(f'\\u2705 Deps OK | Python {sys.version.split()[0]} | {_gpu_msg}')\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 2.  RESOLVE INPUT FILES & CLASSIFY TYPES\n# ─────────────────────────────────────────────────────────────────────────────\ndef _resolve(inp):\n    out = []\n    for p in ([inp] if isinstance(inp, str) else list(inp)):\n        hits = glob.glob(p)\n        out.extend(hits)\n        if not hits and os.path.isfile(p):\n            out.append(p)\n    return sorted({str(Path(f).resolve()) for f in out})\n\nFASTA_FILES = _resolve(FASTA_INPUT)\nif not FASTA_FILES:\n    raise FileNotFoundError(f'No FASTA files found for: {FASTA_INPUT}')\n\ndef _seq_lengths(p):\n    L, c = [], 0\n    with open(p) as fh:\n        for ln in fh:\n            s = ln.strip()\n            if s.startswith('>'):\n                if c: L.append(c)\n                c = 0\n            else:\n                c += len(s)\n    if c: L.append(c)\n    return L\n\nFILE_TYPES = {}   # path -> 'single' | 'multi' | 'multi_equal'\nfor fp in FASTA_FILES:\n    ls = _seq_lengths(fp)\n    if   len(ls) == 1:       FILE_TYPES[fp] = 'single'\n    elif len(set(ls)) == 1:  FILE_TYPES[fp] = 'multi_equal'\n    else:                    FILE_TYPES[fp] = 'multi'\n\n# GFF pairing (same stem, .gff or .gff3)\nGFF_MAP = {}\nfor fp in FASTA_FILES:\n    stem, parent = Path(fp).stem, Path(fp).parent\n    for ext in ('.gff3', '.gff'):\n        candidate = parent / (stem + ext)\n        if candidate.exists():\n            GFF_MAP[fp] = str(candidate)\n            break\n\nprint(f'\\n\\U0001f4c2 Input files: {len(FASTA_FILES)}')\nfor fp in FASTA_FILES:\n    gff_tag = f'  +GFF: {Path(GFF_MAP[fp]).name}' if fp in GFF_MAP else ''\n    print(f'   [{FILE_TYPES[fp]:12s}]  {Path(fp).name}{gff_tag}')\nprint(f'\\n\\U0001f4c1 Output dir : {OUTPUT_DIR}')\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 3.  ADAPTIVE RESOURCE PLANNING\n# ─────────────────────────────────────────────────────────────────────────────\nfrom Utilities.system_resource_inspector import SystemResourceInspector\nfrom Utilities.adaptive_chunk_planner    import AdaptiveChunkPlanner\nfrom Utilities.nonbscanner               import analyze_sequence as _nbf_analyze\nfrom Utilities.utilities                 import (\n    read_fasta_file, export_to_csv, export_to_excel,\n)\n\n_insp   = SystemResourceInspector()\n_budget = RAM_OVERRIDE_BYTES or _insp.get_memory_budget()\n_cpus   = _insp.get_cpu_count()\n_total  = max(sum(os.path.getsize(f) for f in FASTA_FILES if os.path.exists(f)), 1_000)\n_plan   = AdaptiveChunkPlanner().plan(_total, _budget, _cpus)\nCHUNK_SIZE, CHUNK_OVERLAP = _plan['chunk_size'], _plan['overlap']\nN_WORKERS, EXEC_MODE      = _plan['workers'], _plan['mode']\nif GPU_BACKEND:\n    N_WORKERS = min(N_WORKERS * 2, os.cpu_count() or 4)\n\nprint(f'\\u2699\\ufe0f  RAM {_budget/1e9:.2f} GB | chunk={CHUNK_SIZE:,} overlap={CHUNK_OVERLAP:,} '\n      f'workers={N_WORKERS} mode={EXEC_MODE} gpu={GPU_BACKEND or \"none\"}')\n\n_RUN_TS = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n_BASE   = Path(OUTPUT_DIR) / _RUN_TS\n_BASE.mkdir(parents=True, exist_ok=True)\nprint(f'\\U0001f4c2 Run output: {_BASE}')\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 4.  HELPERS\n# ─────────────────────────────────────────────────────────────────────────────\ndef _scan(name, seq):\n    return _nbf_analyze(\n        sequence=seq, sequence_name=name,\n        use_chunking=True,\n        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP,\n        use_parallel_chunks=(EXEC_MODE == 'hybrid'),\n        enabled_classes=ENABLED_CLASSES,\n    )\n\ndef _savefig(fig, path, show=True):\n    fig.savefig(str(path), dpi=150, bbox_inches='tight')\n    plt.close(fig)\n    if show:\n        display(Image(str(path)))\n\ndef _parse_gff(gff_path):\n    feats = []\n    with open(gff_path) as fh:\n        for ln in fh:\n            if ln.startswith('#') or not ln.strip():\n                continue\n            p = ln.rstrip('\\n').split('\\t')\n            if len(p) < 8:\n                continue\n            try:\n                feats.append({\n                    'seqid':  p[0], 'type': p[2],\n                    'start':  max(int(p[3]) - 1, 0), 'end': int(p[4]),\n                    'strand': p[6],\n                    'attrs':  p[8] if len(p) > 8 else '',\n                })\n            except ValueError:\n                pass\n    return feats\n\ndef _gc_and_length(fasta_path):\n    gc = total = 0\n    with open(fasta_path) as fh:\n        for ln in fh:\n            s = ln.strip()\n            if not s or s.startswith('>'):\n                continue\n            su = s.upper()\n            gc    += su.count('G') + su.count('C')\n            total += len(su)\n    return (round(gc / total * 100, 2) if total else 0.0), total\n\ndef _coverage(df, seq_lengths_dict):\n    \"\"\"Fraction of total sequence bases covered by at least one motif.\"\"\"\n    if df.empty or not seq_lengths_dict:\n        return 0.0\n    total_len = sum(seq_lengths_dict.values())\n    if total_len == 0:\n        return 0.0\n    covered = 0\n    for sname, grp in df.groupby('Sequence_Name'):\n        slen = seq_lengths_dict.get(sname, 0)\n        if slen == 0:\n            continue\n        mask = np.zeros(slen, dtype=bool)\n        for _, row in grp.iterrows():\n            s = max(0, int(row['Start']))\n            e = min(slen, int(row['End']))\n            if e > s:\n                mask[s:e] = True\n        covered += mask.sum()\n    return round(covered / total_len * 100, 2)\n\ndef _safe_fname(s):\n    return re.sub(r'[^\\w\\-]', '_', str(s))\n\ndef _parse_species_region(stem):\n    idx = stem.find('_')\n    if idx == -1:\n        return stem, 'unknown'\n    return stem[:idx], stem[idx + 1:]\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 5.  PER-FILE ANALYSIS\n# ─────────────────────────────────────────────────────────────────────────────\nRESULTS_BY_FILE = {}   # stem -> {df, folder, file_type, path, seq_lengths}\nGFF_RESULTS     = {}   # stem -> {region_df, gff_path, folder}\n\nfor fasta_path in tqdm(FASTA_FILES, desc='Files', unit='file'):\n    stem     = Path(fasta_path).stem\n    ftype    = FILE_TYPES[fasta_path]\n    file_dir = _BASE / stem\n    file_dir.mkdir(parents=True, exist_ok=True)\n    tqdm.write(f'\\n\\u2500\\u2500 {stem}  [{ftype}] \\u2500\\u2500')\n\n    seqs = read_fasta_file(fasta_path)\n    if not seqs:\n        tqdm.write('  \\u26a0\\ufe0f  No sequences \\u2014 skipping.')\n        continue\n\n    seq_lengths_map = {sn: len(sq) for sn, sq in seqs.items()}\n\n    # ── Whole-genome scan (parallel over sequences) ───────────────────────────\n    motifs_file, t0 = [], time.perf_counter()\n    with concurrent.futures.ThreadPoolExecutor(max_workers=N_WORKERS) as pool:\n        futs = {pool.submit(_scan, sn, sq): sn for sn, sq in seqs.items()}\n        for fut in tqdm(concurrent.futures.as_completed(futs),\n                        total=len(futs), desc=f'  seqs({stem})', leave=False):\n            sn  = futs[fut]\n            res = fut.result()\n            tqdm.write(f'  \\u25b8 {sn[:55]}  \\u2192 {len(res):,} motifs')\n            motifs_file.extend(res)\n    tqdm.write(f'  \\u2705 {len(motifs_file):,} motifs in {time.perf_counter()-t0:.1f}s')\n    gc.collect()\n\n    # ── Build per-file DataFrame ──────────────────────────────────────────────\n    df = pd.DataFrame(motifs_file) if motifs_file else pd.DataFrame()\n    for col, dflt in [('Class','Unknown'), ('Subclass','Other'), ('Start',0),\n                      ('End',0), ('Length',0), ('Score',0.0), ('Strand','+'),\n                      ('Sequence_Name','')]:\n        if col not in df.columns:\n            df[col] = dflt\n    if not df.empty:\n        m = df['Length'] == 0\n        df.loc[m, 'Length'] = (df.loc[m, 'End'] - df.loc[m, 'Start']).clip(lower=0)\n    df['Source_File'] = Path(fasta_path).name\n    df['File_Type']   = ftype\n\n    # ── Per-file exports (CSV + Excel only) ───────────────────────────────────\n    if not df.empty:\n        rows = df.to_dict(orient='records')\n        export_to_csv(rows,   filename=str(file_dir / 'motifs.csv'))\n        export_to_excel(rows, filename=str(file_dir / 'motifs.xlsx'))\n\n    # ══════════════════════════════════════════════════════════════════════════\n    # PER-FILE PLOTS\n    # ══════════════════════════════════════════════════════════════════════════\n\n    if not df.empty:\n        # -- 1. Class distribution --------------------------------------------\n        cc = df['Class'].value_counts()\n        fig, ax = plt.subplots(figsize=(8, max(3, len(cc) * 0.45)))\n        ax.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n        ax.set_xlabel('Motif Count')\n        ax.set_title(f'{stem} [{ftype}] \\u2014 Class Distribution')\n        for i, v in enumerate(cc.values[::-1]):\n            ax.text(v + 0.5, i, str(v), va='center', fontsize=8)\n        plt.tight_layout()\n        _savefig(fig, file_dir / 'class_distribution.png', show=False)\n\n        # -- 2. Subclass distribution -----------------------------------------\n        sc = df['Subclass'].value_counts().head(30)\n        fig, ax = plt.subplots(figsize=(8, max(3, len(sc) * 0.4)))\n        ax.barh(sc.index[::-1], sc.values[::-1], color='darkorange')\n        ax.set_xlabel('Motif Count')\n        ax.set_title(f'{stem} \\u2014 Subclass Distribution (top 30)')\n        plt.tight_layout()\n        _savefig(fig, file_dir / 'subclass_distribution.png', show=False)\n\n        # -- 3. Hybrid & Cluster breakdown ------------------------------------\n        _special = df[df['Class'].isin(['Hybrid', 'Non-B_DNA_Clusters'])]\n        if not _special.empty:\n            sp_cnt = _special['Class'].value_counts()\n            fig, ax = plt.subplots(figsize=(6, 3))\n            ax.bar(sp_cnt.index, sp_cnt.values, color=['tomato','mediumpurple'])\n            ax.set_ylabel('Count')\n            ax.set_title(f'{stem} \\u2014 Hybrid & Cluster Motifs')\n            for i, v in enumerate(sp_cnt.values):\n                ax.text(i, v + 0.2, str(v), ha='center', fontsize=9)\n            plt.tight_layout()\n            _savefig(fig, file_dir / 'hybrid_cluster_breakdown.png', show=False)\n\n        # -- 4. Motif density per sequence (multi-seq files) ------------------\n        if ftype in ('multi', 'multi_equal'):\n            _dens_rows = []\n            for sn, sq_len in seq_lengths_map.items():\n                n = len(df[df['Sequence_Name'] == sn])\n                _dens_rows.append({'Sequence': sn[:40], 'Length_bp': sq_len,\n                                   'Motifs': n,\n                                   'Density_per_kb': round(n / sq_len * 1000, 4) if sq_len else 0})\n            _dens_df = pd.DataFrame(_dens_rows).sort_values('Density_per_kb', ascending=False)\n            _top_dens = _dens_df.head(40)\n            fig, ax = plt.subplots(figsize=(9, max(4, len(_top_dens) * 0.35)))\n            ax.barh(_top_dens['Sequence'][::-1], _top_dens['Density_per_kb'][::-1],\n                    color='teal')\n            ax.set_xlabel('Motifs per kb')\n            ax.set_title(f'{stem} \\u2014 Motif Density by Sequence (top 40)')\n            plt.tight_layout()\n            _savefig(fig, file_dir / 'motif_density_by_sequence.png', show=False)\n\n        # -- 5. Sequence coverage (%) -----------------------------------------\n        if ftype in ('multi', 'multi_equal'):\n            _cov_rows = []\n            for sn, sq_len in seq_lengths_map.items():\n                sub = df[df['Sequence_Name'] == sn]\n                if sub.empty or sq_len == 0:\n                    _cov_rows.append({'Sequence': sn[:40], 'Coverage_pct': 0.0})\n                    continue\n                mask = np.zeros(sq_len, dtype=bool)\n                for _, row in sub.iterrows():\n                    s = max(0, int(row['Start'])); e = min(sq_len, int(row['End']))\n                    if e > s: mask[s:e] = True\n                _cov_rows.append({'Sequence': sn[:40],\n                                  'Coverage_pct': round(mask.sum() / sq_len * 100, 2)})\n            _cov_df = pd.DataFrame(_cov_rows).sort_values('Coverage_pct', ascending=False)\n            _top_cov = _cov_df.head(40)\n            fig, ax = plt.subplots(figsize=(9, max(4, len(_top_cov) * 0.35)))\n            ax.barh(_top_cov['Sequence'][::-1], _top_cov['Coverage_pct'][::-1],\n                    color='mediumseagreen')\n            ax.set_xlabel('Coverage (%)')\n            ax.set_title(f'{stem} \\u2014 Non-B DNA Coverage by Sequence (top 40)')\n            ax.set_xlim(0, 100)\n            plt.tight_layout()\n            _savefig(fig, file_dir / 'sequence_coverage.png', show=False)\n\n        # -- 6. Positional distribution (equal-length multiFASTA) -------------\n        if ftype == 'multi_equal':\n            seq_len_val = list(seq_lengths_map.values())[0]\n            # Per-class positional frequency\n            for cls in df['Class'].unique():\n                cls_df = df[df['Class'] == cls]\n                starts = cls_df['Start'].dropna().astype(int)\n                starts = starts[starts < seq_len_val]\n                if starts.empty:\n                    continue\n                bins = min(100, seq_len_val)\n                fig, ax = plt.subplots(figsize=(10, 3))\n                ax.hist(starts, bins=bins, color='steelblue', edgecolor='none', alpha=0.8)\n                ax.set_xlabel('Position (bp)')\n                ax.set_ylabel('Frequency')\n                ax.set_title(f'{stem} \\u2014 {cls} Positional Distribution '\n                             f'(n={len(starts):,}, seq_len={seq_len_val:,})')\n                ax.xaxis.set_major_formatter(mticker.FuncFormatter(\n                    lambda x, _: f'{int(x):,}'))\n                plt.tight_layout()\n                _savefig(fig, file_dir / f'positional_dist_{_safe_fname(cls)}.png', show=False)\n\n            # Combined positional distribution (all classes stacked)\n            fig, ax = plt.subplots(figsize=(12, 4))\n            bins = min(100, seq_len_val)\n            for cls in sorted(df['Class'].unique()):\n                starts = df[df['Class'] == cls]['Start'].dropna().astype(int)\n                starts = starts[starts < seq_len_val]\n                if not starts.empty:\n                    ax.hist(starts, bins=bins, alpha=0.5, label=cls, histtype='stepfilled')\n            ax.set_xlabel('Position (bp)')\n            ax.set_ylabel('Frequency')\n            ax.set_title(f'{stem} \\u2014 Combined Positional Distribution '\n                         f'(seq_len={seq_len_val:,})')\n            ax.xaxis.set_major_formatter(mticker.FuncFormatter(\n                lambda x, _: f'{int(x):,}'))\n            ax.legend(fontsize=7, ncol=3)\n            plt.tight_layout()\n            _savefig(fig, file_dir / 'positional_dist_combined.png', show=False)\n\n        tqdm.write(f'  \\U0001f4ca Plots saved to: {file_dir}')\n\n    RESULTS_BY_FILE[stem] = {\n        'df': df, 'folder': file_dir, 'file_type': ftype,\n        'path': fasta_path, 'seq_lengths': seq_lengths_map,\n    }\n\n    # ── GFF region analysis ───────────────────────────────────────────────────\n    if fasta_path in GFF_MAP:\n        gff_path = GFF_MAP[fasta_path]\n        tqdm.write(f'  \\U0001f4cb GFF: {Path(gff_path).name}')\n        features = _parse_gff(gff_path)\n        tqdm.write(f'     {len(features):,} features parsed')\n\n        gff_dir = file_dir / 'gff_regions'\n        gff_dir.mkdir(exist_ok=True)\n\n        region_rows = []\n        feat_types  = sorted({f['type'] for f in features})\n        for ftype_gff in tqdm(feat_types, desc=f'  GFF({stem})', leave=False):\n            type_feats  = [f for f in features if f['type'] == ftype_gff]\n            type_motifs = []\n            for feat in type_feats:\n                seq_id     = feat['seqid']\n                if seq_id not in seqs:\n                    continue\n                region_seq = seqs[seq_id][feat['start']:feat['end']]\n                if len(region_seq) < 12:\n                    continue\n                rname = (f\"{seq_id}:{ftype_gff}:{feat['start']}-\"\n                         f\"{feat['end']}({feat['strand']})\")\n                mots = _scan(rname, region_seq)\n                for m in mots:\n                    m['GFF_Type']   = ftype_gff\n                    m['GFF_SeqID']  = seq_id\n                    m['GFF_Start']  = feat['start']\n                    m['GFF_End']    = feat['end']\n                    m['GFF_Strand'] = feat['strand']\n                    _a = feat['attrs']\n                    m['GFF_Attrs']  = _a[:80] + ('...' if len(_a) > 80 else '')\n                type_motifs.extend(mots)\n            region_rows.extend(type_motifs)\n            tqdm.write(\n                f'     {ftype_gff}: {len(type_feats):,} regions \\u2192 {len(type_motifs):,} motifs')\n            gc.collect()\n\n        gff_df = pd.DataFrame(region_rows) if region_rows else pd.DataFrame()\n        for col, dflt in [('Class','Unknown'), ('Subclass','Other'), ('Start',0),\n                          ('End',0), ('Length',0), ('Score',0.0),\n                          ('GFF_Type',''), ('GFF_SeqID',''),\n                          ('GFF_Start',0), ('GFF_End',0),\n                          ('GFF_Strand','+'), ('GFF_Attrs','')]:\n            if col not in gff_df.columns:\n                gff_df[col] = dflt\n\n        if not gff_df.empty:\n            gff_df.to_csv(str(gff_dir / 'gff_region_motifs.csv'), index=False)\n            pivot = gff_df.groupby(['GFF_Type', 'Class']).size().unstack(fill_value=0)\n            fig, ax = plt.subplots(figsize=(max(8, len(pivot) * 1.4), 5))\n            pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n            ax.set_xlabel('GFF Feature Type')\n            ax.set_ylabel('Motif Count')\n            ax.set_title(f'{stem} \\u2014 Motifs per GFF Feature Type')\n            ax.legend(title='Class', bbox_to_anchor=(1, 1))\n            plt.tight_layout()\n            _savefig(fig, gff_dir / 'gff_motifs_by_type.png', show=False)\n\n        GFF_RESULTS[stem] = {'region_df': gff_df, 'gff_path': gff_path, 'folder': gff_dir}\n        tqdm.write(f'  \\u2705 GFF analysis: {len(gff_df):,} region motifs')\n\nprint(f'\\n\\u2705 Analysis complete \\u2014 {len(RESULTS_BY_FILE)} file(s) processed '\n      f'({len(GFF_RESULTS)} with GFF).')\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 6.  MASTER TABLES & GLOBAL SUMMARY PLOTS\n# ─────────────────────────────────────────────────────────────────────────────\n_dfs       = [r['df'] for r in RESULTS_BY_FILE.values() if not r['df'].empty]\n_master_df = pd.concat(_dfs, ignore_index=True) if _dfs else pd.DataFrame()\n\n_master_dir = _BASE / '_master'\n_master_dir.mkdir(exist_ok=True)\n\n_gdfs   = [v['region_df'] for v in GFF_RESULTS.values() if not v['region_df'].empty]\n_gff_df = pd.concat(_gdfs, ignore_index=True) if _gdfs else pd.DataFrame()\n\n_tables = {}\n\nif not _master_df.empty:\n    _tables['1_global_class_distribution'] = (\n        _master_df.groupby(['Source_File', 'File_Type', 'Class'])\n        .size().reset_index(name='Count')\n    )\n\n    # Per-file summary including hybrid/cluster counts, coverage, density\n    _pf_rows = []\n    for stem, res in RESULTS_BY_FILE.items():\n        df   = res['df']\n        fp   = res['path']\n        ftype_v = res['file_type']\n        sl   = res['seq_lengths']\n        gc_pct, seq_len = _gc_and_length(fp)\n        n    = len(df)\n        density = round(n / seq_len * 1000, 4) if seq_len else 0.0\n        cov_pct = _coverage(df, sl)\n        n_hybrid   = int((df['Class'] == 'Hybrid').sum())             if not df.empty else 0\n        n_clusters = int((df['Class'] == 'Non-B_DNA_Clusters').sum()) if not df.empty else 0\n        _pf_rows.append({\n            'File':             Path(fp).name,\n            'File_Type':        ftype_v,\n            'Sequences':        len(sl),\n            'Total_bp':         seq_len,\n            'GC_Percent':       gc_pct,\n            'Total_Motifs':     n,\n            'Classes':          df['Class'].nunique()    if not df.empty else 0,\n            'Subclasses':       df['Subclass'].nunique() if not df.empty else 0,\n            'Hybrids':          n_hybrid,\n            'Clusters':         n_clusters,\n            'Density_per_kb':   density,\n            'Coverage_pct':     cov_pct,\n        })\n    _tables['2_per_file_summary'] = pd.DataFrame(_pf_rows)\n\n    _tables['3_class_statistics'] = (\n        _master_df.groupby('Class')\n        .agg(Total_Count=('Class', 'count'),\n             Mean_Length=('Length', 'mean'),\n             Mean_Score=('Score', 'mean'))\n        .round(3).reset_index().sort_values('Total_Count', ascending=False)\n    )\n\n    _tables['4_file_class_pivot'] = (\n        _master_df.groupby(['Source_File', 'Class'])\n        .size().unstack(fill_value=0).reset_index()\n    )\n\n    _tables['5_subclass_statistics'] = (\n        _master_df.groupby('Subclass')\n        .agg(Total_Count=('Subclass', 'count'),\n             Mean_Length=('Length', 'mean'),\n             Mean_Score=('Score', 'mean'))\n        .round(3).reset_index().sort_values('Total_Count', ascending=False)\n    )\n\n    # Equal-length multiFASTA positional table\n    _eq_dfs = [r['df'] for r in RESULTS_BY_FILE.values()\n               if r['file_type'] == 'multi_equal' and not r['df'].empty]\n    if _eq_dfs:\n        _eq = pd.concat(_eq_dfs, ignore_index=True)\n        _tables['6_equal_length_positional'] = (\n            _eq.groupby(['Source_File', 'Class', 'Start'])\n            .size().reset_index(name='Frequency')\n            .sort_values(['Source_File', 'Class', 'Frequency'],\n                         ascending=[True, True, False])\n        )\n\nif not _gff_df.empty:\n    _tables['7_gff_motifs_per_feature_type'] = (\n        _gff_df.groupby(['GFF_Type', 'Class'])\n        .size().reset_index(name='Count').sort_values('Count', ascending=False)\n    )\n    _tables['8_gff_density_per_feature'] = (\n        _gff_df.assign(Region_Len=(_gff_df['GFF_End'] - _gff_df['GFF_Start']).clip(lower=1))\n        .groupby('GFF_Type')\n        .agg(Total_Motifs=('Class', 'count'),\n             Unique_Classes=('Class', 'nunique'),\n             Mean_Region_Len=('Region_Len', 'mean'))\n        .round(2).reset_index().sort_values('Total_Motifs', ascending=False)\n    )\n    _tables['9_gff_class_pivot'] = (\n        _gff_df.groupby(['GFF_Type', 'Class']).size().unstack(fill_value=0).reset_index()\n    )\n    _tables['10_gff_top50_hotspot_regions'] = (\n        _gff_df.groupby(['GFF_SeqID', 'GFF_Type', 'GFF_Start', 'GFF_End'])\n        .agg(Motif_Count=('Class', 'count'), Classes=('Class', 'nunique'))\n        .reset_index().sort_values('Motif_Count', ascending=False).head(50)\n    )\n\n# ── Export master tables ──────────────────────────────────────────────────────\nif not _master_df.empty:\n    rows = _master_df.to_dict(orient='records')\n    export_to_csv(rows,   filename=str(_master_dir / 'master_motifs.csv'))\n    export_to_excel(rows, filename=str(_master_dir / 'master_motifs.xlsx'))\nif not _gff_df.empty:\n    _gff_df.to_csv(str(_master_dir / 'gff_region_motifs_all.csv'), index=False)\nfor tname, tdf in _tables.items():\n    tdf.to_csv(str(_master_dir / f'{tname}.csv'), index=False)\n\n# ── Global summary plots ──────────────────────────────────────────────────────\nif not _master_df.empty:\n    _pf_summary = _tables.get('2_per_file_summary', pd.DataFrame())\n    _n_files    = len(RESULTS_BY_FILE)\n\n    # ---- (a) Global class distribution + file-type pie ----------------------\n    _ncol = 2 + (1 if _n_files > 1 else 0) + (1 if not _gff_df.empty else 0)\n    fig, axes = plt.subplots(1, _ncol, figsize=(6 * _ncol, 4))\n    _ax = iter([axes] if _ncol == 1 else axes.flat)\n\n    cc = _master_df['Class'].value_counts()\n    a  = next(_ax)\n    a.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n    a.set_xlabel('Count')\n    a.set_title('Global Class Distribution')\n\n    ft = _master_df.groupby('File_Type').size()\n    a  = next(_ax)\n    a.pie(ft.values, labels=ft.index, autopct='%1.1f%%', startangle=90)\n    a.set_title('Motifs by File Type')\n\n    if _n_files > 1:\n        pf = _master_df.groupby('Source_File').size().sort_values(ascending=False)\n        a  = next(_ax)\n        a.barh([Path(n).stem[:22] for n in pf.index[::-1]], pf.values[::-1], color='coral')\n        a.set_xlabel('Count')\n        a.set_title('Motifs per File')\n\n    if not _gff_df.empty:\n        a  = next(_ax)\n        gt = _gff_df['GFF_Type'].value_counts().head(15)\n        a.barh(gt.index[::-1], gt.values[::-1], color='mediumseagreen')\n        a.set_xlabel('Count')\n        a.set_title('Motifs by GFF Feature Type')\n\n    plt.tight_layout()\n    _savefig(fig, _master_dir / 'master_summary.png')\n\n    # ---- (b) Density comparison across files --------------------------------\n    if not _pf_summary.empty:\n        fig, ax = plt.subplots(figsize=(max(6, len(_pf_summary) * 1.4), 4))\n        _pf_s = _pf_summary.sort_values('Density_per_kb', ascending=False)\n        bars = ax.bar(_pf_s['File'].apply(lambda x: Path(x).stem[:25]),\n                      _pf_s['Density_per_kb'], color='steelblue')\n        ax.bar_label(bars, fmt='%.3f', padding=2, fontsize=8)\n        ax.set_ylabel('Motifs per kb')\n        ax.set_title('Motif Density Comparison Across Files')\n        plt.xticks(rotation=30, ha='right')\n        plt.tight_layout()\n        _savefig(fig, _master_dir / 'density_comparison.png')\n\n    # ---- (c) Coverage comparison across files --------------------------------\n    if not _pf_summary.empty:\n        fig, ax = plt.subplots(figsize=(max(6, len(_pf_summary) * 1.4), 4))\n        _pf_s = _pf_summary.sort_values('Coverage_pct', ascending=False)\n        bars = ax.bar(_pf_s['File'].apply(lambda x: Path(x).stem[:25]),\n                      _pf_s['Coverage_pct'], color='mediumseagreen')\n        ax.bar_label(bars, fmt='%.1f%%', padding=2, fontsize=8)\n        ax.set_ylabel('Coverage (%)')\n        ax.set_title('Non-B DNA Coverage Comparison Across Files')\n        ax.set_ylim(0, 100)\n        plt.xticks(rotation=30, ha='right')\n        plt.tight_layout()\n        _savefig(fig, _master_dir / 'coverage_comparison.png')\n\n    # ---- (d) Hybrid & Cluster comparison ------------------------------------\n    if not _pf_summary.empty and (\n            _pf_summary['Hybrids'].sum() > 0 or _pf_summary['Clusters'].sum() > 0):\n        x      = np.arange(len(_pf_summary))\n        width  = 0.35\n        labels = _pf_summary['File'].apply(lambda x: Path(x).stem[:20])\n        fig, ax = plt.subplots(figsize=(max(7, len(_pf_summary) * 1.5), 4))\n        ax.bar(x - width / 2, _pf_summary['Hybrids'],   width, label='Hybrids',  color='tomato')\n        ax.bar(x + width / 2, _pf_summary['Clusters'],  width, label='Clusters', color='mediumpurple')\n        ax.set_xticks(x); ax.set_xticklabels(labels, rotation=30, ha='right')\n        ax.set_ylabel('Count')\n        ax.set_title('Hybrid & Cluster Motifs Across Files')\n        ax.legend()\n        plt.tight_layout()\n        _savefig(fig, _master_dir / 'hybrid_cluster_comparison.png')\n\n    # ---- (e) GFF heatmap (feature type x class) -----------------------------\n    if not _gff_df.empty and '9_gff_class_pivot' in _tables:\n        _piv = _tables['9_gff_class_pivot'].set_index('GFF_Type')\n        fig2, ax2 = plt.subplots(figsize=(max(10, len(_piv.columns) * 1.2),\n                                          max(4,  len(_piv) * 0.6)))\n        sns.heatmap(_piv, annot=True, fmt='d', cmap='YlOrRd', ax=ax2,\n                    linewidths=0.4, cbar_kws={'label': 'Motif count'})\n        ax2.set_title('GFF Feature Type \\u00d7 Non-B Class Heatmap')\n        ax2.set_xlabel('Non-B Class')\n        ax2.set_ylabel('GFF Feature Type')\n        plt.tight_layout()\n        _savefig(fig2, _master_dir / 'gff_class_heatmap.png')\n\n    # ---- (f) Subclass distribution (top 30 global) --------------------------\n    sc_all = _master_df['Subclass'].value_counts().head(30)\n    fig, ax = plt.subplots(figsize=(8, max(4, len(sc_all) * 0.4)))\n    ax.barh(sc_all.index[::-1], sc_all.values[::-1], color='darkorange')\n    ax.set_xlabel('Count')\n    ax.set_title('Global Subclass Distribution (top 30)')\n    plt.tight_layout()\n    _savefig(fig, _master_dir / 'global_subclass_distribution.png')\n\n# ── Display master tables ─────────────────────────────────────────────────────\nfor tname, tdf in _tables.items():\n    print(f\"\\n{'='*60}\\n{tname.replace('_',' ').upper()}\\n{'='*60}\")\n    display(tdf)\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 7.  COMPARATIVE ANALYSIS\n# ─────────────────────────────────────────────────────────────────────────────\n_sep = '\\u2550' * 60\n\n_comp_rows = []\nfor stem, res in RESULTS_BY_FILE.items():\n    species, region = _parse_species_region(stem)\n    df  = res['df']\n    fp  = res['path']\n    sl  = res['seq_lengths']\n    gc_pct, seq_len = _gc_and_length(fp)\n    n   = len(df)\n    density = round(n / seq_len * 1000, 4) if seq_len else 0.0\n    cov_pct = _coverage(df, sl)\n    _comp_rows.append({\n        'Stem':                  stem,\n        'Species':               species,\n        'Region':                region,\n        'Total_Motifs':          n,\n        'Seq_Length_bp':         seq_len,\n        'Density_per_kb':        density,\n        'Coverage_pct':          cov_pct,\n        'GC_Percent':            gc_pct,\n        'Mean_Motif_Length':     round(df['Length'].mean(),   2) if not df.empty else 0.0,\n        'Median_Motif_Length':   round(df['Length'].median(), 2) if not df.empty else 0.0,\n        'Unique_Classes':        df['Class'].nunique()    if not df.empty else 0,\n        'Unique_Subclasses':     df['Subclass'].nunique() if not df.empty else 0,\n        'Hybrids':               int((df['Class'] == 'Hybrid').sum())             if not df.empty else 0,\n        'Clusters':              int((df['Class'] == 'Non-B_DNA_Clusters').sum()) if not df.empty else 0,\n    })\n\n_comp_df      = pd.DataFrame(_comp_rows)\n_species_list = sorted(_comp_df['Species'].unique())\n_region_list  = sorted(_comp_df['Region'].unique())\nprint(f'Species detected : {_species_list}')\nprint(f'Regions detected : {_region_list}')\n\n_cmp_dir = _BASE / '_comparisons'\n_cmp_dir.mkdir(exist_ok=True)\n\n# Save master comparison tables\n_comp_df.to_csv(str(_cmp_dir / 'all_comparisons_summary.csv'), index=False)\n_comp_df.to_excel(str(_cmp_dir / 'all_comparisons_summary.xlsx'), index=False)\n\n# ── Multi-file comparative plots (even with a single species) ─────────────────\nif len(RESULTS_BY_FILE) >= 2:\n    # Class comparison across ALL files\n    _all_classes = sorted(_master_df['Class'].unique()) if not _master_df.empty else []\n    if _all_classes:\n        _cls_pivot = _master_df.groupby(['Source_File', 'Class']).size().unstack(fill_value=0)\n        fig, ax = plt.subplots(figsize=(max(10, len(_cls_pivot) * 1.4),\n                                        max(4,  len(_cls_pivot.columns) * 0.5)))\n        _cls_pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n        ax.set_xlabel('File')\n        ax.set_ylabel('Motif Count')\n        ax.set_title('Class Distribution \\u2014 All Files Comparison')\n        ax.legend(title='Class', bbox_to_anchor=(1, 1), fontsize=8)\n        plt.xticks(rotation=30, ha='right')\n        plt.tight_layout()\n        _savefig(fig, _cmp_dir / 'all_files_class_comparison.png')\n\n    # Subclass comparison across ALL files\n    _all_subs = sorted(_master_df['Subclass'].unique()) if not _master_df.empty else []\n    if _all_subs:\n        _sub_pivot = _master_df.groupby(['Source_File', 'Subclass']).size().unstack(fill_value=0)\n        # Keep top 20 subclasses by total count for readability\n        _top_subs = _master_df['Subclass'].value_counts().head(20).index\n        _sub_pivot = _sub_pivot[[c for c in _top_subs if c in _sub_pivot.columns]]\n        if not _sub_pivot.empty:\n            fig, ax = plt.subplots(figsize=(max(10, len(_sub_pivot) * 1.4),\n                                            max(4,  len(_sub_pivot.columns) * 0.4)))\n            _sub_pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n            ax.set_xlabel('File')\n            ax.set_ylabel('Motif Count')\n            ax.set_title('Subclass Distribution \\u2014 All Files (top 20 subclasses)')\n            ax.legend(title='Subclass', bbox_to_anchor=(1, 1), fontsize=7)\n            plt.xticks(rotation=30, ha='right')\n            plt.tight_layout()\n            _savefig(fig, _cmp_dir / 'all_files_subclass_comparison.png')\n\n    # Density heatmap (files x classes)\n    if not _master_df.empty:\n        _fname_to_len = {\n            Path(res['path']).name: max(sum(res['seq_lengths'].values()), 1)\n            for res in RESULTS_BY_FILE.values()\n        }\n        _dens_rows_hm = []\n        for (fname, cls), grp in _master_df.groupby(['Source_File', 'Class']):\n            seq_len = _fname_to_len.get(fname, 1)\n            _dens_rows_hm.append({'Source_File': fname, 'Class': cls,\n                                  'Density_per_kb': len(grp) / seq_len * 1000})\n        _dens_cls = pd.DataFrame(_dens_rows_hm)\n        _dens_piv = _dens_cls.pivot_table(\n            index='Source_File', columns='Class', values='Density_per_kb', fill_value=0)\n        if not _dens_piv.empty:\n            fig, ax = plt.subplots(figsize=(max(10, len(_dens_piv.columns) * 1.2),\n                                            max(4,  len(_dens_piv) * 0.7)))\n            sns.heatmap(_dens_piv, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,\n                        linewidths=0.4, cbar_kws={'label': 'Motifs per kb'})\n            ax.set_title('Motif Density Heatmap (motifs per kb) \\u2014 Files \\u00d7 Classes')\n            ax.set_xlabel('Non-B DNA Class')\n            ax.set_ylabel('File')\n            plt.tight_layout()\n            _savefig(fig, _cmp_dir / 'density_heatmap_files_x_classes.png')\n\n# ── Within-species comparison ─────────────────────────────────────────────────\nfor species in _species_list:\n    sp_rows  = _comp_df[_comp_df['Species'] == species].copy()\n    sp_stems = sp_rows['Stem'].tolist()\n    sp_dir   = _cmp_dir / _safe_fname(species)\n    sp_dir.mkdir(exist_ok=True)\n\n    if len(sp_stems) < 2:\n        print(f\"\\n\\u26a0  '{species}' has only one region file — skipping within-species plots.\")\n        continue\n\n    print(f'\\n{_sep}\\nWithin-species comparison: {species}\\n{_sep}')\n\n    # 1. Class distribution by region\n    _class_by_region = {}\n    for stem in sp_stems:\n        df  = RESULTS_BY_FILE[stem]['df']\n        reg = sp_rows.loc[sp_rows['Stem'] == stem, 'Region'].values[0]\n        _class_by_region[reg] = (\n            df['Class'].value_counts() if not df.empty else pd.Series(dtype=int)\n        )\n    _all_cls = sorted({c for s in _class_by_region.values() for c in s.index})\n    if _all_cls:\n        _cmat = pd.DataFrame(\n            {r: s.reindex(_all_cls, fill_value=0) for r, s in _class_by_region.items()}\n        ).T\n        fig, ax = plt.subplots(figsize=(max(8, len(_all_cls) * 1.2), 4))\n        _cmat.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n        ax.set_title(f'{species} \\u2014 Class Distribution by Region')\n        ax.set_xlabel('Region'); ax.set_ylabel('Motif Count')\n        ax.legend(title='Class', bbox_to_anchor=(1, 1))\n        plt.xticks(rotation=30, ha='right')\n        _savefig(fig, sp_dir / 'class_by_region.png', show=False)\n\n    # 2. Subclass distribution by region\n    _sub_by_region = {}\n    for stem in sp_stems:\n        df  = RESULTS_BY_FILE[stem]['df']\n        reg = sp_rows.loc[sp_rows['Stem'] == stem, 'Region'].values[0]\n        _sub_by_region[reg] = (\n            df['Subclass'].value_counts() if not df.empty else pd.Series(dtype=int)\n        )\n    _all_subs = sorted({c for s in _sub_by_region.values() for c in s.index})\n    if _all_subs:\n        _smat = pd.DataFrame(\n            {r: s.reindex(_all_subs, fill_value=0) for r, s in _sub_by_region.items()}\n        ).T\n        fig, ax = plt.subplots(figsize=(max(8, len(_all_subs) * 1.0), 4))\n        _smat.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n        ax.set_title(f'{species} \\u2014 Subclass Distribution by Region')\n        ax.set_xlabel('Region'); ax.set_ylabel('Motif Count')\n        ax.legend(title='Subclass', bbox_to_anchor=(1, 1), fontsize=7)\n        plt.xticks(rotation=30, ha='right')\n        _savefig(fig, sp_dir / 'subclass_by_region.png', show=False)\n\n    # 3. Motif density by region\n    fig, ax = plt.subplots(figsize=(max(6, len(sp_rows) * 1.2), 4))\n    bars = ax.bar(sp_rows['Region'], sp_rows['Density_per_kb'], color='steelblue')\n    ax.bar_label(bars, fmt='%.3f', padding=2)\n    ax.set_title(f'{species} \\u2014 Motif Density (motifs per kb) by Region')\n    ax.set_xlabel('Region'); ax.set_ylabel('Motifs per kb')\n    plt.xticks(rotation=30, ha='right')\n    _savefig(fig, sp_dir / 'density_by_region.png', show=False)\n\n    # 4. Coverage by region\n    fig, ax = plt.subplots(figsize=(max(6, len(sp_rows) * 1.2), 4))\n    bars = ax.bar(sp_rows['Region'], sp_rows['Coverage_pct'], color='mediumseagreen')\n    ax.bar_label(bars, fmt='%.1f%%', padding=2)\n    ax.set_title(f'{species} \\u2014 Non-B DNA Coverage (%) by Region')\n    ax.set_xlabel('Region'); ax.set_ylabel('Coverage (%)')\n    ax.set_ylim(0, 100)\n    plt.xticks(rotation=30, ha='right')\n    _savefig(fig, sp_dir / 'coverage_by_region.png', show=False)\n\n    # 5. Motif length distribution by region\n    _len_parts = []\n    for stem in sp_stems:\n        df  = RESULTS_BY_FILE[stem]['df']\n        reg = sp_rows.loc[sp_rows['Stem'] == stem, 'Region'].values[0]\n        if not df.empty and 'Length' in df.columns:\n            tmp = df[['Length']].copy()\n            tmp['Region'] = reg\n            _len_parts.append(tmp)\n    if _len_parts:\n        _len_df = pd.concat(_len_parts, ignore_index=True)\n        _len_df = _len_df[_len_df['Length'] > 0]\n        if not _len_df.empty:\n            fig, ax = plt.subplots(figsize=(max(8, len(sp_stems) * 2), 4))\n            sns.boxplot(data=_len_df, x='Region', y='Length', ax=ax, palette='Set2')\n            ax.set_title(f'{species} \\u2014 Motif Length Distribution by Region')\n            ax.set_xlabel('Region'); ax.set_ylabel('Motif Length (bp)')\n            plt.xticks(rotation=30, ha='right')\n            _savefig(fig, sp_dir / 'length_by_region.png', show=False)\n\n    # 6. GC content by region\n    fig, ax = plt.subplots(figsize=(max(6, len(sp_rows) * 1.2), 4))\n    bars = ax.bar(sp_rows['Region'], sp_rows['GC_Percent'], color='goldenrod')\n    ax.bar_label(bars, fmt='%.1f%%', padding=2)\n    ax.set_title(f'{species} \\u2014 GC Content (%) by Region')\n    ax.set_xlabel('Region'); ax.set_ylabel('GC %')\n    ax.set_ylim(0, 100)\n    plt.xticks(rotation=30, ha='right')\n    _savefig(fig, sp_dir / 'gc_by_region.png', show=False)\n\n    # 7. Hybrid & Cluster counts by region\n    if sp_rows[['Hybrids', 'Clusters']].sum().sum() > 0:\n        x     = np.arange(len(sp_rows))\n        w     = 0.35\n        fig, ax = plt.subplots(figsize=(max(6, len(sp_rows) * 1.4), 4))\n        ax.bar(x - w / 2, sp_rows['Hybrids'].values,  w, label='Hybrids',  color='tomato')\n        ax.bar(x + w / 2, sp_rows['Clusters'].values, w, label='Clusters', color='mediumpurple')\n        ax.set_xticks(x); ax.set_xticklabels(sp_rows['Region'], rotation=30, ha='right')\n        ax.set_ylabel('Count')\n        ax.set_title(f'{species} \\u2014 Hybrid & Cluster Motifs by Region')\n        ax.legend()\n        plt.tight_layout()\n        _savefig(fig, sp_dir / 'hybrid_cluster_by_region.png', show=False)\n\n    # Summary table\n    _sp_summary = sp_rows.set_index('Region')[[\n        'Total_Motifs', 'Seq_Length_bp', 'Density_per_kb', 'Coverage_pct',\n        'GC_Percent', 'Mean_Motif_Length', 'Median_Motif_Length',\n        'Unique_Classes', 'Unique_Subclasses', 'Hybrids', 'Clusters',\n    ]]\n    _sp_summary.to_csv(str(sp_dir / 'within_species_summary.csv'))\n    print(f'\\n{species} \\u2014 Summary')\n    display(_sp_summary)\n\n# ── Cross-species comparison ──────────────────────────────────────────────────\nif len(_species_list) >= 2:\n    _xs_dir = _cmp_dir / '_cross_species'\n    _xs_dir.mkdir(exist_ok=True)\n\n    print(f'\\n{_sep}\\nCross-species comparison: {_species_list}\\n{_sep}')\n\n    _sp_region_sets = {\n        sp: set(_comp_df[_comp_df['Species'] == sp]['Region'])\n        for sp in _species_list\n    }\n    _shared_regions = sorted(set.intersection(*_sp_region_sets.values()))\n    _all_regions    = sorted(set.union(*_sp_region_sets.values()))\n    print(f'Shared regions : {_shared_regions}')\n    print(f'All regions    : {_all_regions}')\n\n    # 1. Density heatmap (species x region)\n    _dens_pivot = _comp_df.pivot_table(\n        index='Species', columns='Region',\n        values='Density_per_kb', aggfunc='mean')\n    if not _dens_pivot.empty:\n        fig, ax = plt.subplots(figsize=(max(8, len(_all_regions) * 1.4),\n                                        max(4, len(_species_list) * 0.8)))\n        sns.heatmap(_dens_pivot, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,\n                    linewidths=0.4, cbar_kws={'label': 'Motifs per kb'})\n        ax.set_title('Cross-Species \\u2014 Motif Density Heatmap (motifs per kb)')\n        ax.set_xlabel('Region'); ax.set_ylabel('Species')\n        _savefig(fig, _xs_dir / 'cross_species_density_heatmap.png', show=False)\n\n    # 2. Coverage heatmap (species x region)\n    _cov_pivot = _comp_df.pivot_table(\n        index='Species', columns='Region',\n        values='Coverage_pct', aggfunc='mean')\n    if not _cov_pivot.empty:\n        fig, ax = plt.subplots(figsize=(max(8, len(_all_regions) * 1.4),\n                                        max(4, len(_species_list) * 0.8)))\n        sns.heatmap(_cov_pivot, annot=True, fmt='.1f', cmap='Blues', ax=ax,\n                    linewidths=0.4, cbar_kws={'label': 'Coverage %'})\n        ax.set_title('Cross-Species \\u2014 Non-B DNA Coverage Heatmap (%)')\n        ax.set_xlabel('Region'); ax.set_ylabel('Species')\n        _savefig(fig, _xs_dir / 'cross_species_coverage_heatmap.png', show=False)\n\n    # 3. GC% heatmap (species x region)\n    _gc_pivot = _comp_df.pivot_table(\n        index='Species', columns='Region',\n        values='GC_Percent', aggfunc='mean')\n    if not _gc_pivot.empty:\n        fig, ax = plt.subplots(figsize=(max(8, len(_all_regions) * 1.4),\n                                        max(4, len(_species_list) * 0.8)))\n        sns.heatmap(_gc_pivot, annot=True, fmt='.1f', cmap='YlGn', ax=ax,\n                    linewidths=0.4, cbar_kws={'label': 'GC %'})\n        ax.set_title('Cross-Species \\u2014 GC Content Heatmap (%)')\n        ax.set_xlabel('Region'); ax.set_ylabel('Species')\n        _savefig(fig, _xs_dir / 'cross_species_gc_heatmap.png', show=False)\n\n    # 4. Class comparison per shared region\n    for region in _shared_regions:\n        _rc = {}\n        for stem in _comp_df[_comp_df['Region'] == region]['Stem']:\n            df = RESULTS_BY_FILE[stem]['df']\n            sp = _comp_df.loc[_comp_df['Stem'] == stem, 'Species'].values[0]\n            _rc[sp] = df['Class'].value_counts() if not df.empty else pd.Series(dtype=int)\n        _all_cls = sorted({c for s in _rc.values() for c in s.index})\n        if _all_cls:\n            _rmat = pd.DataFrame(\n                {sp: s.reindex(_all_cls, fill_value=0) for sp, s in _rc.items()}\n            ).T\n            fig, ax = plt.subplots(figsize=(max(8, len(_all_cls) * 1.2), 4))\n            _rmat.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n            ax.set_title(f'Cross-Species Class Comparison \\u2014 {region}')\n            ax.set_xlabel('Species'); ax.set_ylabel('Motif Count')\n            ax.legend(title='Class', bbox_to_anchor=(1, 1))\n            plt.xticks(rotation=30, ha='right')\n            _savefig(fig, _xs_dir / f'cross_species_class_{_safe_fname(region)}.png',\n                     show=False)\n\n    # 5. Length distribution for shared regions\n    _xs_len_parts = []\n    for stem, res in RESULTS_BY_FILE.items():\n        row = _comp_df[_comp_df['Stem'] == stem]\n        if row.empty:\n            continue\n        sp     = row['Species'].values[0]\n        region = row['Region'].values[0]\n        if region not in _shared_regions:\n            continue\n        df = res['df']\n        if not df.empty and 'Length' in df.columns:\n            tmp = df[['Length']].copy()\n            tmp['Species'] = sp\n            tmp['Region']  = region\n            _xs_len_parts.append(tmp)\n    if _xs_len_parts:\n        _xs_len_df = pd.concat(_xs_len_parts, ignore_index=True)\n        _xs_len_df = _xs_len_df[_xs_len_df['Length'] > 0]\n        if not _xs_len_df.empty:\n            _w = max(10, len(_shared_regions) * len(_species_list) * 1.5)\n            fig, ax = plt.subplots(figsize=(_w, 5))\n            sns.boxplot(data=_xs_len_df, x='Region', y='Length',\n                        hue='Species', ax=ax, palette='Set2')\n            ax.set_title('Cross-Species \\u2014 Motif Length Distribution by Region')\n            ax.set_xlabel('Region'); ax.set_ylabel('Motif Length (bp)')\n            plt.xticks(rotation=30, ha='right')\n            ax.legend(title='Species', bbox_to_anchor=(1, 1))\n            _savefig(fig, _xs_dir / 'cross_species_length_by_region.png', show=False)\n\n    # 6. Hybrid & Cluster cross-species\n    _xs_summary = _comp_df[[\n        'Species', 'Region', 'Total_Motifs', 'Seq_Length_bp',\n        'Density_per_kb', 'Coverage_pct', 'GC_Percent',\n        'Mean_Motif_Length', 'Median_Motif_Length',\n        'Unique_Classes', 'Unique_Subclasses', 'Hybrids', 'Clusters',\n    ]].sort_values(['Species', 'Region'])\n    _xs_summary.to_csv(str(_xs_dir / 'cross_species_summary.csv'), index=False)\n    print('\\nCross-Species Summary Table')\n    display(_xs_summary)\n\n# ─────────────────────────────────────────────────────────────────────────────\n# 8.  DOWNLOAD LINKS\n# ─────────────────────────────────────────────────────────────────────────────\nimport base64\n\n_MIME = {\n    'csv':  'text/csv',\n    'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n    'png':  'image/png',\n}\n\ndef _dl(path, label):\n    with open(path, 'rb') as fh:\n        b64 = base64.b64encode(fh.read()).decode()\n    ext  = Path(path).suffix.lstrip('.')\n    mime = _MIME.get(ext, 'application/octet-stream')\n    return (f'<a href=\"data:{mime};base64,{b64}\" download=\"{Path(path).name}\" '\n            f'style=\"margin:2px 6px;padding:3px 8px;border:1px solid #aaa;'\n            f'border-radius:4px;text-decoration:none;\">{label}</a>')\n\n_html = ['<h2>\\U0001f4e5 Downloads</h2><h3>Master Outputs</h3><div>']\nfor fmt, fn in [('CSV', 'master_motifs.csv'), ('Excel', 'master_motifs.xlsx')]:\n    p = _master_dir / fn\n    if p.exists(): _html.append(_dl(str(p), f'Master {fmt}'))\nif (_master_dir / 'gff_region_motifs_all.csv').exists():\n    _html.append(_dl(str(_master_dir / 'gff_region_motifs_all.csv'), 'GFF Regions CSV'))\n_html.append('</div><h3>Summary Tables</h3><div>')\nfor tn in _tables:\n    p = _master_dir / f'{tn}.csv'\n    if p.exists(): _html.append(_dl(str(p), tn.replace('_', ' ').title()))\n_html.append('</div><h3>Comparative Analysis</h3><div>')\nfor fn in ['all_comparisons_summary.csv', 'all_comparisons_summary.xlsx']:\n    p = _cmp_dir / fn\n    if p.exists(): _html.append(_dl(str(p), fn))\n_html.append('</div><h3>Per-File Outputs</h3>')\nfor stem, res in RESULTS_BY_FILE.items():\n    _html.append(f'<details style=\"margin:4px 0\"><summary><b>{stem}</b>'\n                 f' <em>[{res[\"file_type\"]}]</em></summary>'\n                 f'<div style=\"margin:4px 12px\">')\n    for fmt, fn in [('CSV', 'motifs.csv'), ('Excel', 'motifs.xlsx')]:\n        p = res['folder'] / fn\n        if p.exists(): _html.append(_dl(str(p), fmt))\n    for fn in sorted((res['folder']).glob('*.png')):\n        _html.append(_dl(str(fn), fn.stem.replace('_', ' ').title()))\n    _html.append('</div></details>')\n\ndisplay(HTML('\\n'.join(_html)))\nprint(f'\\n\\u2705 All outputs saved to: {_BASE}')\n"
  }
 ]
}