{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NonBDNA Finder — Analysis Notebook\n\n## Overview\nDetects and analyses **Non-B DNA structural motifs** in one or more FASTA files.  \nThe notebook is structured as **3 cells (tabs)**:\n\n| Cell | Purpose |\n|------|---------|\n| **Cell 1 · Setup** | Imports, user config, helpers, engine initialisation |\n| **Cell 2 · Analysis** | Detection, all statistics (class/subclass densities & coverages), plots, downloads |\n\nRun **Cell 1 first**, then **Cell 2**.\n\n---\n\n## Detectors — 9 classes, 23+ subclasses\n\n| Class | Key Subclasses |\n|---|---|\n| Curved DNA | Curved, Bent |\n| Slipped DNA | Direct-repeat, Mirror |\n| Cruciform | Cruciform |\n| R-Loop | R-loop, G-rich, C-rich |\n| Triplex | H-DNA, R·R·Y, Y·R·Y |\n| G-Quadruplex | G4, Parallel, Anti-parallel… |\n| i-Motif | iM-Canonical, iM-Partial, iM-C-rich |\n| Z-DNA | ZH-score, CG-repeat |\n| A-philic DNA | A-philic |\n\n---\n\n## Statistics produced\n\n| Table | Columns |\n|---|---|\n| **Per-file summary** | Sequences, bp, GC%, Motifs, Classes, Subclasses, Density/kb, Coverage% |\n| **Class statistics** | Count, Mean Length, Mean Score, **Density/kb**, **Coverage%** |\n| **Subclass statistics** | Count, Mean Length, Mean Score, **Density/kb**, **Coverage%** |\n| **File × Class pivot** | Motif counts per file per class |\n| **Class density pivot** | Density (motifs/kb) per file per class |\n| **Class coverage pivot** | Coverage (%) per file per class |\n\n## Plots produced\n- Class distribution (per-file + global)\n- Subclass distribution (per-file + global)\n- Density per class & per subclass\n- Coverage per class & per subclass\n- Density / coverage comparison across files\n- Hybrid & Cluster breakdown\n- Sequence-level density & coverage (multi-sequence files)\n- Positional distribution (equal-length multiFASTA)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ═══════════════════════════════════════════════════════════════════════════════\n# CELL 1 · SETUP — imports, configuration, helpers\n# Edit FASTA_INPUT and OUTPUT_DIR, then run this cell before Cell 2.\n# ═══════════════════════════════════════════════════════════════════════════════\n\nimport sys, os, importlib, glob, gc, time, datetime, re, warnings\nimport concurrent.futures\nfrom pathlib import Path\nfrom collections import defaultdict\nwarnings.filterwarnings('ignore')\n\n_REPO_ROOT = os.path.abspath(os.getcwd())\nif _REPO_ROOT not in sys.path:\n    sys.path.insert(0, _REPO_ROOT)\n\n# ── Auto-install missing packages ─────────────────────────────────────────────\n_REQUIRED = [('psutil','psutil>=5.8'),('pandas','pandas>=1.3'),('numpy','numpy>=1.21'),\n             ('matplotlib','matplotlib>=3.5'),('seaborn','seaborn>=0.11'),\n             ('openpyxl','openpyxl>=3.0'),('tqdm','tqdm>=4.64')]\n_miss = [p for m,p in _REQUIRED if importlib.util.find_spec(m) is None]\nif _miss:\n    import subprocess; subprocess.check_call([sys.executable,'-m','pip','install',*_miss,'-q'])\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib; matplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom IPython.display import display, HTML, Image\nsns.set_theme(style='whitegrid')\n\n# ── USER CONFIGURATION ────────────────────────────────────────────────────────\nFASTA_INPUT        = ['*.fna', '*.fasta']   # path, wildcard, or list\nOUTPUT_DIR         = 'notebook_reports'\nENABLED_CLASSES    = None                   # None = all; e.g. ['G-Quadruplex','Z-DNA']\nRAM_OVERRIDE_BYTES = None                   # None = auto\n\n# ── GPU detection ─────────────────────────────────────────────────────────────\ndef _detect_gpu():\n    for lib, attr in [('torch','cuda'),('cupy',None)]:\n        try:\n            m = importlib.import_module(lib)\n            if lib == 'torch' and m.cuda.is_available():\n                return 'cuda', m.cuda.get_device_name(0)\n            elif lib == 'cupy':\n                m.array([1]); return 'cupy', 'CUDA GPU'\n        except Exception:\n            pass\n    return None, None\n\nGPU_BACKEND, GPU_NAME = _detect_gpu()\nprint(f'\\u2705 Deps OK | Python {sys.version.split()[0]} | '\n      f'GPU: {GPU_BACKEND+\"(\"+GPU_NAME+\")\" if GPU_BACKEND else \"none (CPU)\"}')\n\n# ── Resolve FASTA files & classify types ─────────────────────────────────────\ndef _resolve(inp):\n    out = []\n    for p in ([inp] if isinstance(inp, str) else list(inp)):\n        hits = glob.glob(p); out.extend(hits)\n        if not hits and os.path.isfile(p): out.append(p)\n    return sorted({str(Path(f).resolve()) for f in out})\n\ndef _seq_lengths(p):\n    L, c = [], 0\n    with open(p) as fh:\n        for ln in fh:\n            s = ln.strip()\n            if s.startswith('>'):\n                if c: L.append(c); c = 0\n            else: c += len(s)\n    if c: L.append(c)\n    return L\n\nFASTA_FILES = _resolve(FASTA_INPUT)\nif not FASTA_FILES:\n    raise FileNotFoundError(f'No FASTA files found for: {FASTA_INPUT}')\n\nFILE_TYPES = {}\nfor fp in FASTA_FILES:\n    ls = _seq_lengths(fp)\n    FILE_TYPES[fp] = ('single' if len(ls)==1 else\n                      'multi_equal' if len(set(ls))==1 else 'multi')\n\nGFF_MAP = {}\nfor fp in FASTA_FILES:\n    stem, parent = Path(fp).stem, Path(fp).parent\n    for ext in ('.gff3','.gff'):\n        cand = parent/(stem+ext)\n        if cand.exists(): GFF_MAP[fp] = str(cand); break\n\nprint(f'\\n\\U0001f4c2 Input files: {len(FASTA_FILES)}')\nfor fp in FASTA_FILES:\n    gff_tag = f'  +GFF: {Path(GFF_MAP[fp]).name}' if fp in GFF_MAP else ''\n    print(f'   [{FILE_TYPES[fp]:12s}]  {Path(fp).name}{gff_tag}')\n\n# ── Adaptive resource planning ────────────────────────────────────────────────\nfrom Utilities.system_resource_inspector import SystemResourceInspector\nfrom Utilities.adaptive_chunk_planner    import AdaptiveChunkPlanner\nfrom Utilities.nonbscanner               import analyze_sequence as _nbf_analyze\nfrom Utilities.utilities                 import read_fasta_file\n\n_insp   = SystemResourceInspector()\n_budget = RAM_OVERRIDE_BYTES or _insp.get_memory_budget()\n_cpus   = _insp.get_cpu_count()\n_total  = max(sum(os.path.getsize(f) for f in FASTA_FILES if os.path.exists(f)), 1_000)\n_plan   = AdaptiveChunkPlanner().plan(_total, _budget, _cpus)\nCHUNK_SIZE, CHUNK_OVERLAP = _plan['chunk_size'], _plan['overlap']\nN_WORKERS, EXEC_MODE      = _plan['workers'], _plan['mode']\nif GPU_BACKEND:\n    N_WORKERS = min(N_WORKERS * 2, os.cpu_count() or 4)\n\n_RUN_TS = datetime.datetime.now(datetime.timezone.utc).strftime('%Y%m%d_%H%M%S')\n_BASE   = Path(OUTPUT_DIR) / _RUN_TS\n_BASE.mkdir(parents=True, exist_ok=True)\nprint(f'\\u2699\\ufe0f  RAM {_budget/1e9:.2f}GB | chunk={CHUNK_SIZE:,} overlap={CHUNK_OVERLAP:,} '\n      f'workers={N_WORKERS} mode={EXEC_MODE}')\nprint(f'\\U0001f4c2 Run output: {_BASE}')\n\n# ── Core helpers ──────────────────────────────────────────────────────────────\ndef _scan(name, seq):\n    return _nbf_analyze(sequence=seq, sequence_name=name, use_chunking=True,\n                        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP,\n                        use_parallel_chunks=(EXEC_MODE=='hybrid'),\n                        enabled_classes=ENABLED_CLASSES)\n\ndef _savefig(fig, path, show=True):\n    fig.savefig(str(path), dpi=150, bbox_inches='tight'); plt.close(fig)\n    if show: display(Image(str(path)))\n\ndef _safe_fname(s): return re.sub(r'[^\\w\\-]', '_', str(s))\n\ndef _parse_species_region(stem):\n    idx = stem.find('_')\n    return (stem, 'unknown') if idx == -1 else (stem[:idx], stem[idx+1:])\n\ndef _gc_and_length(fasta_path):\n    gc = total = 0\n    with open(fasta_path) as fh:\n        for ln in fh:\n            s = ln.strip()\n            if not s or s.startswith('>'): continue\n            su = s.upper(); gc += su.count('G') + su.count('C'); total += len(su)\n    return (round(gc/total*100, 2) if total else 0.0), total\n\ndef _merge_coverage(intervals, cap=None):\n    \"\"\"Sum of merged interval lengths; optionally capped at cap.\"\"\"\n    if len(intervals) == 0: return 0\n    intervals = np.array(intervals, dtype=int)\n    if cap is not None:\n        intervals[:,1] = np.minimum(intervals[:,1], cap)\n    intervals = intervals[intervals[:,1] > intervals[:,0]]\n    if len(intervals) == 0: return 0\n    intervals = intervals[np.argsort(intervals[:,0])]\n    s, e = intervals[0]; covered = 0\n    for cs, ce in intervals[1:]:\n        if cs <= e: e = max(e, ce)\n        else: covered += e-s; s,e = cs,ce\n    return covered + e - s\n\ndef _coverage(df, seq_lengths_dict):\n    \"\"\"Overall coverage % across all sequences.\"\"\"\n    if df.empty or not seq_lengths_dict: return 0.0\n    total_len = sum(seq_lengths_dict.values())\n    if total_len == 0: return 0.0\n    covered = sum(\n        _merge_coverage(grp[['Start','End']].values, cap=seq_lengths_dict.get(sn, 0))\n        for sn, grp in df.groupby('Sequence_Name')\n    )\n    return round(covered / total_len * 100, 2)\n\ndef _class_density_coverage(df, all_results):\n    \"\"\"Return dict: class -> {Density_per_kb, Coverage_pct} across all files.\"\"\"\n    total_bp = sum(sum(r['seq_lengths'].values()) for r in all_results.values())\n    if total_bp == 0 or df.empty: return {}\n    out = {}\n    for cls, grp in df.groupby('Class'):\n        cov_bp = 0\n        for stem, res in all_results.items():\n            sub = grp[grp['Source_File'] == Path(res['path']).name]\n            if sub.empty: continue\n            for sn, sg in sub.groupby('Sequence_Name'):\n                sq_len = res['seq_lengths'].get(sn, 0)\n                cov_bp += _merge_coverage(sg[['Start','End']].values, cap=sq_len)\n        out[cls] = {'Density_per_kb': round(len(grp)/total_bp*1000, 4),\n                    'Coverage_pct':   round(cov_bp/total_bp*100, 3)}\n    return out\n\ndef _subclass_density_coverage(df, all_results):\n    \"\"\"Return dict: subclass -> {Density_per_kb, Coverage_pct} across all files.\"\"\"\n    total_bp = sum(sum(r['seq_lengths'].values()) for r in all_results.values())\n    if total_bp == 0 or df.empty: return {}\n    out = {}\n    for sc, grp in df.groupby('Subclass'):\n        cov_bp = 0\n        for stem, res in all_results.items():\n            sub = grp[grp['Source_File'] == Path(res['path']).name]\n            if sub.empty: continue\n            for sn, sg in sub.groupby('Sequence_Name'):\n                sq_len = res['seq_lengths'].get(sn, 0)\n                cov_bp += _merge_coverage(sg[['Start','End']].values, cap=sq_len)\n        out[sc] = {'Density_per_kb': round(len(grp)/total_bp*1000, 4),\n                   'Coverage_pct':   round(cov_bp/total_bp*100, 3)}\n    return out\n\ndef _parse_gff(gff_path):\n    feats = []\n    with open(gff_path) as fh:\n        for ln in fh:\n            if ln.startswith('#') or not ln.strip(): continue\n            p = ln.rstrip('\\n').split('\\t')\n            if len(p) < 8: continue\n            try:\n                feats.append({'seqid':p[0],'type':p[2],'start':max(int(p[3])-1,0),\n                              'end':int(p[4]),'strand':p[6],\n                              'attrs':p[8] if len(p)>8 else ''})\n            except ValueError: pass\n    return feats\n\nprint('\\u2705 Engine Ready')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ═══════════════════════════════════════════════════════════════════════════════\n# CELL 2 · ANALYSIS — detection, all statistics, plots, downloads\n# Run Cell 1 first.\n# ═══════════════════════════════════════════════════════════════════════════════\n\nRESULTS_BY_FILE = {}   # stem -> {df, folder, file_type, path, seq_lengths}\nGFF_RESULTS     = {}   # stem -> {region_df, gff_path, folder}\n\n# ─────────────────────────────────────────────────────────────────────────────\n# A. PER-FILE DETECTION\n# ─────────────────────────────────────────────────────────────────────────────\nfor fasta_path in tqdm(FASTA_FILES, desc='Files', unit='file'):\n    stem    = Path(fasta_path).stem\n    ftype   = FILE_TYPES[fasta_path]\n    fdir    = _BASE / stem\n    fdir.mkdir(parents=True, exist_ok=True)\n    tqdm.write(f'\\n\\u2500\\u2500 {stem}  [{ftype}] \\u2500\\u2500')\n\n    seqs = read_fasta_file(fasta_path)\n    if not seqs:\n        tqdm.write('  \\u26a0\\ufe0f  No sequences — skipping.')\n        continue\n\n    sl_map = {sn: len(sq) for sn, sq in seqs.items()}  # seq_name -> length\n\n    # Parallel motif scanning\n    motifs_file, t0 = [], time.perf_counter()\n    with concurrent.futures.ThreadPoolExecutor(max_workers=N_WORKERS) as pool:\n        futs = {pool.submit(_scan, sn, sq): sn for sn, sq in seqs.items()}\n        for fut in tqdm(concurrent.futures.as_completed(futs),\n                        total=len(futs), desc=f'  seqs({stem})', leave=False):\n            sn  = futs[fut]; res = fut.result()\n            tqdm.write(f'  \\u25b8 {sn[:55]}  \\u2192 {len(res):,} motifs')\n            motifs_file.extend(res)\n    tqdm.write(f'  \\u2705 {len(motifs_file):,} motifs in {time.perf_counter()-t0:.1f}s')\n    gc.collect()\n\n    # Build DataFrame\n    df = pd.DataFrame(motifs_file) if motifs_file else pd.DataFrame()\n    for col, dflt in [('Class','Unknown'),('Subclass','Other'),('Start',0),\n                      ('End',0),('Length',0),('Score',0.0),('Strand','+'),('Sequence_Name','')]:\n        if col not in df.columns: df[col] = dflt\n    if not df.empty:\n        df['Length'] = np.where(df['Length']==0,\n                                (df['End']-df['Start']).clip(lower=0), df['Length'])\n    df['Source_File'] = Path(fasta_path).name\n    df['File_Type']   = ftype\n\n    # Save CSV + Excel\n    if not df.empty:\n        df.to_csv(str(fdir/'motifs.csv'), encoding='utf-8-sig', index=False)\n        df.to_excel(str(fdir/'motifs.xlsx'), index=False)\n\n    # ── Per-file inline plots ─────────────────────────────────────────────────\n    if not df.empty:\n        total_bp = max(sum(sl_map.values()), 1)\n\n        # 1. Class distribution\n        cc = df['Class'].value_counts()\n        fig, ax = plt.subplots(figsize=(8, max(3, len(cc)*0.45)))\n        ax.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n        ax.set_xlabel('Motif Count')\n        ax.set_title(f'{stem} [{ftype}] — Class Distribution')\n        for i,v in enumerate(cc.values[::-1]): ax.text(v+0.3, i, str(v), va='center', fontsize=8)\n        plt.tight_layout(); _savefig(fig, fdir/'class_distribution.png')\n\n        # 2. Subclass distribution (top 30)\n        sc = df['Subclass'].value_counts().head(30)\n        fig, ax = plt.subplots(figsize=(8, max(3, len(sc)*0.4)))\n        ax.barh(sc.index[::-1], sc.values[::-1], color='darkorange')\n        ax.set_xlabel('Motif Count')\n        ax.set_title(f'{stem} — Subclass Distribution (top 30)')\n        plt.tight_layout(); _savefig(fig, fdir/'subclass_distribution.png')\n\n        # 3. Class density (motifs/kb)\n        cls_dens = df.groupby('Class').apply(\n            lambda g: round(len(g)/total_bp*1000, 4)).sort_values(ascending=False)\n        fig, ax = plt.subplots(figsize=(8, max(3, len(cls_dens)*0.45)))\n        ax.barh(cls_dens.index[::-1], cls_dens.values[::-1], color='teal')\n        ax.set_xlabel('Motifs per kb'); ax.set_title(f'{stem} — Class Density (motifs/kb)')\n        for i,v in enumerate(cls_dens.values[::-1]): ax.text(v, i, f'{v:.4f}', va='center', fontsize=8)\n        plt.tight_layout(); _savefig(fig, fdir/'class_density.png')\n\n        # 4. Class coverage (%)\n        cls_cov = {}\n        for cls, grp in df.groupby('Class'):\n            cov = sum(_merge_coverage(sg[['Start','End']].values, cap=sl_map.get(sn,0))\n                      for sn, sg in grp.groupby('Sequence_Name'))\n            cls_cov[cls] = round(cov/total_bp*100, 3)\n        _cov_s = pd.Series(cls_cov).sort_values(ascending=False)\n        fig, ax = plt.subplots(figsize=(8, max(3, len(_cov_s)*0.45)))\n        ax.barh(_cov_s.index[::-1], _cov_s.values[::-1], color='mediumseagreen')\n        ax.set_xlabel('Coverage (%)'); ax.set_title(f'{stem} — Class Coverage (%)')\n        ax.set_xlim(0, min(100, _cov_s.max()*1.15+0.5))\n        for i,v in enumerate(_cov_s.values[::-1]): ax.text(v, i, f'{v:.3f}%', va='center', fontsize=8)\n        plt.tight_layout(); _savefig(fig, fdir/'class_coverage.png')\n\n        # 5. Subclass density (top 20)\n        sc_dens = df.groupby('Subclass').apply(\n            lambda g: round(len(g)/total_bp*1000, 4)).nlargest(20)\n        fig, ax = plt.subplots(figsize=(8, max(3, len(sc_dens)*0.4)))\n        ax.barh(sc_dens.index[::-1], sc_dens.values[::-1], color='coral')\n        ax.set_xlabel('Motifs per kb'); ax.set_title(f'{stem} — Subclass Density (top 20, motifs/kb)')\n        plt.tight_layout(); _savefig(fig, fdir/'subclass_density.png')\n\n        # 6. Subclass coverage (top 20 by coverage)\n        sc_cov = {}\n        for sc_name, grp in df.groupby('Subclass'):\n            cov = sum(_merge_coverage(sg[['Start','End']].values, cap=sl_map.get(sn,0))\n                      for sn, sg in grp.groupby('Sequence_Name'))\n            sc_cov[sc_name] = round(cov/total_bp*100, 3)\n        _scov_s = pd.Series(sc_cov).nlargest(20)\n        fig, ax = plt.subplots(figsize=(8, max(3, len(_scov_s)*0.4)))\n        ax.barh(_scov_s.index[::-1], _scov_s.values[::-1], color='orchid')\n        ax.set_xlabel('Coverage (%)'); ax.set_title(f'{stem} — Subclass Coverage (top 20, %)')\n        plt.tight_layout(); _savefig(fig, fdir/'subclass_coverage.png')\n\n        # 7. Hybrid & Cluster breakdown\n        _special = df[df['Class'].isin(['Hybrid','Non-B_DNA_Clusters'])]\n        if not _special.empty:\n            sp_cnt = _special['Class'].value_counts()\n            fig, ax = plt.subplots(figsize=(6,3))\n            ax.bar(sp_cnt.index, sp_cnt.values, color=['tomato','mediumpurple'])\n            ax.set_ylabel('Count'); ax.set_title(f'{stem} — Hybrid & Cluster Motifs')\n            for i,v in enumerate(sp_cnt.values): ax.text(i, v+0.2, str(v), ha='center', fontsize=9)\n            plt.tight_layout(); _savefig(fig, fdir/'hybrid_cluster_breakdown.png')\n\n        # 8. Sequence-level density & coverage (multi-seq)\n        if ftype in ('multi','multi_equal'):\n            _rows_d, _rows_c = [], []\n            for sn, sq_len in sl_map.items():\n                sub = df[df['Sequence_Name']==sn]\n                n   = len(sub)\n                cov = (_merge_coverage(sub[['Start','End']].values, cap=sq_len)\n                       if not sub.empty else 0)\n                _rows_d.append({'Sequence':sn[:40],'Density_per_kb':round(n/sq_len*1000,4) if sq_len else 0})\n                _rows_c.append({'Sequence':sn[:40],'Coverage_pct':round(cov/sq_len*100,2) if sq_len else 0})\n\n            _dd = pd.DataFrame(_rows_d).sort_values('Density_per_kb',ascending=False).head(40)\n            fig, ax = plt.subplots(figsize=(9, max(4, len(_dd)*0.35)))\n            ax.barh(_dd['Sequence'][::-1], _dd['Density_per_kb'][::-1], color='teal')\n            ax.set_xlabel('Motifs per kb'); ax.set_title(f'{stem} — Motif Density by Sequence (top 40)')\n            plt.tight_layout(); _savefig(fig, fdir/'motif_density_by_sequence.png')\n\n            _cd = pd.DataFrame(_rows_c).sort_values('Coverage_pct',ascending=False).head(40)\n            fig, ax = plt.subplots(figsize=(9, max(4, len(_cd)*0.35)))\n            ax.barh(_cd['Sequence'][::-1], _cd['Coverage_pct'][::-1], color='mediumseagreen')\n            ax.set_xlabel('Coverage (%)'); ax.set_title(f'{stem} — Non-B DNA Coverage by Sequence (top 40)')\n            ax.set_xlim(0,100); plt.tight_layout(); _savefig(fig, fdir/'sequence_coverage.png')\n\n        # 9. Positional distribution (equal-length multiFASTA)\n        if ftype == 'multi_equal':\n            seq_len_val = list(sl_map.values())[0]\n            for cls in df['Class'].unique():\n                starts = df[df['Class']==cls]['Start'].dropna().astype(int)\n                starts = starts[starts < seq_len_val]\n                if starts.empty: continue\n                fig, ax = plt.subplots(figsize=(10,3))\n                ax.hist(starts, bins=min(100,seq_len_val), color='steelblue', alpha=0.8, edgecolor='none')\n                ax.set_xlabel('Position (bp)'); ax.set_ylabel('Frequency')\n                ax.set_title(f'{stem} — {cls} Positional Distribution (n={len(starts):,})')\n                ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x,_: f'{int(x):,}'))\n                plt.tight_layout(); _savefig(fig, fdir/f'positional_dist_{_safe_fname(cls)}.png', show=False)\n\n        tqdm.write(f'  \\U0001f4ca Plots saved: {fdir}')\n\n    RESULTS_BY_FILE[stem] = {\n        'df':df, 'folder':fdir, 'file_type':ftype,\n        'path':fasta_path, 'seq_lengths':sl_map\n    }\n\n    # GFF region analysis\n    if fasta_path in GFF_MAP:\n        gff_path = GFF_MAP[fasta_path]\n        tqdm.write(f'  \\U0001f4cb GFF: {Path(gff_path).name}')\n        features = _parse_gff(gff_path)\n        gff_dir  = fdir/'gff_regions'; gff_dir.mkdir(exist_ok=True)\n        region_rows = []\n        for ftype_gff in tqdm(sorted({f['type'] for f in features}),\n                              desc=f'  GFF({stem})', leave=False):\n            type_feats  = [f for f in features if f['type']==ftype_gff]\n            type_motifs = []\n            for feat in type_feats:\n                sid = feat['seqid']\n                if sid not in seqs: continue\n                rseq = seqs[sid][feat['start']:feat['end']]\n                if len(rseq) < 12: continue\n                rname = f\"{sid}:{ftype_gff}:{feat['start']}-{feat['end']}({feat['strand']})\"\n                for m in _scan(rname, rseq):\n                    m.update({'GFF_Type':ftype_gff,'GFF_SeqID':sid,\n                               'GFF_Start':feat['start'],'GFF_End':feat['end'],\n                               'GFF_Strand':feat['strand'],\n                               'GFF_Attrs':feat['attrs'][:80]})\n                    type_motifs.append(m)\n            region_rows.extend(type_motifs)\n            gc.collect()\n        gff_df = pd.DataFrame(region_rows) if region_rows else pd.DataFrame()\n        for col, dflt in [('Class','Unknown'),('Subclass','Other'),('Start',0),\n                          ('End',0),('Length',0),('Score',0.0),\n                          ('GFF_Type',''),('GFF_SeqID',''),('GFF_Start',0),\n                          ('GFF_End',0),('GFF_Strand','+'),('GFF_Attrs','')]:\n            if col not in gff_df.columns: gff_df[col] = dflt\n        if not gff_df.empty:\n            gff_df.to_csv(str(gff_dir/'gff_region_motifs.csv'), encoding='utf-8-sig', index=False)\n            pivot = gff_df.groupby(['GFF_Type','Class']).size().unstack(fill_value=0)\n            fig, ax = plt.subplots(figsize=(max(8,len(pivot)*1.4), 5))\n            pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n            ax.set_xlabel('GFF Feature Type'); ax.set_ylabel('Motif Count')\n            ax.set_title(f'{stem} — Motifs per GFF Feature Type')\n            ax.legend(title='Class', bbox_to_anchor=(1,1)); plt.tight_layout()\n            _savefig(fig, gff_dir/'gff_motifs_by_type.png', show=False)\n        GFF_RESULTS[stem] = {'region_df':gff_df,'gff_path':gff_path,'folder':gff_dir}\n        tqdm.write(f'  \\u2705 GFF: {len(gff_df):,} region motifs')\n\nprint(f'\\n\\u2705 Detection complete — {len(RESULTS_BY_FILE)} file(s) '\n      f'({len(GFF_RESULTS)} with GFF)')\n\n# ─────────────────────────────────────────────────────────────────────────────\n# B. MASTER TABLES & GLOBAL STATISTICS\n# ─────────────────────────────────────────────────────────────────────────────\n_dfs       = [r['df'] for r in RESULTS_BY_FILE.values() if not r['df'].empty]\n_master_df = pd.concat(_dfs, ignore_index=True) if _dfs else pd.DataFrame()\n_master_dir = _BASE / '_master'; _master_dir.mkdir(exist_ok=True)\n_gdfs   = [v['region_df'] for v in GFF_RESULTS.values() if not v['region_df'].empty]\n_gff_df = pd.concat(_gdfs, ignore_index=True) if _gdfs else pd.DataFrame()\n_tables = {}\n\nif not _master_df.empty:\n    total_bp_all = max(sum(sum(r['seq_lengths'].values())\n                           for r in RESULTS_BY_FILE.values()), 1)\n\n    # Table 1: Global class distribution (file × class counts)\n    _tables['1_global_class_distribution'] = (\n        _master_df.groupby(['Source_File','File_Type','Class'])\n        .size().reset_index(name='Count'))\n\n    # Table 2: Per-file summary\n    _pf_rows = []\n    for stem, res in RESULTS_BY_FILE.items():\n        df, fp, ftype_v, sl = res['df'], res['path'], res['file_type'], res['seq_lengths']\n        gc_pct, seq_len = _gc_and_length(fp)\n        n = len(df)\n        _pf_rows.append({\n            'File':           Path(fp).name,\n            'File_Type':      ftype_v,\n            'Sequences':      len(sl),\n            'Total_bp':       seq_len,\n            'GC_Percent':     gc_pct,\n            'Total_Motifs':   n,\n            'Classes':        df['Class'].nunique()    if not df.empty else 0,\n            'Subclasses':     df['Subclass'].nunique() if not df.empty else 0,\n            'Hybrids':        int((df['Class']=='Hybrid').sum())             if not df.empty else 0,\n            'Clusters':       int((df['Class']=='Non-B_DNA_Clusters').sum()) if not df.empty else 0,\n            'Density_per_kb': round(n/seq_len*1000,4) if seq_len else 0.0,\n            'Coverage_pct':   _coverage(df, sl),\n        })\n    _tables['2_per_file_summary'] = pd.DataFrame(_pf_rows)\n\n    # Table 3: Class statistics WITH density and coverage\n    _cls_dc = _class_density_coverage(_master_df, RESULTS_BY_FILE)\n    _tables['3_class_statistics'] = (\n        _master_df.groupby('Class')\n        .agg(Total_Count=('Class','count'),\n             Mean_Length=('Length','mean'),\n             Mean_Score=('Score','mean'))\n        .round(3).reset_index()\n        .assign(Density_per_kb=lambda d: d['Class'].map(\n                    lambda c: _cls_dc.get(c,{}).get('Density_per_kb',0)),\n                Coverage_pct=lambda d: d['Class'].map(\n                    lambda c: _cls_dc.get(c,{}).get('Coverage_pct',0)))\n        .sort_values('Total_Count', ascending=False)\n        [['Class','Total_Count','Mean_Length','Mean_Score','Density_per_kb','Coverage_pct']]\n    )\n\n    # Table 4: File × Class pivot (counts)\n    _tables['4_file_class_pivot'] = (\n        _master_df.groupby(['Source_File','Class'])\n        .size().unstack(fill_value=0).reset_index())\n\n    # Table 5: Subclass statistics WITH density and coverage\n    _sc_dc = _subclass_density_coverage(_master_df, RESULTS_BY_FILE)\n    _tables['5_subclass_statistics'] = (\n        _master_df.groupby('Subclass')\n        .agg(Total_Count=('Subclass','count'),\n             Mean_Length=('Length','mean'),\n             Mean_Score=('Score','mean'))\n        .round(3).reset_index()\n        .assign(Density_per_kb=lambda d: d['Subclass'].map(\n                    lambda s: _sc_dc.get(s,{}).get('Density_per_kb',0)),\n                Coverage_pct=lambda d: d['Subclass'].map(\n                    lambda s: _sc_dc.get(s,{}).get('Coverage_pct',0)))\n        .sort_values('Total_Count', ascending=False)\n        [['Subclass','Total_Count','Mean_Length','Mean_Score','Density_per_kb','Coverage_pct']]\n    )\n\n    # Table 6: Class density pivot (density per file per class)\n    _dens_rows_t = []\n    for (fname, cls), grp in _master_df.groupby(['Source_File','Class']):\n        stem = Path(fname).stem\n        res  = RESULTS_BY_FILE.get(stem, {})\n        slen = max(sum(res.get('seq_lengths',{1:1}).values()),1)\n        _dens_rows_t.append({'Source_File':fname,'Class':cls,\n                              'Density_per_kb':round(len(grp)/slen*1000,4)})\n    _tables['6_class_density_pivot'] = (\n        pd.DataFrame(_dens_rows_t)\n        .pivot_table(index='Source_File',columns='Class',\n                     values='Density_per_kb',fill_value=0).reset_index())\n\n    # Table 7: Class coverage pivot (coverage % per file per class)\n    _cov_rows_t = []\n    for fname in _master_df['Source_File'].unique():\n        stem = Path(fname).stem\n        res  = RESULTS_BY_FILE.get(stem)\n        if not res: continue\n        sub_file = _master_df[_master_df['Source_File']==fname]\n        slen = max(sum(res['seq_lengths'].values()),1)\n        for cls, grp in sub_file.groupby('Class'):\n            cov = sum(_merge_coverage(sg[['Start','End']].values, cap=res['seq_lengths'].get(sn,0))\n                      for sn, sg in grp.groupby('Sequence_Name'))\n            _cov_rows_t.append({'Source_File':fname,'Class':cls,\n                                 'Coverage_pct':round(cov/slen*100,3)})\n    _tables['7_class_coverage_pivot'] = (\n        pd.DataFrame(_cov_rows_t)\n        .pivot_table(index='Source_File',columns='Class',\n                     values='Coverage_pct',fill_value=0).reset_index())\n\n    # Equal-length positional table\n    _eq_dfs = [r['df'] for r in RESULTS_BY_FILE.values()\n               if r['file_type']=='multi_equal' and not r['df'].empty]\n    if _eq_dfs:\n        _eq = pd.concat(_eq_dfs, ignore_index=True)\n        _tables['8_equal_length_positional'] = (\n            _eq.groupby(['Source_File','Class','Start'])\n            .size().reset_index(name='Frequency')\n            .sort_values(['Source_File','Class','Frequency'], ascending=[True,True,False]))\n\nif not _gff_df.empty:\n    _tables['9_gff_motifs_per_feature'] = (\n        _gff_df.groupby(['GFF_Type','Class']).size().reset_index(name='Count')\n        .sort_values('Count',ascending=False))\n    _tables['10_gff_density_per_feature'] = (\n        _gff_df.assign(Region_Len=(_gff_df['GFF_End']-_gff_df['GFF_Start']).clip(lower=1))\n        .groupby('GFF_Type')\n        .agg(Total_Motifs=('Class','count'),Unique_Classes=('Class','nunique'),\n             Mean_Region_Len=('Region_Len','mean'))\n        .round(2).reset_index().sort_values('Total_Motifs',ascending=False))\n\n# Export all tables + master CSVs\nif not _master_df.empty:\n    _master_df.to_csv(str(_master_dir/'master_motifs.csv'), encoding='utf-8-sig', index=False)\n    _master_df.to_excel(str(_master_dir/'master_motifs.xlsx'), index=False)\nif not _gff_df.empty:\n    _gff_df.to_csv(str(_master_dir/'gff_region_motifs_all.csv'), encoding='utf-8-sig', index=False)\nfor tname, tdf in _tables.items():\n    tdf.to_csv(str(_master_dir/f'{tname}.csv'), encoding='utf-8-sig', index=False)\n\n# ─────────────────────────────────────────────────────────────────────────────\n# C. GLOBAL SUMMARY PLOTS (all inline)\n# ─────────────────────────────────────────────────────────────────────────────\nif not _master_df.empty:\n    _pf_summary = _tables.get('2_per_file_summary', pd.DataFrame())\n    _n_files    = len(RESULTS_BY_FILE)\n\n    # (a) Global class distribution\n    cc = _master_df['Class'].value_counts()\n    fig, ax = plt.subplots(figsize=(8, max(3, len(cc)*0.45)))\n    ax.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n    ax.set_xlabel('Count'); ax.set_title('Global Class Distribution')\n    for i,v in enumerate(cc.values[::-1]): ax.text(v+0.3, i, str(v), va='center', fontsize=8)\n    plt.tight_layout(); _savefig(fig, _master_dir/'global_class_distribution.png')\n\n    # (b) Global class density (motifs/kb)\n    cls_stat = _tables['3_class_statistics'].set_index('Class')['Density_per_kb']\n    fig, ax = plt.subplots(figsize=(8, max(3, len(cls_stat)*0.45)))\n    ax.barh(cls_stat.index[::-1], cls_stat.values[::-1], color='teal')\n    ax.set_xlabel('Motifs per kb'); ax.set_title('Global Class Density (motifs/kb)')\n    for i,v in enumerate(cls_stat.values[::-1]): ax.text(v, i, f'{v:.4f}', va='center', fontsize=8)\n    plt.tight_layout(); _savefig(fig, _master_dir/'global_class_density.png')\n\n    # (c) Global class coverage (%)\n    cls_cov_s = _tables['3_class_statistics'].set_index('Class')['Coverage_pct']\n    fig, ax = plt.subplots(figsize=(8, max(3, len(cls_cov_s)*0.45)))\n    ax.barh(cls_cov_s.index[::-1], cls_cov_s.values[::-1], color='mediumseagreen')\n    ax.set_xlabel('Coverage (%)'); ax.set_title('Global Class Coverage (%)')\n    for i,v in enumerate(cls_cov_s.values[::-1]): ax.text(v, i, f'{v:.3f}%', va='center', fontsize=8)\n    plt.tight_layout(); _savefig(fig, _master_dir/'global_class_coverage.png')\n\n    # (d) Global subclass distribution (top 30)\n    sc_all = _master_df['Subclass'].value_counts().head(30)\n    fig, ax = plt.subplots(figsize=(8, max(4, len(sc_all)*0.4)))\n    ax.barh(sc_all.index[::-1], sc_all.values[::-1], color='darkorange')\n    ax.set_xlabel('Count'); ax.set_title('Global Subclass Distribution (top 30)')\n    plt.tight_layout(); _savefig(fig, _master_dir/'global_subclass_distribution.png')\n\n    # (e) Global subclass density (top 20)\n    sc_dens_all = _tables['5_subclass_statistics'].set_index('Subclass')['Density_per_kb'].nlargest(20)\n    fig, ax = plt.subplots(figsize=(8, max(3, len(sc_dens_all)*0.4)))\n    ax.barh(sc_dens_all.index[::-1], sc_dens_all.values[::-1], color='coral')\n    ax.set_xlabel('Motifs per kb'); ax.set_title('Global Subclass Density (top 20, motifs/kb)')\n    plt.tight_layout(); _savefig(fig, _master_dir/'global_subclass_density.png')\n\n    # (f) Global subclass coverage (top 20)\n    sc_cov_all = _tables['5_subclass_statistics'].set_index('Subclass')['Coverage_pct'].nlargest(20)\n    fig, ax = plt.subplots(figsize=(8, max(3, len(sc_cov_all)*0.4)))\n    ax.barh(sc_cov_all.index[::-1], sc_cov_all.values[::-1], color='orchid')\n    ax.set_xlabel('Coverage (%)'); ax.set_title('Global Subclass Coverage (top 20, %)')\n    plt.tight_layout(); _savefig(fig, _master_dir/'global_subclass_coverage.png')\n\n    # (g) File-level density & coverage comparison\n    if not _pf_summary.empty:\n        for col, label, color, title in [\n            ('Density_per_kb','Motifs per kb','steelblue','Motif Density Comparison Across Files'),\n            ('Coverage_pct',  'Coverage (%)','mediumseagreen','Non-B DNA Coverage Comparison Across Files'),\n        ]:\n            _pfs = _pf_summary.sort_values(col, ascending=False)\n            fig, ax = plt.subplots(figsize=(max(6, len(_pfs)*1.4), 4))\n            bars = ax.bar(_pfs['File'].apply(lambda x: Path(x).stem[:25]),\n                          _pfs[col], color=color)\n            ax.bar_label(bars, fmt='%.3f' if col=='Density_per_kb' else '%.1f%%',\n                         padding=2, fontsize=8)\n            ax.set_ylabel(label); ax.set_title(title)\n            if col=='Coverage_pct': ax.set_ylim(0,100)\n            plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n            _savefig(fig, _master_dir/f'{\"density\" if col==\"Density_per_kb\" else \"coverage\"}_comparison.png')\n\n    # (h) Class density heatmap (files × classes)\n    if '6_class_density_pivot' in _tables and not _tables['6_class_density_pivot'].empty:\n        _dens_piv = _tables['6_class_density_pivot'].set_index('Source_File')\n        if not _dens_piv.empty:\n            fig, ax = plt.subplots(figsize=(max(10, len(_dens_piv.columns)*1.2),\n                                            max(4,  len(_dens_piv)*0.7)))\n            sns.heatmap(_dens_piv, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax,\n                        linewidths=0.4, cbar_kws={'label':'Motifs per kb'})\n            ax.set_title('Class Density Heatmap (motifs/kb) — Files × Classes')\n            ax.set_xlabel('Non-B Class'); ax.set_ylabel('File')\n            plt.tight_layout(); _savefig(fig, _master_dir/'class_density_heatmap.png')\n\n    # (i) Class coverage heatmap (files × classes)\n    if '7_class_coverage_pivot' in _tables and not _tables['7_class_coverage_pivot'].empty:\n        _cov_piv = _tables['7_class_coverage_pivot'].set_index('Source_File')\n        if not _cov_piv.empty:\n            fig, ax = plt.subplots(figsize=(max(10, len(_cov_piv.columns)*1.2),\n                                            max(4,  len(_cov_piv)*0.7)))\n            sns.heatmap(_cov_piv, annot=True, fmt='.3f', cmap='Blues', ax=ax,\n                        linewidths=0.4, cbar_kws={'label':'Coverage %'})\n            ax.set_title('Class Coverage Heatmap (%) — Files × Classes')\n            ax.set_xlabel('Non-B Class'); ax.set_ylabel('File')\n            plt.tight_layout(); _savefig(fig, _master_dir/'class_coverage_heatmap.png')\n\n    # (j) Hybrid & Cluster comparison\n    if not _pf_summary.empty and (_pf_summary['Hybrids'].sum()>0 or _pf_summary['Clusters'].sum()>0):\n        x = np.arange(len(_pf_summary)); w = 0.35\n        labels = _pf_summary['File'].apply(lambda x: Path(x).stem[:20])\n        fig, ax = plt.subplots(figsize=(max(7, len(_pf_summary)*1.5), 4))\n        ax.bar(x-w/2, _pf_summary['Hybrids'],  w, label='Hybrids',  color='tomato')\n        ax.bar(x+w/2, _pf_summary['Clusters'], w, label='Clusters', color='mediumpurple')\n        ax.set_xticks(x); ax.set_xticklabels(labels, rotation=30, ha='right')\n        ax.set_ylabel('Count'); ax.set_title('Hybrid & Cluster Motifs Across Files')\n        ax.legend(); plt.tight_layout()\n        _savefig(fig, _master_dir/'hybrid_cluster_comparison.png')\n\n    # (k) GFF heatmap\n    if not _gff_df.empty and '9_gff_motifs_per_feature' in _tables:\n        _piv = _gff_df.groupby(['GFF_Type','Class']).size().unstack(fill_value=0)\n        fig2, ax2 = plt.subplots(figsize=(max(10,len(_piv.columns)*1.2), max(4,len(_piv)*0.6)))\n        sns.heatmap(_piv, annot=True, fmt='d', cmap='YlOrRd', ax=ax2,\n                    linewidths=0.4, cbar_kws={'label':'Motif count'})\n        ax2.set_title('GFF Feature Type × Non-B Class Heatmap')\n        ax2.set_xlabel('Non-B Class'); ax2.set_ylabel('GFF Feature Type')\n        plt.tight_layout(); _savefig(fig2, _master_dir/'gff_class_heatmap.png')\n\n# Display all statistics tables\nprint('\\n' + '='*70)\nprint('ALL STATISTICS TABLES')\nprint('='*70)\nfor tname, tdf in _tables.items():\n    print(f\"\\n{'─'*60}\")\n    print(f\"  {tname.replace('_',' ').upper()}\")\n    print(f\"{'─'*60}\")\n    display(tdf)\n\n# ─────────────────────────────────────────────────────────────────────────────\n# D. COMPARATIVE ANALYSIS\n# ─────────────────────────────────────────────────────────────────────────────\n_comp_rows = []\nfor stem, res in RESULTS_BY_FILE.items():\n    species, region = _parse_species_region(stem)\n    df, fp, sl = res['df'], res['path'], res['seq_lengths']\n    gc_pct, seq_len = _gc_and_length(fp)\n    n = len(df)\n    _comp_rows.append({\n        'Stem':stem,'Species':species,'Region':region,\n        'Total_Motifs':n,'Seq_Length_bp':seq_len,\n        'Density_per_kb':round(n/seq_len*1000,4) if seq_len else 0.0,\n        'Coverage_pct':_coverage(df,sl),'GC_Percent':gc_pct,\n        'Mean_Motif_Length':  round(df['Length'].mean(),2)   if not df.empty else 0.0,\n        'Median_Motif_Length':round(df['Length'].median(),2) if not df.empty else 0.0,\n        'Unique_Classes':   df['Class'].nunique()    if not df.empty else 0,\n        'Unique_Subclasses':df['Subclass'].nunique() if not df.empty else 0,\n        'Hybrids':  int((df['Class']=='Hybrid').sum())             if not df.empty else 0,\n        'Clusters': int((df['Class']=='Non-B_DNA_Clusters').sum()) if not df.empty else 0,\n    })\n_comp_df      = pd.DataFrame(_comp_rows)\n_species_list = sorted(_comp_df['Species'].unique())\n_region_list  = sorted(_comp_df['Region'].unique())\n_cmp_dir = _BASE / '_comparisons'; _cmp_dir.mkdir(exist_ok=True)\n_comp_df.to_csv(str(_cmp_dir/'all_comparisons_summary.csv'), encoding='utf-8-sig', index=False)\n_comp_df.to_excel(str(_cmp_dir/'all_comparisons_summary.xlsx'), index=False)\nprint(f'\\nSpecies: {_species_list}  |  Regions: {_region_list}')\n\n# Multi-file comparative plots\nif len(RESULTS_BY_FILE) >= 2 and not _master_df.empty:\n    # Class comparison\n    _cls_pivot = _master_df.groupby(['Source_File','Class']).size().unstack(fill_value=0)\n    fig, ax = plt.subplots(figsize=(max(10,len(_cls_pivot)*1.4), max(4,len(_cls_pivot.columns)*0.5)))\n    _cls_pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n    ax.set_xlabel('File'); ax.set_ylabel('Motif Count')\n    ax.set_title('Class Distribution — All Files Comparison')\n    ax.legend(title='Class', bbox_to_anchor=(1,1), fontsize=8)\n    plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n    _savefig(fig, _cmp_dir/'all_files_class_comparison.png')\n\n    # Subclass comparison (top 20)\n    _top_subs = _master_df['Subclass'].value_counts().head(20).index\n    _sub_pivot = _master_df.groupby(['Source_File','Subclass']).size().unstack(fill_value=0)\n    _sub_pivot = _sub_pivot[[c for c in _top_subs if c in _sub_pivot.columns]]\n    if not _sub_pivot.empty:\n        fig, ax = plt.subplots(figsize=(max(10,len(_sub_pivot)*1.4), max(4,len(_sub_pivot.columns)*0.4)))\n        _sub_pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n        ax.set_xlabel('File'); ax.set_ylabel('Motif Count')\n        ax.set_title('Subclass Distribution — All Files (top 20)')\n        ax.legend(title='Subclass', bbox_to_anchor=(1,1), fontsize=7)\n        plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n        _savefig(fig, _cmp_dir/'all_files_subclass_comparison.png')\n\n# Within-species comparisons\n_sep = '\\u2550'*60\nfor species in _species_list:\n    sp_rows  = _comp_df[_comp_df['Species']==species].copy()\n    sp_stems = sp_rows['Stem'].tolist()\n    sp_dir   = _cmp_dir/_safe_fname(species); sp_dir.mkdir(exist_ok=True)\n    if len(sp_stems) < 2:\n        print(f\"\\n\\u26a0  '{species}' — single region, skipping within-species plots.\")\n        continue\n    print(f'\\n{_sep}\\nWithin-species: {species}\\n{_sep}')\n\n    # Class + subclass by region\n    for attr, label, fname, colors in [\n        ('Class',   'Class',   'class_by_region.png',   'tab20'),\n        ('Subclass','Subclass','subclass_by_region.png','tab20'),\n    ]:\n        _by_reg = {sp_rows.loc[sp_rows['Stem']==st,'Region'].values[0]:\n                   RESULTS_BY_FILE[st]['df'][attr].value_counts()\n                   if not RESULTS_BY_FILE[st]['df'].empty else pd.Series(dtype=int)\n                   for st in sp_stems}\n        _all_v = sorted({c for s in _by_reg.values() for c in s.index})\n        if not _all_v: continue\n        _mat = pd.DataFrame({r:s.reindex(_all_v,fill_value=0) for r,s in _by_reg.items()}).T\n        fig, ax = plt.subplots(figsize=(max(8,len(_all_v)*1.2),4))\n        _mat.plot(kind='bar', ax=ax, colormap=colors, width=0.8)\n        ax.set_title(f'{species} — {label} Distribution by Region')\n        ax.set_xlabel('Region'); ax.set_ylabel('Motif Count')\n        ax.legend(title=label, bbox_to_anchor=(1,1), fontsize=7)\n        plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n        _savefig(fig, sp_dir/fname, show=False)\n\n    # Density, coverage, GC, length by region\n    for col, label, color, fmt, ylim, fn in [\n        ('Density_per_kb','Motifs per kb',    'steelblue',     '%.3f', None, 'density_by_region.png'),\n        ('Coverage_pct',  'Coverage (%)',     'mediumseagreen','%.1f%%',(0,100),'coverage_by_region.png'),\n        ('GC_Percent',    'GC (%)',           'goldenrod',     '%.1f%%',(0,100),'gc_by_region.png'),\n    ]:\n        fig, ax = plt.subplots(figsize=(max(6,len(sp_rows)*1.2),4))\n        bars = ax.bar(sp_rows['Region'], sp_rows[col], color=color)\n        ax.bar_label(bars, fmt=fmt, padding=2)\n        ax.set_title(f'{species} — {label} by Region')\n        ax.set_xlabel('Region'); ax.set_ylabel(label)\n        if ylim: ax.set_ylim(*ylim)\n        plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n        _savefig(fig, sp_dir/fn, show=False)\n\n    # Motif length boxplot\n    _len_parts = []\n    for st in sp_stems:\n        df = RESULTS_BY_FILE[st]['df']\n        reg = sp_rows.loc[sp_rows['Stem']==st,'Region'].values[0]\n        if not df.empty and 'Length' in df.columns:\n            tmp = df[['Length']].copy(); tmp['Region'] = reg; _len_parts.append(tmp)\n    if _len_parts:\n        _len_df = pd.concat(_len_parts)[lambda d: d['Length']>0]\n        if not _len_df.empty:\n            fig, ax = plt.subplots(figsize=(max(8,len(sp_stems)*2),4))\n            sns.boxplot(data=_len_df, x='Region', y='Length', ax=ax, palette='Set2')\n            ax.set_title(f'{species} — Motif Length Distribution by Region')\n            plt.xticks(rotation=30, ha='right'); plt.tight_layout()\n            _savefig(fig, sp_dir/'length_by_region.png', show=False)\n\n    _sp_summary = sp_rows.set_index('Region')[[\n        'Total_Motifs','Seq_Length_bp','Density_per_kb','Coverage_pct',\n        'GC_Percent','Mean_Motif_Length','Median_Motif_Length',\n        'Unique_Classes','Unique_Subclasses','Hybrids','Clusters',\n    ]]\n    _sp_summary.to_csv(str(sp_dir/'within_species_summary.csv'), encoding='utf-8-sig')\n    print(f'{species} Summary:'); display(_sp_summary)\n\n# Cross-species\nif len(_species_list) >= 2:\n    _xs_dir = _cmp_dir/'_cross_species'; _xs_dir.mkdir(exist_ok=True)\n    print(f'\\n{_sep}\\nCross-species: {_species_list}\\n{_sep}')\n    _all_regs = sorted(set.union(*[set(_comp_df[_comp_df['Species']==sp]['Region'])\n                                   for sp in _species_list]))\n    for col, label, cmap, fmt, fn in [\n        ('Density_per_kb','Motifs/kb','YlOrRd','.3f','cross_species_density_heatmap.png'),\n        ('Coverage_pct',  'Coverage %','Blues', '.1f','cross_species_coverage_heatmap.png'),\n        ('GC_Percent',    'GC %',     'YlGn',  '.1f','cross_species_gc_heatmap.png'),\n    ]:\n        _piv = _comp_df.pivot_table(index='Species',columns='Region',values=col,aggfunc='mean')\n        if not _piv.empty:\n            fig, ax = plt.subplots(figsize=(max(8,len(_all_regs)*1.4), max(4,len(_species_list)*0.8)))\n            sns.heatmap(_piv, annot=True, fmt=fmt, cmap=cmap, ax=ax,\n                        linewidths=0.4, cbar_kws={'label':label})\n            ax.set_title(f'Cross-Species — {label} Heatmap')\n            ax.set_xlabel('Region'); ax.set_ylabel('Species')\n            plt.tight_layout(); _savefig(fig, _xs_dir/fn, show=False)\n    _xs_summary = _comp_df.sort_values(['Species','Region'])\n    _xs_summary.to_csv(str(_xs_dir/'cross_species_summary.csv'), encoding='utf-8-sig', index=False)\n    print('Cross-Species Summary:'); display(_xs_summary)\n\n# ─────────────────────────────────────────────────────────────────────────────\n# E. DOWNLOAD LINKS\n# ─────────────────────────────────────────────────────────────────────────────\nimport base64\n\n_MIME = {'csv':'text/csv',\n         'xlsx':'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n         'png':'image/png'}\n\ndef _dl(path, label):\n    with open(path,'rb') as fh: b64 = base64.b64encode(fh.read()).decode()\n    ext  = Path(path).suffix.lstrip('.')\n    mime = _MIME.get(ext,'application/octet-stream')\n    return (f'<a href=\"data:{mime};base64,{b64}\" download=\"{Path(path).name}\" '\n            f'style=\"margin:2px 6px;padding:3px 8px;border:1px solid #aaa;'\n            f'border-radius:4px;text-decoration:none;\">{label}</a>')\n\n_html = ['<h2>\\U0001f4e5 Downloads</h2><h3>Master Outputs</h3><div>']\nfor fmt, fn in [('CSV','master_motifs.csv'),('Excel','master_motifs.xlsx')]:\n    p = _master_dir/fn\n    if p.exists(): _html.append(_dl(str(p), f'Master {fmt}'))\nif (_master_dir/'gff_region_motifs_all.csv').exists():\n    _html.append(_dl(str(_master_dir/'gff_region_motifs_all.csv'),'GFF Regions CSV'))\n_html.append('</div><h3>Statistics Tables</h3><div>')\nfor tn in _tables:\n    p = _master_dir/f'{tn}.csv'\n    if p.exists(): _html.append(_dl(str(p), tn.replace('_',' ').title()))\n_html.append('</div><h3>Comparative Analysis</h3><div>')\nfor fn in ['all_comparisons_summary.csv','all_comparisons_summary.xlsx']:\n    p = _cmp_dir/fn\n    if p.exists(): _html.append(_dl(str(p), fn))\n_html.append('</div><h3>Per-File Outputs</h3>')\nfor stem, res in RESULTS_BY_FILE.items():\n    _html.append(f'<details style=\"margin:4px 0\"><summary><b>{stem}</b> '\n                 f'<em>[{res[\"file_type\"]}]</em></summary><div style=\"margin:4px 12px\">')\n    for fmt, fn in [('CSV','motifs.csv'),('Excel','motifs.xlsx')]:\n        p = res['folder']/fn\n        if p.exists(): _html.append(_dl(str(p), fmt))\n    for fn in sorted(res['folder'].glob('*.png')):\n        _html.append(_dl(str(fn), fn.stem.replace('_',' ').title()))\n    _html.append('</div></details>')\n\ndisplay(HTML('\\n'.join(_html)))\nprint(f'\\n\\u2705 All outputs saved to: {_BASE}')\n"
  }
 ]
}