{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TAB 1 \u2014 Setup \u00b7 File Detection \u00b7 GPU Detection\n# Edit FASTA_INPUT and OUTPUT_DIR, then run all three cells in order.\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nimport sys, os, importlib, glob, warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\n# \u2500\u2500 Add repo root to path \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_REPO_ROOT = os.path.abspath(os.getcwd())\nif _REPO_ROOT not in sys.path:\n    sys.path.insert(0, _REPO_ROOT)\n\n# \u2500\u2500 Auto-install missing packages \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_REQUIRED = [\n    ('psutil','psutil>=5.8.0'), ('pandas','pandas>=1.3.0'),\n    ('numpy','numpy>=1.21.0'),  ('matplotlib','matplotlib>=3.5.0'),\n    ('seaborn','seaborn>=0.11.0'), ('openpyxl','openpyxl>=3.0.0'),\n    ('tqdm','tqdm>=4.64.0'),\n]\n_miss = [p for m,p in _REQUIRED if importlib.util.find_spec(m) is None]\nif _miss:\n    import subprocess; subprocess.check_call([sys.executable,'-m','pip','install',*_miss,'-q'])\n\nimport pandas as pd, numpy as np\n\n# \u2500\u2500 User Configuration \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFASTA_INPUT        = ['*.fna', '*.fasta']   # path, wildcard, or list\nOUTPUT_DIR         = 'notebook_reports'\nENABLED_CLASSES    = None                   # None = all 9 detectors\nRAM_OVERRIDE_BYTES = None                   # None = auto-detect\nEXPORT_CSV         = True\nEXPORT_BED         = True\nEXPORT_JSON        = True\nEXPORT_EXCEL       = True\n\n# \u2500\u2500 GPU detection \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _detect_gpu():\n    try:\n        import torch\n        if torch.cuda.is_available():\n            return 'cuda', torch.cuda.get_device_name(0)\n    except ImportError:\n        pass\n    try:\n        import cupy as cp; cp.array([1])\n        return 'cupy', 'CUDA GPU'\n    except Exception:\n        pass\n    return None, None\n\nGPU_BACKEND, GPU_NAME = _detect_gpu()\n_gpu_msg = f'GPU  {GPU_BACKEND} ({GPU_NAME})' if GPU_BACKEND else 'GPU  none (CPU only)'\nprint(f'\\u2705 Deps OK | Python {sys.version.split()[0]} | {_gpu_msg}')\n\n# \u2500\u2500 Resolve input files \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _resolve(inp):\n    out = []\n    for p in ([inp] if isinstance(inp, str) else list(inp)):\n        hits = glob.glob(p)\n        out.extend(hits)\n        if not hits and os.path.isfile(p):\n            out.append(p)\n    return sorted({str(Path(f).resolve()) for f in out})\n\nFASTA_FILES = _resolve(FASTA_INPUT)\nif not FASTA_FILES:\n    raise FileNotFoundError(f'No FASTA files found: {FASTA_INPUT}')\n\n# \u2500\u2500 Sequence-count helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _seq_lengths(p):\n    L, c = [], 0\n    with open(p) as fh:\n        for ln in fh:\n            s = ln.strip()\n            if s.startswith('>'):\n                if c: L.append(c)\n                c = 0\n            else:\n                c += len(s)\n    if c: L.append(c)\n    return L\n\n# \u2500\u2500 File-type classification \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFILE_TYPES = {}   # path -> 'single' | 'multi' | 'multi_equal'\nfor fp in FASTA_FILES:\n    ls = _seq_lengths(fp)\n    if   len(ls) == 1:           FILE_TYPES[fp] = 'single'\n    elif len(set(ls)) == 1:      FILE_TYPES[fp] = 'multi_equal'\n    else:                         FILE_TYPES[fp] = 'multi'\n\n# \u2500\u2500 GFF pairing (same stem, .gff or .gff3) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nGFF_MAP = {}   # fna_path -> gff_path  (only .fna files with a matching GFF)\nfor fp in FASTA_FILES:\n    stem   = Path(fp).stem\n    parent = Path(fp).parent\n    for ext in ('.gff3', '.gff'):\n        candidate = parent / (stem + ext)\n        if candidate.exists():\n            GFF_MAP[fp] = str(candidate)\n            break\n\n# \u2500\u2500 Summary \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint(f'\\n\\U0001f4c2 Input files: {len(FASTA_FILES)}')\nfor fp in FASTA_FILES:\n    gff_tag = f'  +GFF: {Path(GFF_MAP[fp]).name}' if fp in GFF_MAP else ''\n    print(f'   [{FILE_TYPES[fp]:12s}]  {Path(fp).name}{gff_tag}')\nprint(f'\\n\\U0001f4c1 Output dir : {OUTPUT_DIR}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TAB 2 \u2014 Adaptive Analysis  (whole-genome + GFF-region analysis)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nimport gc, time, datetime, concurrent.futures\nimport matplotlib; matplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nfrom Utilities.system_resource_inspector import SystemResourceInspector\nfrom Utilities.adaptive_chunk_planner    import AdaptiveChunkPlanner\nfrom Utilities.nonbscanner               import analyze_sequence as _nbf_analyze\nfrom Utilities.utilities                 import (\n    read_fasta_file, export_to_csv, export_to_bed,\n    export_to_json, export_to_excel,\n)\n\n# \u2500\u2500 Adaptive resource plan \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_insp   = SystemResourceInspector()\n_budget = RAM_OVERRIDE_BYTES or _insp.get_memory_budget()\n_cpus   = _insp.get_cpu_count()\n_total  = max(sum(os.path.getsize(f) for f in FASTA_FILES if os.path.exists(f)), 1_000)\n_plan   = AdaptiveChunkPlanner().plan(_total, _budget, _cpus)\nCHUNK_SIZE, CHUNK_OVERLAP = _plan['chunk_size'], _plan['overlap']\nN_WORKERS, EXEC_MODE      = _plan['workers'], _plan['mode']\n\n# Boost workers when GPU acceleration is active\nif GPU_BACKEND:\n    N_WORKERS = min(N_WORKERS * 2, os.cpu_count() or 4)\n\nprint(f'\\u2699\\ufe0f  RAM {_budget/1e9:.2f} GB | chunk={CHUNK_SIZE:,} overlap={CHUNK_OVERLAP:,} '\n      f'workers={N_WORKERS} mode={EXEC_MODE} gpu={GPU_BACKEND or \"none\"}')\n\n# \u2500\u2500 Run folder \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_RUN_TS = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n_BASE   = Path(OUTPUT_DIR) / _RUN_TS\n_BASE.mkdir(parents=True, exist_ok=True)\nprint(f'\\U0001f4c2 Run output: {_BASE}')\n\n# \u2500\u2500 Lightweight GFF parser \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _parse_gff(gff_path):\n    feats = []\n    with open(gff_path) as fh:\n        for ln in fh:\n            if ln.startswith('#') or not ln.strip():\n                continue\n            p = ln.rstrip('\\n').split('\\t')\n            if len(p) < 8:\n                continue\n            try:\n                feats.append({\n                    'seqid':  p[0],\n                    'type':   p[2],\n                    'start':  max(int(p[3]) - 1, 0),\n                    'end':    int(p[4]),\n                    'strand': p[6],\n                    'attrs':  p[8] if len(p) > 8 else '',\n                })\n            except ValueError:\n                pass\n    return feats\n\n# \u2500\u2500 Motif scan wrapper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _scan(name, seq):\n    return _nbf_analyze(\n        sequence=seq, sequence_name=name,\n        use_chunking=True,\n        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP,\n        use_parallel_chunks=(EXEC_MODE == 'hybrid'),\n        enabled_classes=ENABLED_CLASSES,\n    )\n\n# \u2500\u2500 Per-file analysis \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nRESULTS_BY_FILE  = {}   # stem -> {df, folder, file_type, path}\nGFF_RESULTS      = {}   # stem -> {region_df, gff_path, folder}\nsns.set_theme(style='whitegrid')\n\nfor fasta_path in tqdm(FASTA_FILES, desc='Files', unit='file'):\n    stem     = Path(fasta_path).stem\n    ftype    = FILE_TYPES[fasta_path]\n    file_dir = _BASE / stem\n    file_dir.mkdir(parents=True, exist_ok=True)\n    tqdm.write(f'\\n\\u2500\\u2500 {stem}  [{ftype}] \\u2500\\u2500')\n\n    seqs = read_fasta_file(fasta_path)\n    if not seqs:\n        tqdm.write('  \\u26a0\\ufe0f  No sequences \\u2014 skipping.')\n        continue\n\n    # \u2500\u2500 Whole-genome scan (parallel over sequences) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    motifs_file, t0 = [], time.perf_counter()\n    with concurrent.futures.ThreadPoolExecutor(max_workers=N_WORKERS) as pool:\n        futs = {pool.submit(_scan, sn, sq): sn for sn, sq in seqs.items()}\n        for fut in tqdm(concurrent.futures.as_completed(futs),\n                        total=len(futs), desc=f'  seqs({stem})', leave=False):\n            sn = futs[fut]\n            res = fut.result()\n            tqdm.write(f'  \\u25b8 {sn[:55]}  \\u2192 {len(res):,} motifs')\n            motifs_file.extend(res)\n    tqdm.write(f'  \\u2705 {len(motifs_file):,} motifs in {time.perf_counter()-t0:.1f}s')\n    gc.collect()\n\n    # \u2500\u2500 Build per-file DataFrame \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    df = pd.DataFrame(motifs_file) if motifs_file else pd.DataFrame()\n    for col, dflt in [('Class','Unknown'),('Subclass','Other'),('Start',0),\n                      ('End',0),('Length',0),('Score',0.0),('Strand','+'),\n                      ('Sequence_Name','')]:\n        if col not in df.columns: df[col] = dflt\n    if not df.empty:\n        m = df['Length'] == 0\n        df.loc[m,'Length'] = (df.loc[m,'End'] - df.loc[m,'Start']).clip(lower=0)\n    df['Source_File'] = Path(fasta_path).name\n    df['File_Type']   = ftype\n\n    # \u2500\u2500 Per-file exports \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    if not df.empty:\n        rows = df.to_dict(orient='records')\n        if EXPORT_CSV:   export_to_csv(rows,   filename=str(file_dir/'motifs.csv'))\n        if EXPORT_BED:   export_to_bed(rows,   filename=str(file_dir/'motifs.bed'))\n        if EXPORT_JSON:  export_to_json(rows,  filename=str(file_dir/'motifs.json'))\n        if EXPORT_EXCEL: export_to_excel(rows, filename=str(file_dir/'motifs.xlsx'))\n\n    # \u2500\u2500 Per-file class-distribution plot \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    if not df.empty:\n        cc  = df['Class'].value_counts()\n        fig, ax = plt.subplots(figsize=(8,3))\n        ax.barh(cc.index[::-1], cc.values[::-1])\n        ax.set_xlabel('Motif Count'); ax.set_title(f'{stem} [{ftype}] \\u2014 Class Distribution')\n        plt.tight_layout(); fig.savefig(str(file_dir/'class_distribution.png'), dpi=150)\n        plt.close(fig)\n\n    RESULTS_BY_FILE[stem] = {'df':df,'folder':file_dir,'file_type':ftype,'path':fasta_path}\n\n    # \u2500\u2500 GFF region analysis \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    if fasta_path in GFF_MAP:\n        gff_path = GFF_MAP[fasta_path]\n        tqdm.write(f'  \\U0001f4cb GFF: {Path(gff_path).name}')\n        features  = _parse_gff(gff_path)\n        tqdm.write(f'     {len(features):,} features parsed')\n\n        gff_dir = file_dir / 'gff_regions'\n        gff_dir.mkdir(exist_ok=True)\n\n        region_rows = []\n        feat_types  = sorted({f['type'] for f in features})\n        for ftype_gff in tqdm(feat_types, desc=f'  GFF({stem})', leave=False):\n            type_feats  = [f for f in features if f['type'] == ftype_gff]\n            type_motifs = []\n            for feat in type_feats:\n                seq_id     = feat['seqid']\n                if seq_id not in seqs:\n                    continue\n                region_seq = seqs[seq_id][feat['start']:feat['end']]\n                if len(region_seq) < 12:   # 12 bp = minimum motif length in any detector\n                    continue\n                rname = f\"{seq_id}:{ftype_gff}:{feat['start']}-{feat['end']}({feat['strand']})\"\n                mots  = _scan(rname, region_seq)\n                for m in mots:\n                    m['GFF_Type']   = ftype_gff\n                    m['GFF_SeqID']  = seq_id\n                    m['GFF_Start']  = feat['start']\n                    m['GFF_End']    = feat['end']\n                    m['GFF_Strand'] = feat['strand']\n                    _a = feat['attrs']\n                    m['GFF_Attrs']  = _a[:80] + ('...' if len(_a) > 80 else '')\n                type_motifs.extend(mots)\n            region_rows.extend(type_motifs)\n            tqdm.write(f'     {ftype_gff}: {len(type_feats):,} regions -> {len(type_motifs):,} motifs')\n            gc.collect()\n\n        gff_df = pd.DataFrame(region_rows) if region_rows else pd.DataFrame()\n        for col, dflt in [('Class','Unknown'),('Subclass','Other'),('Start',0),\n                          ('End',0),('Length',0),('Score',0.0),\n                          ('GFF_Type',''),('GFF_SeqID',''),\n                          ('GFF_Start',0),('GFF_End',0),\n                          ('GFF_Strand','+'),('GFF_Attrs','')]:\n            if col not in gff_df.columns: gff_df[col] = dflt\n\n        if not gff_df.empty:\n            gff_df.to_csv(str(gff_dir/'gff_region_motifs.csv'), index=False)\n            pivot = gff_df.groupby(['GFF_Type','Class']).size().unstack(fill_value=0)\n            fig, ax = plt.subplots(figsize=(max(8, len(pivot)*1.4), 5))\n            pivot.plot(kind='bar', ax=ax, colormap='tab20', width=0.8)\n            ax.set_xlabel('GFF Feature Type'); ax.set_ylabel('Motif Count')\n            ax.set_title(f'{stem} \\u2014 Motifs per GFF Feature Type')\n            ax.legend(title='Class', bbox_to_anchor=(1,1))\n            plt.tight_layout()\n            fig.savefig(str(gff_dir/'gff_motifs_by_type.png'), dpi=150)\n            plt.close(fig)\n\n        GFF_RESULTS[stem] = {'region_df':gff_df,'gff_path':gff_path,'folder':gff_dir}\n        tqdm.write(f'  \\u2705 GFF analysis: {len(gff_df):,} region motifs')\n\nprint(f'\\n\\u2705 Analysis complete \\u2014 {len(RESULTS_BY_FILE)} file(s) processed '\n      f'({len(GFF_RESULTS)} with GFF).')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TAB 3 \u2014 Master Tables, Summary Plots & Downloads\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nimport base64\nfrom IPython.display import display, HTML, Image\n\n# \u2500\u2500 Master DataFrames \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_dfs       = [r['df'] for r in RESULTS_BY_FILE.values() if not r['df'].empty]\n_master_df = pd.concat(_dfs, ignore_index=True) if _dfs else pd.DataFrame()\n\n_master_dir = _BASE / '_master'\n_master_dir.mkdir(exist_ok=True)\n\n_gdfs   = [v['region_df'] for v in GFF_RESULTS.values() if not v['region_df'].empty]\n_gff_df = pd.concat(_gdfs, ignore_index=True) if _gdfs else pd.DataFrame()\n\n# \u2500\u2500 Summary tables \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_tables = {}\nif not _master_df.empty:\n    _tables['1_global_class_distribution'] = (\n        _master_df.groupby(['Source_File','File_Type','Class'])\n        .size().reset_index(name='Count')\n    )\n    _tables['2_per_file_summary'] = pd.DataFrame([\n        {'File': Path(r['path']).name, 'File_Type': r['file_type'],\n         'Sequences': r['df']['Sequence_Name'].nunique() if not r['df'].empty else 0,\n         'Total_Motifs': len(r['df']),\n         'Classes': r['df']['Class'].nunique() if not r['df'].empty else 0}\n        for r in RESULTS_BY_FILE.values()\n    ])\n    _tables['3_class_statistics'] = (\n        _master_df.groupby('Class')\n        .agg(Total_Count=('Class','count'), Mean_Length=('Length','mean'),\n             Mean_Score=('Score','mean'))\n        .round(3).reset_index().sort_values('Total_Count', ascending=False)\n    )\n    _tables['4_file_class_pivot'] = (\n        _master_df.groupby(['Source_File','Class'])\n        .size().unstack(fill_value=0).reset_index()\n    )\n    _eq_dfs = [r['df'] for r in RESULTS_BY_FILE.values()\n               if r['file_type'] == 'multi_equal' and not r['df'].empty]\n    if _eq_dfs:\n        _eq = pd.concat(_eq_dfs, ignore_index=True)\n        _tables['5_equal_length_positional'] = (\n            _eq.groupby(['Source_File','Class','Start'])\n            .size().reset_index(name='Frequency')\n            .sort_values(['Source_File','Class','Frequency'], ascending=[True,True,False])\n        )\n\n# \u2500\u2500 GFF-specific summary tables \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nif not _gff_df.empty:\n    _tables['6_gff_motifs_per_feature_type'] = (\n        _gff_df.groupby(['GFF_Type','Class'])\n        .size().reset_index(name='Count')\n        .sort_values('Count', ascending=False)\n    )\n    _tables['7_gff_density_per_feature'] = (\n        _gff_df.assign(Region_Len=(_gff_df['GFF_End']-_gff_df['GFF_Start']).clip(lower=1))\n        .groupby('GFF_Type')\n        .agg(Total_Motifs=('Class','count'),\n             Unique_Classes=('Class','nunique'),\n             Mean_Region_Len=('Region_Len','mean'))\n        .round(2).reset_index()\n        .sort_values('Total_Motifs', ascending=False)\n    )\n    _tables['8_gff_class_pivot'] = (\n        _gff_df.groupby(['GFF_Type','Class'])\n        .size().unstack(fill_value=0).reset_index()\n    )\n    _tables['9_gff_top50_hotspot_regions'] = (\n        _gff_df.groupby(['GFF_SeqID','GFF_Type','GFF_Start','GFF_End'])\n        .agg(Motif_Count=('Class','count'), Classes=('Class','nunique'))\n        .reset_index().sort_values('Motif_Count', ascending=False).head(50)\n    )\n\n# \u2500\u2500 Export all data \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nif not _master_df.empty:\n    rows = _master_df.to_dict(orient='records')\n    if EXPORT_CSV:   export_to_csv(rows,   filename=str(_master_dir/'master_motifs.csv'))\n    if EXPORT_BED:   export_to_bed(rows,   filename=str(_master_dir/'master_motifs.bed'))\n    if EXPORT_JSON:  export_to_json(rows,  filename=str(_master_dir/'master_motifs.json'))\n    if EXPORT_EXCEL: export_to_excel(rows, filename=str(_master_dir/'master_motifs.xlsx'))\nif not _gff_df.empty:\n    _gff_df.to_csv(str(_master_dir/'gff_region_motifs_all.csv'), index=False)\nfor tname, tdf in _tables.items():\n    tdf.to_csv(str(_master_dir/f'{tname}.csv'), index=False)\n\n# \u2500\u2500 Master summary plots \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_ncol  = (2\n          + (1 if len(RESULTS_BY_FILE) > 1 else 0)\n          + (1 if not _gff_df.empty else 0))\nfig, axes = plt.subplots(1, _ncol, figsize=(6*_ncol, 4))\n_ax = iter([axes] if _ncol == 1 else axes.flat)\n\nif not _master_df.empty:\n    cc = _master_df['Class'].value_counts()\n    a  = next(_ax)\n    a.barh(cc.index[::-1], cc.values[::-1], color='steelblue')\n    a.set_xlabel('Count'); a.set_title('Global Class Distribution')\n\n    ft = _master_df.groupby('File_Type').size()\n    a  = next(_ax)\n    a.pie(ft.values, labels=ft.index, autopct='%1.1f%%', startangle=90)\n    a.set_title('Motifs by File Type')\n\n    if len(RESULTS_BY_FILE) > 1:\n        pf = _master_df.groupby('Source_File').size().sort_values(ascending=False)\n        a  = next(_ax)\n        a.barh([Path(n).stem[:22] for n in pf.index[::-1]], pf.values[::-1], color='coral')\n        a.set_xlabel('Count'); a.set_title('Motifs per File')\n\nif not _gff_df.empty:\n    a  = next(_ax)\n    gt = _gff_df['GFF_Type'].value_counts().head(15)\n    a.barh(gt.index[::-1], gt.values[::-1], color='mediumseagreen')\n    a.set_xlabel('Count'); a.set_title('Motifs by GFF Feature Type')\n\nplt.tight_layout()\n_plot = str(_master_dir/'master_summary.png')\nfig.savefig(_plot, dpi=150); plt.close(fig)\ndisplay(Image(_plot))\n\n# \u2500\u2500 GFF feature-type x class heatmap \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nif not _gff_df.empty and '8_gff_class_pivot' in _tables:\n    _piv = _tables['8_gff_class_pivot'].set_index('GFF_Type')\n    fig2, ax2 = plt.subplots(figsize=(max(10, len(_piv.columns)*1.2),\n                                       max(4,  len(_piv)*0.6)))\n    sns.heatmap(_piv, annot=True, fmt='d', cmap='YlOrRd', ax=ax2,\n                linewidths=0.4, cbar_kws={'label':'Motif count'})\n    ax2.set_title('GFF Feature Type \\u00d7 Non-B Class Heatmap')\n    ax2.set_xlabel('Non-B Class'); ax2.set_ylabel('GFF Feature Type')\n    plt.tight_layout()\n    _gheat = str(_master_dir/'gff_class_heatmap.png')\n    fig2.savefig(_gheat, dpi=150); plt.close(fig2)\n    display(Image(_gheat))\n\n# \u2500\u2500 Display tables \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfor tname, tdf in _tables.items():\n    print(f\"\\n{'='*60}\\n{tname.replace('_',' ').upper()}\\n{'='*60}\")\n    display(tdf)\n\n# \u2500\u2500 Download helpers \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n_MIME = {'csv':'text/csv','bed':'text/plain','json':'application/json',\n         'xlsx':'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n         'png':'image/png'}\n\ndef _dl(path, label):\n    with open(path,'rb') as fh: b64 = base64.b64encode(fh.read()).decode()\n    ext  = Path(path).suffix.lstrip('.')\n    mime = _MIME.get(ext,'application/octet-stream')\n    return (f'<a href=\"data:{mime};base64,{b64}\" download=\"{Path(path).name}\" '\n            f'style=\"margin:2px 6px;padding:3px 8px;border:1px solid #aaa;'\n            f'border-radius:4px;text-decoration:none;\">{label}</a>')\n\n_html = ['<h2>\\U0001f4e5 Downloads</h2><h3>Master Outputs</h3><div>']\nfor fmt,fn in [('CSV','master_motifs.csv'),('BED','master_motifs.bed'),\n               ('JSON','master_motifs.json'),('Excel','master_motifs.xlsx')]:\n    p = _master_dir/fn\n    if p.exists(): _html.append(_dl(str(p), f'Master {fmt}'))\nif (_master_dir/'gff_region_motifs_all.csv').exists():\n    _html.append(_dl(str(_master_dir/'gff_region_motifs_all.csv'), 'GFF Regions CSV'))\n_html.append('</div><h3>Summary Tables</h3><div>')\nfor tn in _tables:\n    p = _master_dir/f'{tn}.csv'\n    if p.exists(): _html.append(_dl(str(p), tn.replace('_',' ').title()))\n_html.append('</div><h3>Summary Plots</h3><div>')\nfor fn,lbl in [('master_summary.png','Master Summary'),\n               ('gff_class_heatmap.png','GFF Heatmap')]:\n    p = _master_dir/fn\n    if p.exists(): _html.append(_dl(str(p), lbl))\n_html.append('</div><h3>Per-File Outputs</h3>')\nfor stem, res in RESULTS_BY_FILE.items():\n    _html.append(f'<details style=\"margin:4px 0\"><summary><b>{stem}</b>'\n                 f' <em>[{res[\"file_type\"]}]</em></summary><div style=\"margin:4px 12px\">')\n    for fmt,fn in [('CSV','motifs.csv'),('BED','motifs.bed'),\n                   ('JSON','motifs.json'),('Excel','motifs.xlsx')]:\n        p = res['folder']/fn\n        if p.exists(): _html.append(_dl(str(p), fmt))\n    for fn,lbl in [('class_distribution.png','Plot'),\n                   ('gff_regions/gff_motifs_by_type.png','GFF Plot'),\n                   ('gff_regions/gff_region_motifs.csv','GFF CSV')]:\n        p = res['folder']/fn\n        if p.exists(): _html.append(_dl(str(p), lbl))\n    _html.append('</div></details>')\n\ndisplay(HTML('\\n'.join(_html)))\nprint(f'\\n\\u2705 All outputs: {_BASE}')\n"
  }
 ]
}