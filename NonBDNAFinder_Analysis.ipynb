{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1-setup-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# CELL 1 — Setup, Configuration & File-Type Detection\n",
    "# Run once. Edit FASTA_INPUT and OUTPUT_DIR to match your environment.\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import sys, os, importlib, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure repository root is on PYTHONPATH\n",
    "_REPO_ROOT = os.path.abspath(os.getcwd())\n",
    "if _REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, _REPO_ROOT)\n",
    "\n",
    "# ── Install missing packages ──────────────────────────────────────────────────\n",
    "_REQUIRED = [\n",
    "    ('psutil',     'psutil>=5.8.0'),\n",
    "    ('pandas',     'pandas>=1.3.0'),\n",
    "    ('numpy',      'numpy>=1.21.0'),\n",
    "    ('matplotlib', 'matplotlib>=3.5.0'),\n",
    "    ('seaborn',    'seaborn>=0.11.0'),\n",
    "    ('openpyxl',   'openpyxl>=3.0.0'),\n",
    "]\n",
    "_missing = [pkg for mod, pkg in _REQUIRED if importlib.util.find_spec(mod) is None]\n",
    "if _missing:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *_missing, '-q'])\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# ── User Configuration ────────────────────────────────────────────────────────\n",
    "# FASTA_INPUT: single path, wildcard, or list  (e.g. '*.fna', ['a.fasta','b.fa'])\n",
    "FASTA_INPUT        = ['*.fna', '*.fasta']\n",
    "OUTPUT_DIR         = 'notebook_reports'\n",
    "ENABLED_CLASSES    = None   # None = all 9 detectors\n",
    "RAM_OVERRIDE_BYTES = None   # None = auto-detect\n",
    "EXPORT_CSV         = True\n",
    "EXPORT_BED         = True\n",
    "EXPORT_JSON        = True\n",
    "EXPORT_EXCEL       = True\n",
    "\n",
    "# ── Resolve input files ───────────────────────────────────────────────────────\n",
    "def _resolve_inputs(inp):\n",
    "    patterns = [inp] if isinstance(inp, str) else list(inp)\n",
    "    files = []\n",
    "    for p in patterns:\n",
    "        hits = glob.glob(p)\n",
    "        files.extend(hits)\n",
    "        if not hits and os.path.isfile(p):\n",
    "            files.append(p)\n",
    "    return sorted({str(Path(f).resolve()) for f in files})\n",
    "\n",
    "FASTA_FILES = _resolve_inputs(FASTA_INPUT)\n",
    "if not FASTA_FILES:\n",
    "    raise FileNotFoundError(f'No FASTA files found matching: {FASTA_INPUT}')\n",
    "\n",
    "# ── File-type detection (single / multi / multi_equal) ───────────────────────\n",
    "def _get_seq_lengths(fasta_path):\n",
    "    lengths, cur = [], 0\n",
    "    with open(fasta_path) as fh:\n",
    "        for line in fh:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if cur:\n",
    "                    lengths.append(cur)\n",
    "                cur = 0\n",
    "            else:\n",
    "                cur += len(line)\n",
    "    if cur:\n",
    "        lengths.append(cur)\n",
    "    return lengths\n",
    "\n",
    "FILE_TYPES = {}   # maps abs path -> 'single' | 'multi' | 'multi_equal'\n",
    "for fp in FASTA_FILES:\n",
    "    lens = _get_seq_lengths(fp)\n",
    "    n    = len(lens)\n",
    "    if n == 1:\n",
    "        FILE_TYPES[fp] = 'single'\n",
    "    elif len(set(lens)) == 1:\n",
    "        FILE_TYPES[fp] = 'multi_equal'\n",
    "    else:\n",
    "        FILE_TYPES[fp] = 'multi'\n",
    "\n",
    "# ── Summary ───────────────────────────────────────────────────────────────────\n",
    "print(f'\\u2705 Dependencies OK | Python {sys.version.split()[0]} | '\n",
    "      f'pandas {pd.__version__} | numpy {np.__version__}')\n",
    "print(f'\\n\\U0001f4c2 FASTA files detected: {len(FASTA_FILES)}')\n",
    "for fp in FASTA_FILES:\n",
    "    print(f'   [{FILE_TYPES[fp]:12s}]  {Path(fp).name}')\n",
    "print(f'\\n\\U0001f4c1 Output directory: {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# CELL 2 — Adaptive Resource Planning, Motif Analysis & Per-File Output\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import gc, time, datetime, warnings\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from Utilities.system_resource_inspector import SystemResourceInspector\n",
    "from Utilities.adaptive_chunk_planner    import AdaptiveChunkPlanner\n",
    "from Utilities.nonbscanner               import analyze_sequence as _nbf_analyze\n",
    "from Utilities.utilities                 import (\n",
    "    read_fasta_file, export_to_csv, export_to_bed,\n",
    "    export_to_json, export_to_excel,\n",
    ")\n",
    "\n",
    "# ── Adaptive resource plan ────────────────────────────────────────────────────\n",
    "_insp    = SystemResourceInspector()\n",
    "_budget  = RAM_OVERRIDE_BYTES or _insp.get_memory_budget()\n",
    "_cpus    = _insp.get_cpu_count()\n",
    "_total_sz = max(sum(os.path.getsize(f) for f in FASTA_FILES if os.path.exists(f)), 1_000)\n",
    "_plan    = AdaptiveChunkPlanner().plan(\n",
    "    genome_length=_total_sz, ram_budget=_budget, cpu_count=_cpus)\n",
    "\n",
    "CHUNK_SIZE    = _plan['chunk_size']\n",
    "CHUNK_OVERLAP = _plan['overlap']\n",
    "N_WORKERS     = _plan['workers']\n",
    "EXEC_MODE     = _plan['mode']\n",
    "\n",
    "print(f'\\u2699\\ufe0f  RAM {_budget/1e9:.2f} GB | chunk={CHUNK_SIZE:,} '\n",
    "      f'overlap={CHUNK_OVERLAP:,} workers={N_WORKERS} mode={EXEC_MODE}')\n",
    "\n",
    "# ── Timestamped run folder ────────────────────────────────────────────────────\n",
    "_RUN_TS = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "_BASE   = Path(OUTPUT_DIR) / _RUN_TS\n",
    "_BASE.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\U0001f4c2 Run output: {_BASE}')\n",
    "\n",
    "# ── Per-file analysis loop ────────────────────────────────────────────────────\n",
    "RESULTS_BY_FILE = {}   # stem -> {df, folder, file_type, path}\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "for fasta_path in FASTA_FILES:\n",
    "    stem     = Path(fasta_path).stem\n",
    "    ftype    = FILE_TYPES[fasta_path]\n",
    "    file_dir = _BASE / stem\n",
    "    file_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f'\\n\\u2500\\u2500 {stem}  [{ftype}] \\u2500\\u2500')\n",
    "\n",
    "    seqs = read_fasta_file(fasta_path)\n",
    "    if not seqs:\n",
    "        print(f'  \\u26a0\\ufe0f  No sequences found in {Path(fasta_path).name} \\u2014 skipping.')\n",
    "        continue\n",
    "\n",
    "    motifs_file, t0 = [], time.perf_counter()\n",
    "    for sname, seq in seqs.items():\n",
    "        print(f'  \\u25b8 {sname[:60]}  ({len(seq):,} bp)', end='', flush=True)\n",
    "        mots = _nbf_analyze(\n",
    "            sequence=seq, sequence_name=sname,\n",
    "            use_chunking=True,\n",
    "            chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP,\n",
    "            use_parallel_chunks=(EXEC_MODE == 'hybrid'),\n",
    "            enabled_classes=ENABLED_CLASSES,\n",
    "        )\n",
    "        print(f' \\u2192 {len(mots):,} motifs')\n",
    "        motifs_file.extend(mots)\n",
    "        gc.collect()\n",
    "\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    print(f'  \\u2705 {len(motifs_file):,} motifs in {elapsed:.1f}s')\n",
    "\n",
    "    # Build per-file DataFrame\n",
    "    df = pd.DataFrame(motifs_file) if motifs_file else pd.DataFrame()\n",
    "    for col, default in [\n",
    "        ('Class','Unknown'), ('Subclass','Other'), ('Start',0),\n",
    "        ('End',0), ('Length',0), ('Score',0.0), ('Strand','+'), ('Sequence_Name',''),\n",
    "    ]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = default\n",
    "    if not df.empty and 'Length' in df.columns:\n",
    "        m = df['Length'] == 0\n",
    "        df.loc[m, 'Length'] = (df.loc[m,'End'] - df.loc[m,'Start']).clip(lower=0)\n",
    "    df['Source_File'] = Path(fasta_path).name\n",
    "    df['File_Type']   = ftype\n",
    "\n",
    "    # Per-file exports\n",
    "    if not df.empty:\n",
    "        rows = df.to_dict(orient='records')\n",
    "        if EXPORT_CSV:   export_to_csv(rows,   filename=str(file_dir / 'motifs.csv'))\n",
    "        if EXPORT_BED:   export_to_bed(rows,   filename=str(file_dir / 'motifs.bed'))\n",
    "        if EXPORT_JSON:  export_to_json(rows,  filename=str(file_dir / 'motifs.json'))\n",
    "        if EXPORT_EXCEL: export_to_excel(rows, filename=str(file_dir / 'motifs.xlsx'))\n",
    "\n",
    "    # Per-file class distribution plot\n",
    "    if not df.empty:\n",
    "        cc = df['Class'].value_counts()\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        ax.barh(cc.index[::-1], cc.values[::-1])\n",
    "        ax.set_xlabel('Motif Count')\n",
    "        ax.set_title(f'{stem}  [{ftype}] — Class Distribution')\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(str(file_dir / 'class_distribution.png'), dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "    RESULTS_BY_FILE[stem] = {\n",
    "        'df': df, 'folder': file_dir,\n",
    "        'file_type': ftype, 'path': fasta_path,\n",
    "    }\n",
    "    print(f'  \\U0001f4c1 Output folder: {file_dir}')\n",
    "\n",
    "print(f'\\n\\u2705 Analysis complete \\u2014 {len(RESULTS_BY_FILE)} file(s) processed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3-master-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "# CELL 3 — Comprehensive Master Tables & Downloads\n",
    "# ═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "import base64\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "# ── Combine all results into master DataFrame ─────────────────────────────────\n",
    "_dfs = [r['df'] for r in RESULTS_BY_FILE.values() if not r['df'].empty]\n",
    "_master_df = pd.concat(_dfs, ignore_index=True) if _dfs else pd.DataFrame()\n",
    "\n",
    "_master_dir = _BASE / '_master'\n",
    "_master_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ── Comprehensive master tables ───────────────────────────────────────────────\n",
    "_tables = {}\n",
    "if not _master_df.empty:\n",
    "    # 1. Global class distribution across all files\n",
    "    _tables['1_global_class_distribution'] = (\n",
    "        _master_df.groupby(['Source_File', 'File_Type', 'Class'])\n",
    "        .size().reset_index(name='Count')\n",
    "    )\n",
    "    # 2. Per-file summary (file type, sequence count, motif count, unique classes)\n",
    "    _tables['2_per_file_summary'] = pd.DataFrame([\n",
    "        {\n",
    "            'File':         Path(r['path']).name,\n",
    "            'File_Type':    r['file_type'],\n",
    "            'Sequences':    r['df']['Sequence_Name'].nunique() if not r['df'].empty else 0,\n",
    "            'Total_Motifs': len(r['df']),\n",
    "            'Classes':      r['df']['Class'].nunique() if not r['df'].empty else 0,\n",
    "        }\n",
    "        for r in RESULTS_BY_FILE.values()\n",
    "    ])\n",
    "    # 3. Class-level statistics (count, mean length, mean score)\n",
    "    _tables['3_class_statistics'] = (\n",
    "        _master_df.groupby('Class')\n",
    "        .agg(\n",
    "            Total_Count  = ('Class',  'count'),\n",
    "            Mean_Length  = ('Length', 'mean'),\n",
    "            Mean_Score   = ('Score',  'mean'),\n",
    "        )\n",
    "        .round(3).reset_index().sort_values('Total_Count', ascending=False)\n",
    "    )\n",
    "    # 4. Cross-file x class pivot table\n",
    "    _tables['4_file_class_pivot'] = (\n",
    "        _master_df.groupby(['Source_File', 'Class'])\n",
    "        .size().unstack(fill_value=0).reset_index()\n",
    "    )\n",
    "    # 5. Equal-length multi-sequence positional summary (if applicable)\n",
    "    _eq_dfs = [r['df'] for r in RESULTS_BY_FILE.values()\n",
    "               if r['file_type'] == 'multi_equal' and not r['df'].empty]\n",
    "    if _eq_dfs:\n",
    "        _eq_df = pd.concat(_eq_dfs, ignore_index=True)\n",
    "        _tables['5_equal_length_positional'] = (\n",
    "            _eq_df.groupby(['Source_File', 'Class', 'Start'])\n",
    "            .size().reset_index(name='Frequency')\n",
    "            .sort_values(['Source_File', 'Class', 'Frequency'],\n",
    "                         ascending=[True, True, False])\n",
    "        )\n",
    "\n",
    "    # Export master motifs in all enabled formats\n",
    "    _rows = _master_df.to_dict(orient='records')\n",
    "    if EXPORT_CSV:   export_to_csv(_rows,   filename=str(_master_dir / 'master_motifs.csv'))\n",
    "    if EXPORT_BED:   export_to_bed(_rows,   filename=str(_master_dir / 'master_motifs.bed'))\n",
    "    if EXPORT_JSON:  export_to_json(_rows,  filename=str(_master_dir / 'master_motifs.json'))\n",
    "    if EXPORT_EXCEL: export_to_excel(_rows, filename=str(_master_dir / 'master_motifs.xlsx'))\n",
    "\n",
    "    # Export each summary table as CSV\n",
    "    for tname, tdf in _tables.items():\n",
    "        tdf.to_csv(str(_master_dir / f'{tname}.csv'), index=False)\n",
    "\n",
    "    # Master summary plot\n",
    "    _cc   = _master_df['Class'].value_counts()\n",
    "    _ft   = _master_df.groupby('File_Type').size()\n",
    "    _ncol = 3 if len(RESULTS_BY_FILE) > 1 else 2\n",
    "    fig, axes = plt.subplots(1, _ncol, figsize=(6 * _ncol, 4))\n",
    "\n",
    "    axes[0].barh(_cc.index[::-1], _cc.values[::-1], color='steelblue')\n",
    "    axes[0].set_xlabel('Motif Count')\n",
    "    axes[0].set_title('Global Class Distribution')\n",
    "\n",
    "    axes[1].pie(_ft.values, labels=_ft.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Motifs by File Type')\n",
    "\n",
    "    if _ncol == 3:\n",
    "        _pf = _master_df.groupby('Source_File').size().sort_values(ascending=False)\n",
    "        axes[2].barh([Path(n).stem[:25] for n in _pf.index[::-1]], _pf.values[::-1],\n",
    "                     color='coral')\n",
    "        axes[2].set_xlabel('Motif Count')\n",
    "        axes[2].set_title('Motifs per File')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    _plot_path = str(_master_dir / 'master_summary.png')\n",
    "    fig.savefig(_plot_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    display(Image(_plot_path))\n",
    "\n",
    "# ── Display master tables ─────────────────────────────────────────────────────\n",
    "for tname, tdf in _tables.items():\n",
    "    print(f\"\\n{'='*60}\\n{tname.replace('_',' ').upper()}\\n{'='*60}\")\n",
    "    display(tdf)\n",
    "\n",
    "# ── Download links (base64 data URIs — work in any Jupyter environment) ───────\n",
    "_MIME = {\n",
    "    'csv':  'text/csv',\n",
    "    'bed':  'text/plain',\n",
    "    'json': 'application/json',\n",
    "    'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
    "    'png':  'image/png',\n",
    "    'html': 'text/html',\n",
    "}\n",
    "\n",
    "def _dl_link(path, label):\n",
    "    with open(path, 'rb') as fh:\n",
    "        b64  = base64.b64encode(fh.read()).decode()\n",
    "    ext  = Path(path).suffix.lstrip('.')\n",
    "    mime = _MIME.get(ext, 'application/octet-stream')\n",
    "    return (f'<a href=\"data:{mime};base64,{b64}\" '\n",
    "            f'download=\"{Path(path).name}\" '\n",
    "            f'style=\"margin:2px 6px;padding:3px 8px;border:1px solid #aaa;'\n",
    "            f'border-radius:4px;text-decoration:none;\">'\n",
    "            f'{label}</a>')\n",
    "\n",
    "_html_parts = ['<h2>\\U0001f4e5 Downloads</h2>']\n",
    "\n",
    "_html_parts.append('<h3>Master Outputs</h3><div>')\n",
    "for fmt, fname in [\n",
    "    ('CSV',   'master_motifs.csv'),\n",
    "    ('BED',   'master_motifs.bed'),\n",
    "    ('JSON',  'master_motifs.json'),\n",
    "    ('Excel', 'master_motifs.xlsx'),\n",
    "]:\n",
    "    p = _master_dir / fname\n",
    "    if p.exists():\n",
    "        _html_parts.append(_dl_link(str(p), f'Master {fmt}'))\n",
    "_html_parts.append('</div>')\n",
    "\n",
    "_html_parts.append('<h3>Summary Tables</h3><div>')\n",
    "for tname in _tables:\n",
    "    p = _master_dir / f'{tname}.csv'\n",
    "    if p.exists():\n",
    "        _html_parts.append(_dl_link(str(p), tname.replace('_', ' ').title()))\n",
    "_html_parts.append('</div>')\n",
    "\n",
    "_html_parts.append('<h3>Per-File Outputs</h3>')\n",
    "for stem, res in RESULTS_BY_FILE.items():\n",
    "    _html_parts.append(\n",
    "        f'<details style=\"margin:4px 0\"><summary>'\n",
    "        f'<b>{stem}</b> &nbsp;<em>[{res[\"file_type\"]}]</em></summary>'\n",
    "        f'<div style=\"margin:4px 12px\">'\n",
    "    )\n",
    "    for fmt, fname in [\n",
    "        ('CSV', 'motifs.csv'), ('BED', 'motifs.bed'),\n",
    "        ('JSON', 'motifs.json'), ('Excel', 'motifs.xlsx'),\n",
    "    ]:\n",
    "        p = res['folder'] / fname\n",
    "        if p.exists():\n",
    "            _html_parts.append(_dl_link(str(p), fmt))\n",
    "    _img = res['folder'] / 'class_distribution.png'\n",
    "    if _img.exists():\n",
    "        _html_parts.append(_dl_link(str(_img), 'Plot'))\n",
    "    _html_parts.append('</div></details>')\n",
    "\n",
    "display(HTML('\\n'.join(_html_parts)))\n",
    "print(f'\\n\\u2705 All outputs saved in: {_BASE}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}